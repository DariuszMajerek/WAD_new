---
output: html_document
number-sections: false
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

# Modele strukturalne

Modele strukturalne (ang. *Structural Equation Models*) stanowią uogólnienie
klasycznych modeli regresyjnych do układów wielu równań z jednoczesnymi
zależnościami między zmiennymi. W najprostszym wariancie, zwanym *path
analysis* (PA), wszystkie zmienne są obserwowalne, a celem jest estymacja
współczynników ścieżek, dekompozycja efektów na bezpośrednie i pośrednie oraz
wyjaśnienie współzmienności. Konfirmacyjna analiza czynnikowa (CFA) rozszerza
to ujęcie o niewidoczne wprost czynniki latentne, modelując relację
wskaźnik–czynnik i separując wariancję wspólną od swoistej. Modele strukturalne
(SEM) integrują oba poziomy: pomiarowy (jak w CFA) i strukturalny (jak w *path
analysis*), tworząc jedną ramę, w której czynniki latentne i zmienne
obserwowalne łączą się w sieć równań opisujących zależności
przyczynowo-interpretacyjne.

Rys historyczny sięga prac Sewalla Wrighta z lat 1918–1934, który wprowadził
*path analysis* i reguły śledzenia ścieżek, pozwalające dekomponować
kowariancje na sumy iloczynów współczynników [@wright1934]. Równolegle
rozwijała się analiza czynnikowa: @spearman1961, który postulował czynnik
ogólny, a @thurstone1931 wprowadził czynniki wielowymiarowe. Przełomem był
formalny opis CFA i ujęcie SEM przez Jöreskoga (koniec lat 60.), który połączył
model pomiarowy i strukturalny w system LISREL [@tarka2017]. Lata 80. i 90.
przyniosły rozwój estymacji, wskaźników dopasowania i oprogramowania (m.in.
EQS, AMOS), a podręcznikowa synteza Bollen’a (1989) ugruntowała teorię
[@bollen1989]. W kolejnych dekadach pojawiały się metody odporne i dla
zmiennych porządkowych oraz uogólnienia dla danych longitudalnych i
wielopoziomowych, co uczyniło z SEM uniwersalną ramę modelowania.

## Konfirmacyjna analiza czynnikowa

Konfirmacyjna analiza czynnikowa (ang. *Confirmatory Factor Analysis*, CFA),
stanowi ujęcie modelu pomiarowego, w którym a priori narzuca strukturę
zależności między zmiennymi obserwowalnymi a czynnikami ukrytymi. W odróżnieniu
od eksploracyjnej analizy czynnikowej, gdzie pozwala danym „odkrywać” wzorzec
ładunków, w CFA określamy, które zmienne ładują się na których czynnikach,
które ładunki są równe zeru, a które mogą się różnić, oraz czy dopuszczamy
korelacje błędów pomiaru. Celem jest weryfikacja hipotezy o poprawnej budowie
narzędzia pomiarowego i o liczbie oraz treści czynników, a następnie oceniamy
dopasowanie modelu do macierzy kowariancji/średnich w populacji.

Formalnie przyjmujemy ten sam model pomiarowy co w EFA, lecz z nałożonymi
ograniczeniami strukturalnymi na macierz ładunków. Niech
$\mathbf{x}\in\mathbb{R}^p$ oznacza wektor zmiennych obserwowalnych,
$\mathbf{f}\in\mathbb{R}^m$ wektor czynników,
$\Lambda\in\mathbb{R}^{p\times m}$ macierz ładunków,
$\boldsymbol{\epsilon}\in\mathbb{R}^p$ wektor składników swoistych. Model
przyjmuje wówczas postać $$
\mathbf{x}=\boldsymbol{\mu}+\Lambda\,\mathbf{f}+\boldsymbol{\epsilon},\qquad
\mathbb{E}(\mathbf{f})=\mathbf{0},\ \ \mathbb{E}(\boldsymbol{\epsilon})=\mathbf{0},\ \ \mathrm{Cov}(\mathbf{f})=\Phi,\ \ \mathrm{Cov}(\boldsymbol{\epsilon})=\Psi,
$$ gdzie $\Phi$ jest dodatnio określoną macierzą kowariancji czynników (dla
rotacji skośnych) lub macierzą jednostkową (dla czynników ortogonalnych), a
$\Psi$ z reguły jest macierzą diagonalną, co odpowiada nieskorelowanym błędom
pomiaru. Macierz kowariancji implikowana przez model ma postać $$
\Sigma(\theta)=\Lambda\,\Phi\,\Lambda^\top + \Psi,
$$ gdzie $\theta$ reprezentuje wszystkie parametry modelu.

Klucz identyfikacji w CFA polega na tym, że rotacyjna nieoznaczoność znika
dzięki z góry zdefiniowanemu wzorcowi zer w $\Lambda$ (każdy wskaźnik ładujący
się wyłącznie na „własnym” czynniku). Aby skalować czynniki, przyjmujemy jedną
z równoważnych konwencji: ustalamy wariancję czynnika na 1 i estymujemy
wszystkie ładunki, albo ustalamy po jednym ładunku na 1 w każdej kolumnie
$\Lambda$ i estymujemy wariancje czynników. Praktycznie zapewniamy co najmniej
trzy sensowne wskaźniki na czynnik; dwa wskaźniki bywają wystarczające przy
dodatkowych ograniczeniach równości lub znanych błędach pomiaru.

Estymujemy parametry zwykle metodą największej wiarygodności, co przy
normalności wielowymiarowej oznacza minimalizowanie rozbieżność między $S$ a
$\Sigma(\theta)$ i umożliwia wprowadzenie testu globalnego dopasowania
$\chi^2$. Przy naruszeniach normalności stosujemy wersje odporne lub ważone
metody najmniejszych kwadratów dla danych porządkowych (WLSMV) [@li2015].

Interpretację CFA opieramy na ładunkach ($\Lambda$) jako czułościach wskaźników
na czynniki, wariancjach i korelacjach czynników ($\Phi$) jako sile i
współwystępowaniu wymiarów latentnych oraz na resztach jako sygnałach lokalnego
niedopasowania. Siła CFA polega na tym, że pozwala wprost testować hipotezy o
narzędziu pomiarowym, porównywać modele teoretycznie motywowane i zapewniać
podstawę do dalszych modeli strukturalnych, SEM, w których czynniki stają się
zmiennymi wyjaśniającymi i wyjaśnianymi.

::: {#exm-1}
Przeprowadzimy CFA na danych pochodzących z badania PISA 2009, dotyczących
strategii uczenia się uczniów. Wybierzemy 13 pozycji z kwestionariusza ucznia,
które mają odzwierciedlać trzy strategie: zapamiętywania (M), opracowywania (E)
i kontroli (C). Sprawdzimy, czy dane z Wielkiej Brytanii potwierdzają tę
strukturę trójczynnikową.

```{r}
#| fig-height: 12
#| fig-width: 8

#devtools::install_github("talbano/epmr")
library(epmr)
library(gt)
library(lavaan)
library(easystats)
library(tidyverse)
library(sjPlot)

# wybór itemów z testu (łącznie 13), podzielonych wg założonej struktury, 
# którą będziemy weryfikować
# strategie zapamiętywania, opracowywania i kontroli
mitems <- c("st27q01", "st27q03", "st27q05", "st27q07")
eitems <- c("st27q04", "st27q08", "st27q10", "st27q12")
citems <- c("st27q02", "st27q06", "st27q09", "st27q11", 
  "st27q13")
alitems <- c(mitems, eitems, citems)

# Zawęzimy badania tylko go Wielkiej Brytanii
pisagbr <- PISA09[PISA09$cnt == "GBR", alitems]
pisagbr <- pisagbr[complete.cases(pisagbr[, c(mitems, 
  eitems, citems)]), ]
plot_likert(pisagbr, groups = c(rep("Zapamiętywanie", 
  length(mitems)), rep("Opracowywanie", length(eitems)), 
  rep("Kontrola", length(citems))))
```

Na potrzeby budowy modelu konfirmacyjnego użyjemy pakietu `lavaan`. Definiujemy
model z trzema czynnikami, gdzie każdy czynnik jest ładowany przez odpowiednie
pozycje kwestionariusza. Następnie estymujemy model metodą największej
wiarygodności i sprawdzamy dopasowanie modelu do danych.

```{r}
# Definicja modelu CFA
model_cfa <- '
  # Definicja czynników
  Zapamiętywanie =~ st27q01 + st27q03 + st27q05 + st27q07
  Opracowywanie =~ st27q04 + st27q08 + st27q10 + st27q12
  Kontrola =~ st27q02 + st27q06 + st27q09 + st27q11 + st27q13
'

# Estymacja modelu CFA
fit_cfa <- cfa(model_cfa, data = pisagbr, auto.var = TRUE, auto.cov.lv.x = TRUE, std.lv = TRUE)
```

-   `auto.var = TRUE` - estymuje wariancje czynników i błędów pomiarowych, bez
    potrzeby ręcznego ich dodawania.
-   `auto.cov.lv.x = TRUE` - estymuje kowariancje pomiędzy wszystkimi
    czynnikami latentnymi.
-   `std.lv = TRUE` - ustawia wariancję czynników latentnych na 1, co daje
    bezpośrednio interpretowalne ładunki czynnikowe jako korelacje.

```{r}
# Podsumowanie dopasowania
model_performance(fit_cfa, metrics = c("p_Chi2", "GFI", "AGFI", "NFI", "NNFI", "CFI", "RMSEA", "RMR", "SRMR", "RFI")) %>% 
  gt() %>% 
  fmt_number(
    columns = is.double,
    decimals = 3)
```

Najpierw ocenimy dopasowanie modelu:

-   Po pierwsze, test chi-kwadrat (p_Chi2 = 0.000) jest istotny, co formalnie
    sugeruje, że model nie odtwarza idealnie macierzy kowariancji w populacji.
    Jednakże, przy większych próbach test ten jest nadwrażliwy i często
    prowadzi do odrzucenia nawet dobrze dopasowanych modeli, dlatego nie należy
    go traktować jako jedynego kryterium oceny.
-   Jeśli chodzi o wskaźniki dopasowania absolutnego, wartości GFI = 0.936 oraz
    AGFI = 0.907 wskazują na przyzwoite dopasowanie – oba mieszczą się powyżej
    progu 0.90, choć nie osiągają poziomu bardzo dobrego (≥ 0.95). Podobnie RMR
    = 0.042 i SRMR = 0.057 sugerują, że przeciętne reszty między obserwowaną a
    implikowaną macierzą są umiarkowanie niskie – SRMR \< 0.08 jest zwykle
    uznawane za akceptowalne.
-   W przypadku wskaźników dopasowania przyrostowego (NFI = 0.881, NNFI =
    0.856, CFI = 0.885, RFI = 0.850), wszystkie wartości są poniżej
    konwencjonalnego progu 0.90, co wskazuje na pewne niedopasowanie.
-   Szczególnie ważny jest RMSEA = 0.081, który mieści się w strefie
    dopuszczalnej, ale nie idealnej (0.05–0.08 uznaje się za akceptowalne
    dopasowanie, a \> 0.10 za słabe). Wartość 0.081 wskazuje na model na
    granicy akceptowalności – można go uznać za umiarkowanie dopasowany, ale
    istnieją przesłanki do jego ulepszania (np. rozważenie korelacji błędów
    pomiarowych, dodanie lub modyfikacja pozycji).

Teraz przejdźmy do interpretacji parametrów modelu:

```{r}
model_parameters(fit_cfa, component = "loading", standardize = T) %>% 
  gt() %>% 
  fmt_number(
    columns = is.double,
    decimals = 3)

model_parameters(fit_cfa, component = "correlation") %>% 
  gt() %>% 
  fmt_number(
    columns = is.double,
    decimals = 3)
```

-   W przypadku strategii zapamiętywania, wszystkie pozycje
    (`st27q01, st27q03, st27q05, st27q07`) ładują się umiarkowanie silnie na
    czynniku, z wartościami współczynników standaryzowanych w przedziale
    0.59–0.64. Oznacza to, że zmienne te są spójnymi wskaźnikami tego
    konstruktu i wnoszą podobny wkład w jego pomiar. Wysokie istotności
    statystyczne (p \< .001) potwierdzają, że każda z tych zmiennych odgrywa
    istotną rolę w budowie czynnika.
-   Dla strategii opracowywania obserwujemy wyższe wartości ładunków
    czynnikowych – od 0.53 dla `st27q04` do 0.73 dla `st27q12`. Oznacza to, że
    ta grupa pytań jest silnie związana z konstruktem emocjonalnych strategii
    uczenia się, a zwłaszcza pozycje `st27q10` i `st27q12` okazują się
    najbardziej reprezentatywne. Interpretować to można jako silną spójność
    wskaźników i dużą trafność pomiarową tego czynnika.
-   Jeśli chodzi o strategie kontrolne, wszystkie pozycje mają dość wysokie
    ładunki, od 0.55 do 0.67, co sugeruje dobrą konsystencję wewnętrzną tego
    konstruktu. Szczególnie istotne są pozycje `st27q06, st27q09 i st27q11`,
    które mają najwyższe wartości współczynników, a więc najlepiej
    odzwierciedlają mechanizmy związane z kontrolą uczenia się.
-   Wyniki korelacji między trzema strategiami uczenia się wskazują, że są one
    ze sobą istotnie powiązane, choć w różnym stopniu. Najsilniejszy związek
    występuje między Zapamiętywaniem a Kontrolą (r = 0.714, p \< 0.001), co
    sugeruje, że monitorowanie procesu uczenia się jest ściśle powiązane ze
    stosowaniem technik zapamiętywania. Nieco słabsze, ale nadal istotne
    powiązania obserwuje się między Opracowywaniem a Kontrolą (r = 0.576, p \<
    0.001) oraz między Zapamiętywaniem a Opracowywaniem (r = 0.368, p \<
    0.001), co wskazuje, że przetwarzanie materiału oraz kontrola uczenia się
    są umiarkowanie powiązane z technikami pamięciowymi. Łącznie wyniki te
    potwierdzają, że strategie tworzą spójny, ale zróżnicowany zbiór
    powiązanych ze sobą podejść do uczenia się.

Model możemy również przedstawić graficznie.

```{r}
library(semPlot)
library(RColorBrewer)

# wybieramy pastelową paletę
pastel_cols <- brewer.pal(3, "Pastel2")

semPaths(fit_cfa,
         whatLabels = "std",
         what = 'std',
         layout = "tree2",
         groups = "latents",
         sizeMan = 6,
         sizeLat = 8,
         nCharNodes = 0,
         style = "lisrel",
         # kolory pastelowe dla zmiennych latentnych i obserwowanych
         color = pastel_cols,
         colorLat = pastel_cols[1],
         colorMan = pastel_cols[2],
         edge.color = "grey70")
```
:::

## *Path analysis*

Analiza ścieżkowa (ang. *path analysis*) jest jedną z najwcześniejszych form
modelowania strukturalnego i stanowi naturalne rozwinięcie regresji
wielokrotnej. Jej głównym celem jest badanie złożonych układów zależności
przyczynowo-skutkowych między zmiennymi obserwowalnymi, w tym układów
obejmujących zmienne pośredniczące (mediatory). Została zaproponowana przez
Sewalla Wrighta w latach 20. XX wieku jako narzędzie do formalizacji równań
przyczynowych w biologii, a następnie rozwinęła się jako fundament
współczesnych modeli SEM.

Formalnie model analizy ścieżkowej można zapisać jako system równań liniowych
$$
\mathbf{y} = B\mathbf{y} + \Gamma \mathbf{x} + \zeta,
$$ gdzie:

-   $\mathbf{y}$ to wektor zmiennych endogenicznych [^sem-1],
-   $\mathbf{x}$ to wektor zmiennych egzogenicznych [^sem-2],
-   $B$ to macierz współczynników regresji pomiędzy zmiennymi endogenicznymi,
-   $\Gamma$ to macierz współczynników regresji łączących zmienne egzogeniczne
    z endogenicznymi,
-   $\zeta$ to wektor zakłóceń (błędów strukturalnych).

Założenia analizy ścieżkowej są w dużej mierze zbieżne z klasycznymi
założeniami regresji liniowej. Obejmują one liniowość zależności, brak silnej
współliniowości między predyktorami, nieskorelowanie błędów $\zeta$ z
egzogenicznymi zmiennymi $\mathbf{x}$ oraz odpowiednio dużą próbę, aby zapewnić
stabilność estymacji. Dodatkowo zakłada się poprawność teoretyczną modelu – to
badacz definiuje strukturę ścieżek na podstawie teorii lub wcześniejszych
wyników, a analiza ma na celu jej statystyczną weryfikację.

Estymacja parametrów w analizie ścieżkowej opiera się najczęściej na metodzie
największej wiarygodności (*maximum likelihood*, ML), która minimalizuje
różnicę między macierzą kowariancji obserwowanej a macierzą kowariancji
implikowaną przez model. Alternatywnie stosuje się metody oparte na
najmniejszych kwadratach (*generalized least squares*, GLS, *ordinary least
squares*, OLS) [@principl2016], a w przypadku naruszenia normalności rozkładu
dostępne są warianty odporne, takie jak *robust* ML [@principl2016] czy
estymacja asymptotycznie niezależna (*asymptotically distribution free*, ADF)
[@huang2015]. W nowszych zastosowaniach wykorzystuje się również metody
bayesowskie, które pozwalają wprowadzić rozkłady a priori dla parametrów i
prowadzić wnioskowanie probabilistyczne o strukturze zależności.

::: {#exm-2}
Wykonamy prostą analizę ścieżkową na danych `mtcars`, aby zbadać wpływ masy
pojazdu (`wt`) na jego zużycie paliwa (`mpg`), za pośrednictwem mocy silnika
(`hp`). Hipoteza zakłada, że masa wpływa na moc, która z kolei wpływa na
zużycie paliwa.

```{r}
# Model ścieżkowy (wyłącznie zmienne obserwowalne)
# hp jest mediatorem między wt a mpg
model_pa <- '
  # równania regresji (część strukturalna)
  mpg ~ c*wt + b*hp
  hp  ~ a*wt

  # efekty pośrednie i całkowite
  ind := a*b
  tot := c + (a*b)
'

fit_pa <- sem(model_pa, data = mtcars,
              estimator = "MLR")                         # estymator odporny (robust ML)

# Podsumowanie wyników (standaryzacja, istotności, efekty zdefiniowane)
summary(fit_pa, standardized = TRUE, ci = TRUE, rsquare = TRUE)

# Wizualizacja diagramu ścieżek
semPaths(fit_pa,
         what = "std", 
         whatLabels = "std",
         layout = "circle",
         style = "lisrel",
         residuals = FALSE, intercepts = FALSE,
         nCharNodes = 0, sizeMan = 7,
         groups = "manifests",
         color = brewer.pal(3, "Pastel2"),
         edge.color = "grey60")
```

Model zapisujemy jako: $$
\mathbf{y} = B\mathbf{y} + \Gamma \mathbf{x} + \zeta,
$$ gdzie:

-   $\mathbf{y} = \begin{bmatrix} mpg \\ hp \end{bmatrix}$ to zmienne
    endogeniczne,
-   $\mathbf{x} = wt$ to zmienna egzogeniczna,
-   $B$ to macierz regresji pomiędzy zmiennymi endogenicznymi,
-   $\Gamma$ to macierz efektów zmiennych egzogenicznych na endogeniczne,
-   $\zeta$ to wektor błędów strukturalnych.

Estymowane równania $$
\begin{aligned}
mpg &= c \cdot wt + b \cdot hp + \zeta_{mpg}, \\
hp  &= a \cdot wt + \zeta_{hp},
\end{aligned}
$$ gdzie:

-   $a = 46.160$ (standaryzowane $0.659$) – wpływ masy (`wt`) na moc (`hp`),

-   $b = -0.032$ (standaryzowane $-0.361$) – wpływ mocy (`hp`) na spalanie
    (`mpg`),

-   $c = -3.878$ (standaryzowane $-0.630$) – bezpośredni wpływ masy (`wt`) na
    spalanie (`mpg`).

-   Macierz $B$ (zależności między endogenicznymi): $$
    B =
    \begin{bmatrix}
    0 & b \\
    0 & 0
    \end{bmatrix},
    \quad b = -0.032.
    $$

-   Macierz $\Gamma$ (wpływy egzogenicznej zmiennej $wt$): $$
    \Gamma =
    \begin{bmatrix}
    c \\
    a
    \end{bmatrix},
    \quad c = -3.878, \quad a = 46.160.
    $$

-   Wariancje resztowe (błędy strukturalne): $$
    \mathrm{Var}(\zeta_{mpg}) = 6.095 \; (17.3\%),
    \quad \mathrm{Var}(\zeta_{hp}) = 2577.777 \; (56.6\%).
    $$

Oznacza to, że model wyjaśnia 82.7% wariancji spalania i 43.4% wariancji mocy.

-   Efekt pośredni masy na spalanie przez moc $$
    ind = a \cdot b = 46.160 \cdot (-0.032) = -1.467
    $$ istotny statystycznie ($p < 0.001$).

-   Efekt całkowity masy na spalanie: $$
    tot = c + a \cdot b = -3.878 + (-1.467) = -5.344.
    $$ Oznacza to, że wzrost masy samochodu (o jedno odchylenie standardowe tej
    zmiennej) zmniejsza spalanie o 0.868 odchylenia standardowego `mpg` – w
    dużej części bezpośrednio, a w mniejszej poprzez wzrost mocy.

Model ścieżkowy wskazuje, że masa samochodu (`wt`) ma silny negatywny wpływ na
oszczędność paliwa (`mpg`), zarówno bezpośrednio, jak i pośrednio poprzez
zwiększanie mocy silnika (`hp`). Moc natomiast sama w sobie pogarsza spalanie.
Wartości $R^2$ potwierdzają, że model bardzo dobrze wyjaśnia zmienność `mpg`
(83%), ale umiarkowanie słabiej radzi sobie z `hp` (43%).
:::

[^sem-1]: Zmienna endogeniczna jest wielkością, której wartości **wynikają z
    procesów opisanych przez model**. Jest to zmienna **wyjaśniana** przez
    model, czyli taka, której zmienność tłumaczy się innymi czynnikami. W
    modelu przyczynowym jest to zmienna pozostająca **wewnątrz układu
    zależności**.

[^sem-2]: Zmienna egzogeniczna jest wielkością, której wartości są **zadane z
    zewnątrz modelu** i nie wynikają z jego struktury. Jest to zmienna
    **wyjaśniająca**, traktowana jako niezależna od procesu losowego
    opisującego zmienną endogeniczną.

## Modele strukturalne (SEM)

Modele typu *covariance-based structural equation modeling* (CB-SEM), określane
po prostu jako SEM, stanowią rozwinięcie i uogólnienie dwóch podejść: analizy
czynnikowej (CFA) oraz analizy ścieżkowej (*path analysis*). Istota SEM polega
na tym, że pozwala ono jednocześnie badamy trafność pomiaru zmiennych
latentnych oraz testujemy hipotezy dotyczące relacji między tymi zmiennymi.
Dzięki temu SEM stanowi narzędzie integrujące w sobie modelowanie pomiarowe i
strukturalne, umożliwiając analizę złożonych układów zależności obserwowalnych
i nieobserwowalnych.

Formalnie model SEM zapisuje się jako system równań macierzowych. Model
pomiarowy dla zmiennych egzogenicznych ma postać $$
\mathbf{x} = \Lambda_x \boldsymbol{\xi} + \boldsymbol{\delta},
$$ gdzie $\mathbf{x}$ to wektor zmiennych obserwowalnych, $\boldsymbol{\xi}$ –
wektor latentnych zmiennych egzogenicznych, $\Lambda_x$ – macierz ładunków
czynnikowych, a $\boldsymbol{\delta}$ – błędy pomiarowe. Analogicznie model
pomiarowy dla zmiennych endogenicznych przyjmuje formę $$
\mathbf{y} = \Lambda_y \boldsymbol{\eta} + \boldsymbol{\epsilon},
$$ gdzie $\mathbf{y}$ oznacza obserwowalne zmienne endogeniczne,
$\boldsymbol{\eta}$ – latentne zmienne endogeniczne, $\Lambda_y$ – macierz
ładunków, a $\boldsymbol{\epsilon}$ – błędy pomiaru. Trzecim elementem jest
model strukturalny $$
\boldsymbol{\eta} = B \boldsymbol{\eta} + \Gamma \boldsymbol{\xi} + \boldsymbol{\zeta},
$$ który opisuje relacje pomiędzy zmiennymi latentnymi endogenicznymi $(B)$
oraz wpływ zmiennych egzogenicznych na endogeniczne $(\Gamma)$, z
uwzględnieniem zakłóceń strukturalnych $(\boldsymbol{\zeta})$.

W modelach SEM kluczowe znaczenie mają zmienne latentne $(\xi, \eta)$, które
reprezentują konstrukty teoretyczne trudne do bezpośredniego pomiaru, np.
satysfakcję z życia czy strategie uczenia się. Zmienne obserwowalne $(x, y)$
stanowią wskaźniki tych konstruktów. Ładunki czynnikowe $\Lambda$ wskazują, jak
silnie dana zmienna obserwowalna powiązana jest z konstruktem latentnym.
Macierze $B$ i $\Gamma$ opisują odpowiednio zależności między konstruktami oraz
ich uwarunkowania przez zmienne egzogeniczne. Błędy pomiarowe
$(\delta, \epsilon)$ i zakłócenia strukturalne ($\zeta$) odzwierciedlają
niewyjaśnioną wariancję.

Parametry SEM mogą być estymowane różnymi metodami. Najczęściej stosuje się
metodę największej wiarygodności (ML), która minimalizuje rozbieżność między
macierzą kowariancji modelową a empiryczną. Alternatywą są metody najmniejszych
kwadratów: GLS (ang. *Generalized Least Squares*), ULS (ang. *Unweighted Least
Squares*, mniej wymagająca co do rozkładów, lecz bez klasycznych testów
istotności) oraz DWLS (ang. *Diagonally Weighted Least Squares*), szczególnie
polecana przy danych porządkowych. W przypadku naruszeń normalności rozkładu
stosuje się wersje odporne, takie jak MLR (ang. *Maximum Likelihood Robust*)
czy MLM (ang. *Maximum Likelihood Mean-adjusted*), które korygują wariancje i
błędy standardowe [@suppleme2016; @kiliç2020; @li2021; @kyriazos2023].

Znaczenie SEM polega na tym, że łączy ono analizę czynnikową i analizę
ścieżkową w jeden spójny model. W części pomiarowej pozwala sprawdzić, czy
narzędzie badawcze dobrze odwzorowuje zamierzone konstrukty, natomiast w części
strukturalnej umożliwia testowanie hipotez o związkach między zmiennymi
ukrytymi. Dzięki temu SEM jest traktowane jako złoty standard w psychometrii,
naukach społecznych i zarządzaniu, oferując zarówno rzetelną ocenę jakości
pomiaru, jak i analizę zależności przyczynowych.

## Założenia modeli SEM

1.  Oparcie na teorii - SEM z definicji służy testowaniu i potwierdzaniu modelu
    teoretycznego. Dlatego punktem wyjścia musi być koncepcja badawcza oparta
    na wcześniejszych badaniach i spójnej teorii. Model powinien odzwierciedlać
    hipotezy dotyczące relacji między konstruktami latentnymi i zmiennymi
    obserwowalnymi.

2.  Wielkość próby - zaleca się próby liczące co najmniej około 200 obserwacji,
    choć ostateczny wymóg zależy od trzech czynników:

    -   rozkładu zmiennych,
    -   złożoności modelu,
    -   metody estymacji.

    Duże próby zwiększają stabilność wyników i odporność na naruszenia założeń.

3.  Normalność rozkładu - ponieważ SEM opiera się na macierzy kowariancji,
    standardowo zakłada się wielowymiarową normalność rozkładu zmiennych. W
    praktyce odchylenia od normalności można kompensować, stosując estymatory
    odporne, np. robust ML czy WLSMV.

4.  Liniowość związków - zakłada się, że relacje między konstruktami latentnymi
    a wskaźnikami obserwowalnymi oraz między zmiennymi latentnymi mają
    charakter liniowy.

5.  Brak silnej współliniowości - predyktory w modelu powinny być możliwie
    niezależne. Choć umiarkowana współliniowość zwykle nie jest problemem,
    silne korelacje mogą prowadzić do trudności w estymacji i interpretacji
    ścieżek.

6.  Kompletność danych - modele SEM wymagają pełnych danych. Można to osiągnąć
    poprzez imputację (np. średnią, regresję) albo stosując metody
    wykorzystujące pełną informację przy brakach danych, jak FIML (Full
    Information Maximum Likelihood).

7.  Niezależność błędów pomiarowych - standardowe założenie głosi, że błędy
    pomiarowe są nieskorelowane. W praktyce jednak niekiedy dopuszcza się ich
    korelacje, zwłaszcza gdy sugerują to indeksy modyfikacyjne i uzasadnia
    teoria.

## Ocena dopasowania modelu SEM

| Wskaźnik | Wartość idealna | Wartość akceptowalna |
|--------------------------|--------------------------|--------------------------|
| Chi-kwadrat (CMIN) \* | p \> 0,05 (przy α = 0,05) | p \< 0,05 (przy α = 0,05) |
| Standaryzowany chi-kwadrat (CMIN/df) \* | \< 3 | \< 5 |
| GFI (Goodness of Fit Index) | \> 0,95 | \> 0,90 |
| AGFI (Adjusted GFI) | \> 0,90 | \> 0,85 |
| CFI (Comparative Fit Index) \* | \> 0,95 | \> 0,90 |
| TLI (Tucker-Lewis Index, NNFI) | \> 0,90 | \> 0,85 |
| NFI (Normed Fit Index) | \> 0,95 | \> 0,90 |
| PGFI (Parsimonious GFI) | \> 0,50 | brak sztywnych progów |
| PNFI (Parsimonious NFI) | \> 0,50 | brak sztywnych progów |
| PCFI (Parsimonious CFI) | \> 0,50 | brak sztywnych progów |
| SRMR (Standardized RMR) \* | \< 0,05 | \< 0,08 |
| RMSEA (Root Mean Square Error of Approximation) \* | \< 0,05 \[90% CI\] | \< 0,10 \[90% CI\] |

::: {#exm-3}
Zbiór `HolzingerSwineford1939` (pakietu `lavaan`) zawiera wyniki uczniów w
dziewięciu testach poznawczych oraz podstawowe cechy demograficzne i szkolne
[@turney1939]. Dziewięć pozycji testowych tworzy trzy klasyczne domeny
poznawcze: *visual* (postrzeganie wzrokowe), *textual* (kompetencje werbalne) i
*speed* (szybkość przetwarzania), po trzy wskaźniki w każdej domenie.
Oryginalne zmienne testowe oznaczone są jako `x1–x9` i w literaturze przypisuje
się je do czynników: - `x1, x2, x3` → czynnik *Visual*, - `x4, x5, x6` →
czynnik *Textual*, - `x7, x8, x9` → czynnik *Speed.*

W danych można znaleźć też zmienne: `ageyr` (wiek w latach), `agemo` (nadwyżka
miesięcy), `sex` (płeć, kod 1 = chłopiec, 2 = dziewczynka), school (szkoła),
`grade` (klasa). Do modelu wprowadzony zostanie wiek w latach ciągłych:
`age = ageyr + agemo/12`, a płeć zostanie przekodowana binarnie (`sex01`: 0 =
dziewczynka, 1 = chłopiec) dla przejrzystości interpretacji.

Hipotezy badawcze (wpływy bezpośrednie i pośrednie)

Przyjmiemy klasyczną trójczynnikową strukturę pomiarową (*Visual, Textual,
Speed*), a w części strukturalnej założymy wpływy wieku i płci na latentne
zdolności oraz zależność między zdolnościami:

-   $H_0^1:$ Wiek dodatnio wpływa na *Visual* i *Textual* oraz – pośrednio – na
    *Speed*.
-   $H_0^2:$ Płeć (kod 1 = chłopiec) różnicuje profile: dodatnio wpływa na
    *Visual*, natomiast słabiej lub ujemnie na *Textual*; wpływ na *Speed*
    występuje pośrednio poprzez *Visual* i *Textual*.
-   $H_0^3:$ Czynnik *Speed* zależy wprost od *Visual* i *Textual*; efekty
    wieku i płci na *Speed* będą zatem częściowo pośredniczone przez *Visual* i
    *Textual*.

```{r}
data("HolzingerSwineford1939")

# Przygotowanie zmiennych egzogenicznych
hs <- within(HolzingerSwineford1939, {
  age <- ageyr + agemo/12
  sex01 <- as.numeric(sex == 1)  # 1=boy, 0=girl (w razie innego kodowania dostosować)
})

# Specyfikacja modelu SEM: część pomiarowa (CFA) + część strukturalna
model_sem <- '

# Część pomiarowa (CFA)

Visual  =~ x1 + x2 + x3
Textual =~ x4 + x5 + x6
Speed   =~ x7 + x8 + x9

# Część strukturalna

Speed   ~ b1*Visual + b2*Textual + d1*age + d2*sex01
Visual  ~ a1*age + a2*sex01
Textual ~ a3*age + a4*sex01

# Efekty pośrednie wieku i płci na Speed

ind_age  := a1*b1 + a3*b2
ind_sex  := a2*b1 + a4*b2

# Efekty bezpośrednie wieku i płci na Speed

dir_age  := d1
dir_sex  := d2

# Efekty całkowite wieku i płci na Speed

tot_age  := dir_age + ind_age
tot_sex  := dir_sex + ind_sex
'

fit_sem <- sem(model_sem, data = hs,
               estimator = "MLR",      # robust ML
               meanstructure = TRUE)

model_parameters(fit_sem)
```

W części pomiarowej zdefiniowano trzy czynniki pierwszego rzędu z klasycznym
mapowaniem wskaźników. W części strukturalnej założono, że `Visual` i `Textual`
determinują `Speed`, a `age` i `sex01` oddziałują na `Visual` i `Textual.`
Zdefiniowano także etykiety ścieżek, aby policzyć efekty pośrednie i całkowite
(`:=`). Parametry raportowane są w skalach surowych i standaryzowanych.

```{r}
model_performance(fit_sem, c("Chi2","Chi2_df","p_Chi2","CFI","NNFI","RMSEA","RMSEA_CI_low","RMSEA_CI_high","SRMR")) %>% 
  print_html()
```

Ocena dopasowania modelu SEM zawsze powinna być przeprowadzona z kilku
perspektyw: testu chi-kwadrat, wskaźników dopasowania przyrostowych
(*incremental fit indices*) oraz wskaźników błędu aproksymacji. Wyniki uzyskane
w analizie wskazują na istotne sygnały niedopasowania modelu.

Test chi-kwadrat dla modelu dał wartość $\chi^2 = 143,11$ przy df = 37, co przy
dużej liczności prowadzi do p < 0.001. Oznacza to, że w sensie dosłownym
odrzucamy hipotezę o pełnym zgodnym odwzorowaniu macierzy kowariancji w
populacji przez model. Jednak test chi-kwadrat jest bardzo wrażliwy zarówno na
rozmiar próby, jak i złożoność modelu, dlatego wynik ten traktuje się raczej
jako punkt wyjścia niż rozstrzygające kryterium.

Wskaźniki przyrostowe pokazują umiarkowanie słabe dopasowanie. Wartości CFI =
0.89 i NNFI = 0.84 (znany również jako TFI) są wyraźnie poniżej rekomendowanego poziomu 0.90, a tym
bardziej 0.95, które zwykle przyjmuje się jako granicę bardzo dobrego
dopasowania. To sugeruje, że model w obecnej postaci nie wyjaśnia wystarczająco
dobrze struktury zależności obserwowanych w danych i potencjalnie wymaga
modyfikacji – np. dodania powiązań reszt, rewizji struktury ścieżek lub
przemyślenia samego modelu pomiarowego.

Wskaźnik błędu aproksymacji RMSEA = 0.10 (90% CI: 0.08–0.11) jest stosunkowo
wysoki i wykracza poza granicę akceptowalności (zwykle < 0.08, a najlepiej <
0.05). Taki wynik sugeruje, że model charakteryzuje się zauważalnym błędem
przybliżenia w stosunku do danych populacyjnych. Z kolei wskaźnik SRMR = 0.10
jest powyżej standardowego progu akceptowalności 0.08, co dodatkowo wskazuje na
problemy z odwzorowaniem korelacji obserwowanych przez model.

Chcąc poprawić dopasowanie modelu można zaproponować pewne modyfikacje [^sem-3].

[^sem-3]: Indeksy modyfikacyjne (*modification indices*, MI) wskazują, o ile
    zmniejszyłby się chi-kwadrat modelu, gdyby wprowadzono daną modyfikację
    (np. dodano ścieżkę lub skorelowano błędy). Wysokie wartości MI sugerują
    potencjalne obszary niedopasowania modelu do danych i mogą być punktem
    wyjścia do rozważań nad jego ulepszeniem. Należy jednak podchodzić do nich
    ostrożnie i zawsze w kontekście teorii, aby uniknąć nadmiernego dopasowania
    modelu do konkretnego zbioru danych.

```{r}
# Pomocniczo: gdzie są największe niedopasowania?
modindices(fit_sem, sort.=TRUE, minimum.value = 10)[1:11, c("lhs","op","rhs","mi","epc","sepc.all")] %>% 
  gt() %>% 
  fmt_number(columns = c("mi","epc","sepc.all"), decimals = 3) 
```

W powyższej liście wskaźników modyfikacji widać dwa zasadnicze problemy. Po pierwsze, silne sygnały sugerują, że część niedopasowania pochodzi z błędnie określonej lub zbyt restrykcyjnej części pomiarowej (propozycje typu `Textual =~ x1`, `Visual =~ x9`, `Visual =~ x7`, `Visual =~ x6`). Po drugie, wiele propozycji o identycznym mi = 29.857 (`Visual ~ Textual`, `Textual ~ Speed`, `Visual ~~ Textual`, `Textual ~ Visual`, `Visual ~ Speed`) wskazuje, że model próbuje „odzyskać” brakującą współzmienność między konstruktami w części strukturalnej.

Nie należy wprowadzać zbyt wiele modyfikacji jednocześnie. W modelu z mediacją częściową sensowne jest dopuszczenie kowariancji reszt (zakłóceń) między mediatorami, czyli `Visual ~~ Textual`, ponieważ oba konstrukty są endogeniczne (zależne od `age` i `sex01`) i mogą współdzielić niewyjaśnione czynniki. 

```{r}
model_sem_mod1 <- '
  # CFA
  Visual  =~ x1 + x2 + x3
  Textual =~ x4 + x5 + x6
  Speed   =~ x7 + x8 + x9

  # Strukturalny (mediacja częściowa)
  Speed   ~ b1*Visual + b2*Textual + d1*age + d2*sex01
  Visual  ~ a1*age + a2*sex01
  Textual ~ a3*age + a4*sex01

  # Kowariancje reszt zmiennych latentnych
  Visual  ~~ Textual

  # Efekty pośrednie, bezpośrednie i całkowite
  ind_age  := a1*b1 + a3*b2
  ind_sex  := a2*b1 + a4*b2
  dir_age  := d1
  dir_sex  := d2
  tot_age  := dir_age + ind_age
  tot_sex  := dir_sex + ind_sex
'

fit_sem_mod1 <- sem(model_sem_mod1, data = hs,
                      estimator = "MLR",
                      meanstructure = TRUE)

model_performance(fit_sem_mod1, c("Chi2","Chi2_df","p_Chi2","CFI","NNFI","RMSEA","RMSEA_CI_low","RMSEA_CI_high","SRMR")) %>%
  print_html()
```

Po wprowadzeniu kowariancji `Visual ~~ Textual` dopasowanie poprawiło się, ale nadal nie jest ono w pełni satysfakcjonujące, zwłaszcza jeżeli traktować kryteria dopasowania w sposób konserwatywny.

Test $\chi^2$ jest istotny (p = 1.02e-08), co oznacza, że model jako całość nadal odbiega od danych. Trzeba jednak pamiętać, że $\chi^2$ jest bardzo czuły na liczebność próby i na nawet niewielkie niedopasowania, więc w praktyce ocenia się go łącznie z miarami przybliżonego dopasowania. CFI = 0.93 jest wynikiem „umiarkowanie dobrym”, często uznawanym za akceptowalny w analizach aplikacyjnych, ale poniżej typowego progu „dobrego” dopasowania (często 0.95). NNFI/TLI = 0.89 jest słabsze; to sygnał, że w relacji do stopni swobody model nadal jest zbyt uproszczony lub wymusza zbyt wiele restrykcji. RMSEA = 0.08 jest na granicy dopasowania akceptowalnego; przedział ufności 0.06–0.10 sugeruje, że realne niedopasowanie może być od umiarkowanego do wyraźnego, bo górna granica 0.10 jest wysoka. SRMR = 0.06 jest natomiast dobre (często wartości poniżej 0.08 uznaje się za akceptowalne), co wskazuje, że przeciętne reszty w macierzy kowariancji nie są duże, choć pozostają lokalne obszary niedopasowania, które psują CFI/TLI i RMSEA.

```{r}
modindices(fit_sem_mod1, sort.=TRUE, minimum.value = 10)[, c("lhs","op","rhs","mi","epc","sepc.all")] %>% 
  gt() %>% 
  fmt_number(columns = c("mi","epc","sepc.all"), decimals = 3) 
```

W tym momencie ranking `mi` jest znacznie „czystszy” i można z niego wyprowadzić sensowną kolejność działań. Najważniejsza obserwacja jest taka, że największe wartości `mi` dotyczą już głównie części pomiarowej (ładunki krzyżowe), a nie części strukturalnej. To zwykle oznacza, że największe niedopasowania nie wynikają już z braku jednej kowariancji między zmiennymi latentnymi, tylko z tego, że wskaźniki nie są „czystymi” miernikami swoich czynników albo istnieje dodatkowy efekt metody wśród zadań.

W pierwszej kolejności dodamy `x7 ~~ x8` (`mi = 19.271`). Jest to modyfikacja o relatywnie najniższym koszcie interpretacyjnym, bo nie zmienia definicji żadnego czynnika latentnego, a jedynie dopuszcza współzmienność reszt dwóch wskaźników, co często da się uzasadnić podobieństwem treści, formatem zadania lub wspólnym komponentem metody. W praktyce taki krok często poprawia TLI i RMSEA bez „przestawiania” konstruktu. 

```{r}
model_sem_refined <- paste0(model_sem_mod1, '
  # Dodatkowa korelacja reszt wskaźników Speed
  x7 ~~ x8
')

fit_sem_refined <- sem(model_sem_refined, data = hs,
                      estimator = "MLR",
                      meanstructure = TRUE)
model_performance(fit_sem_refined, c("Chi2","Chi2_df","p_Chi2","CFI","NNFI","RMSEA","RMSEA_CI_low","RMSEA_CI_high","SRMR")) %>%
  print_html()
```

W ujęciu decyzyjnym dopasowanie jest już na poziomie, przy którym sensowne jest zatrzymanie się, o ile kolejne modyfikacje wymagałyby ładunków krzyżowych lub zmian strukturalnych bez mocnego uzasadnienia treściowego.

```{r}
model_parameters(fit_sem_refined, standardized = TRUE) 
```

Struktura pomiarowa jest spójna z założeniem trzech czynników. Wszystkie ładunki czynnikowe są dodatnie i istotne, a przedziały ufności są dalekie od zera, co oznacza, że wskaźniki x1–x3 dobrze operacjonalizują Visual, x4–x6 dobrze operacjonalizują Textual, a x7–x9 dobrze operacjonalizują Speed. Jednocześnie istotna korelacja resztowa `x7 ~~ x8` sugeruje, że te dwa wskaźniki Speed współdzielą dodatkową wariancję niewyjaśnioną przez czynnik (np. podobieństwo formatu zadania lub efekt metody), ale nie podważa to samej trójczynnikowej struktury.

W hipotezie dotyczącej zależności Speed od Visual i Textual uzyskuje się częściowe potwierdzenie. Speed zależy istotnie od Visual (b1 = 0.30, p < 0.001), co jest zgodne z założeniem, że wyższa zdolność wizualna wiąże się z wyższym wynikiem na czynniku Speed. Natomiast wpływ Textual na Speed nie jest istotny (b2 = 0.04, p = 0.402), a przedział ufności obejmuje 0, więc w tych danych nie ma podstaw do tezy, że zdolność tekstowa wnosi niezależny wkład do Speed po uwzględnieniu Visual oraz predyktorów bezpośrednich.

Hipoteza o wieku („wiek dodatnio wpływa na Visual i Textual oraz pośrednio na Speed”) nie znajduje potwierdzenia w proponowanym kierunku. Wiek nie wpływa istotnie na Visual (a1 = −0.04, p = 0.547), a na Textual wpływa istotnie, ale ujemnie (a3 = −0.24, p < 0.001). Oznacza to, że wraz ze wzrostem wieku (przy takim kodowaniu age, jakie mamy w danych) obserwuje się spadek czynnika Textual, a nie wzrost. Konsekwentnie, łączny efekt pośredni wieku na Speed nie jest istotny (ind_age = −0.02, p = 0.358). Jednocześnie pojawia się istotny dodatni wpływ bezpośredni wieku na Speed (dir_age = 0.10, p = 0.034), czyli po kontrolowaniu Visual i Textual wiek nadal wnosi dodatni wkład do Speed. W efekcie całkowity wpływ wieku na Speed jest na granicy istotności (tot_age = 0.08, p = 0.052), co sugeruje, że wypadkowy efekt jest słaby i częściowo znoszony przez ujemną ścieżkę age → Textual przy nieistotnym Textual → Speed.

Hipoteza o płci („kod 1 = chłopiec: dodatni wpływ na Visual, słabszy lub ujemny na Textual, a wpływ na Speed pośrednio przez Visual i Textual”) jest potwierdzona tylko częściowo i w ważnym fragmencie inaczej niż zakładano. Zgodnie z hipotezą, płeć ma dodatni i istotny wpływ na Visual (a2 = 0.33, p = 0.007), co oznacza, że chłopcy osiągają wyższy poziom czynnika Visual. Wpływ płci na Textual jest nieistotny (a4 = −0.08, p = 0.537), więc nie ma podstaw, aby mówić o systematycznym „słabszym” profilu tekstowym w tej próbie. Co do Speed, model wskazuje istotny dodatni efekt pośredni płci (ind_sex = 0.10, p = 0.033), który w praktyce pochodzi głównie z drogi sex01 → Visual (dodatniej) oraz Visual → Speed (dodatniej), przy braku wkładu drogi przez Textual. Jednocześnie występuje istotny ujemny efekt bezpośredni płci na Speed (dir_sex = −0.16, p = 0.011), czyli po uwzględnieniu Visual i Textual chłopcy mają niższy poziom Speed. Te dwa efekty działają w przeciwnych kierunkach, przez co efekt całkowity płci na Speed nie jest istotny (tot_sex = −0.07, p = 0.279).

Istotna dodatnia kowariancja `Visual ~~ Textual` (0.38, p < 0.001) potwierdza założenie, że zdolności wizualne i tekstowe współwystępują, nawet po uwzględnieniu wieku i płci. To wspiera narrację o „zależności między zdolnościami”, ale w formie korelacji (współdzielonej wariancji), a nie relacji kierunkowej.

Podsumowując, model wspiera tezę o trójczynnikowej strukturze pomiarowej oraz o istotnym związku Speed z Visual, ale nie wspiera tezy o niezależnym wpływie Textual na Speed. Założenie o dodatnim wpływie wieku na zdolności nie znajduje potwierdzenia; wiek działa bezpośrednio dodatnio na Speed, a na Textual działa ujemnie. Dla płci uzyskuje się profil mieszany: dodatni wpływ na Visual, brak istotnego wpływu na Textual, dodatni wpływ pośredni na Speed przez Visual oraz jednocześnie ujemny wpływ bezpośredni na Speed, co wypadkowo daje nieistotny efekt całkowity.

```{r}
#| fig-width: 10
#| fig-height: 8
# Wizualizacja modelu SEM
semPaths(fit_sem_refined,
         what = "std", 
         whatLabels = "std",
         layout = "tree2",
         style = "lisrel",
         residuals = T, intercepts = F,
         nCharNodes = 0, sizeMan = 5,
         groups = "latent",
         color = brewer.pal(3, "Pastel2"),
         edge.color = "grey60")

```
:::

## CB-SEM vs. PLS-SEM

Analiza równań strukturalnych (SEM) rozwija się w dwóch głównych nurtach:
CB-SEM (ang. *Covariance Based SEM*) oraz PLS-SEM (ang. *Partial Least Squares
SEM*). Różnica pomiędzy CB-SEM a PLS-SEM sprowadza się przede wszystkim do
podejścia badawczego i celu analizy. CB-SEM koncentruje się na globalnym
dopasowaniu całego modelu do danych i jest metodą konfirmacyjną – służy do
testowania hipotez wyprowadzonych z teorii. Wymaga dobrze zdefiniowanego
modelu, dużych prób i spełnienia klasycznych założeń statystycznych, a w zamian
dostarcza bogaty zestaw wskaźników dopasowania i rzetelnych testów
statystycznych. Z kolei PLS-SEM opiera się na minimalizacji reszt na poziomie
zależności między zmiennymi i traktuje model bardziej jako narzędzie
predykcyjne niż potwierdzające [@partial2017]. Jest elastyczniejszy, lepiej
sprawdza się przy małych próbach i nienormalnych danych, ale oferuje mniej
rozwinięte kryteria dopasowania i bywa obciążony w sensie statystycznym. W
praktyce CB-SEM wybiera się do badań potwierdzających teorię, a PLS-SEM – do
badań eksploracyjnych i predykcyjnych.

CB-SEM stosuje się głównie w sytuacjach, gdy badacz chce przetestować
ugruntowany model teoretyczny, wymagający dużych prób i danych o normalnym
rozkładzie. PLS-SEM natomiast okazuje się przydatny w badaniach
eksploracyjnych, przy mniejszych próbach i danych odchylających się od
normalności. Trzeba jednak pamiętać, że wyniki PLS-SEM mogą być bardziej
obciążone, a sama metoda wciąż jest rozwijana. Najnowsze podejścia, takie jak
PLSc-SEM, starają się połączyć zalety obu nurtów.

| Kryterium | CB-SEM | PLS-SEM |
|--------------------------|--------------------------|--------------------------|
| Cel analizy | Potwierdzanie całościowego modelu i dobrze zdefiniowanej teorii | Eksploracja i predykcja, rozwój teorii w początkowej fazie |
| Metoda estymacji | Najczęściej największa wiarygodność (ML), wymagająca normalności | Metoda najmniejszych kwadratów (*Partial Least Squares*), odporna na nienormalność |
| Zmienne latentne | Modele czynnikowe (*factor-based*), akcent na konstrukty latentne | Modele kompozytowe (*composite-based*), akcent na wskaźniki i prognozowanie |
| Dopasowanie modelu | Bogaty zestaw wskaźników globalnego dopasowania (χ², RMSEA, CFI, GFI) | Ograniczony zestaw wskaźników – głównie R², AVE, α Cronbacha |
| Elastyczność modelu | Mniej elastyczny, restrykcyjny, wymaga dokładnego określenia teorii | Bardziej elastyczny, radzi sobie z małymi próbami i brakiem normalności |
| Wymagania co do próby | Zwykle duża próba (≥200), dane normalne | Może być stosowany dla mniejszych prób, brak wymogu normalności |
| Typ badań | Potwierdzające, weryfikacja teorii | Eksploracyjne, poszukujące nowych zależności |
| Rozwój metody | Stabilna, ugruntowana tradycja | Wciąż rozwijana (np. PLSc-SEM), wyniki mogą być obciążone |

## Tworzenie i adaptacja narzędzi pomiarowych w SEM

Poniżej zostanie przedstawiona pełna, uporządkowana ścieżka tworzenia oraz
adaptacji narzędzia pomiarowego (np. psychometrycznego) – od konceptualizacji
do finalnego podręcznika – wraz z kluczowymi statystykami, ich wzorami,
sposobem liczenia i interpretacją. Całość formułujemy w duchu klasycznej teorii
testów, uzupełniając o elementy analizy czynnikowej oraz SEM.

1.  Konceptualizacja konstruktu i specyfikacja treści

Rozpoczynamy od precyzyjnego zdefiniowania konstruktu (dziedzina, zakres,
wymiary) na podstawie literatury. Tworzymy mapę treści (tzw. *blueprint*),
która łączy wymiary teoretyczne z planowanymi obszarami itemów i formatem
odpowiedzi. Już na tym etapie określamy typ modelu pomiarowego (refleksyjny czy
formatywny)[^sem-4], bo determinuje to dalszą metodologię.

![](images/indicators.png)

2.  Generowanie puli pozycji i weryfikacja treści

Budujemy szeroką pulę itemów o zróżnicowanej trudności/poziomie (w testach
osiągnięć) lub „natężeniu” treści (w skalach postaw). Zapewniać jednoznaczność
językową, unikać sformułowań *double-barreled* („Czy jest Pan zadowolony z
obsługi i ceny usługi?” - pytanie jest jednocześnie o obsługę i cenę) i
niepotrzebnych zaprzeczeń („Nie zgadzam się z tym, że nie powinno się zabraniać
palenia w restauracjach”).

Trafność treściowa służy do oceny, czy zestaw pozycji (itemów) faktycznie reprezentuje zakres treści, który ma być mierzony, czyli czy narzędzie „pokrywa” istotne aspekty konstruktu i nie zawiera pytań przypadkowych lub marginalnych. Ponieważ jest to własność merytoryczna, a nie czysto statystyczna, weryfikować ją należy na etapie projektowania narzędzia poprzez ocenę ekspertów dziedzinowych, którzy przypisują każdej pozycji oceny adekwatności (np. na skali porządkowej 1–4). Do ilościowego podsumowania zgodności tych ocen stosuje się współczynnik Aikena $V$, który normalizuje oceny do przedziału [0,1]:
$$
V \;=\; \frac{\sum_{i=1}^{N} (s_i - s_{\min})}{N\,(s_{\max}-s_{\min})},
$$
gdzie $s_i$ oznacza ocenę $i$-tego eksperta, $N$ liczbę ekspertów, a $s_{\min}$ i $s_{\max}$ odpowiednio minimalną i maksymalną wartość skali ocen. Wartość $V=0$ odpowiada sytuacji, w której wszyscy eksperci przyznają oceny minimalne, natomiast $V=1$ oznacza pełną zgodność na poziomie maksymalnym; im wyższe $V$, tym silniejsza jest zgodność, że dana pozycja jest trafna treściowo. W praktyce często przyjmuje się, że wysokie $V$ (np. $\ge 0{,}70$) wskazuje na dobrą trafność treściową pozycji, a niskie wartości stanowią przesłankę do jej przeformułowania lub odrzucenia, przy czym interpretację zawsze należy powiązać z liczbą ekspertów i kryteriami oceny (np. adekwatność, jasność, reprezentatywność).

3.  Adaptacja językowo-kulturowa

Przy przenoszeniu narzędzia między językami stosować *forward translation* (2
niezależne tłumaczenia), *back-translation*, konsensus zespołu i *decentering*
(ew. korekta źródła). Wykonuje się *cognitive interviews* (parafrazy -
powtarzanie pytań własnymi słowami, *think-aloud* - respondent mówi na głos,
jak rozumie pytanie i dlaczego wybiera daną odpowiedź) w grupie docelowej, aby
sprawdzić proces odpowiedzi. Wersję pilotażową poprzedza się audytem językowym
i kulturowym przykładów/skal.

4.  Pilotaż i analiza pozycji

W badaniu pilotażowym szacuje się własności pozycji. W klasycznej teorii testów
kluczowe są:

-   korelacja pozycja–wynik całkowity (skorygowana o daną pozycję); wartości
    $\ge 0.30$ wskazuje satysfakcjonującą dyskryminację;
-   trudność pozycji[^trud] (w testach osiągnięć) jako średni wynik lub odsetek
    poprawnych odpowiedzi $p\in[0,1]$; pożądany rozkład trudności dla zakresu
    zdolności badanych;
-   wpływ usunięcia pozycji na rzetelność (*alpha if item deleted*).

[^trud]: Trudność pozycji dotyczy głównie testów osiągnięć, gdzie istnieje odpowiedź poprawna/niepoprawna. Najprościej definiuje się ją jako odsetek poprawnych odpowiedzi $p \in [0,1]$ albo jako średni wynik w danej pozycji. Wysokie $p$ oznacza pozycję łatwą, niskie $p$ oznacza pozycję trudną. Pożądany nie jest jeden „idealny” poziom trudności, tylko taki rozkład trudności w całym teście, który pokrywa zakres umiejętności badanych: część zadań ma być łatwa, część umiarkowana, część trudna. Dzięki temu test potrafi odróżniać osoby zarówno słabsze, jak i bardzo dobre; gdy wszystkie pozycje są zbyt łatwe lub zbyt trudne, pojawia się efekt sufitu lub podłogi i pomiar traci rozdzielczość.

5.  Wstępna struktura czynnikowa (EFA)

Na oddzielnej próbie wykonuje się eksploracyjną analizę czynnikową (EFA).
Ustala się liczbę czynników stosując *parallel analysis* i kryterium MAP
Velicera. Następnie stosuje się estymatjcę modelu za pomocą PAF lub ML, z
rotacją ortogonalną (np. *varimax*) lub ukośną (np. *oblimin*), zależnie od
oczekiwanej korelacji czynników. Wartości ładunków $|\lambda| \ge 0.40$ zwykle
uznaje się za użyteczne; diagnozuje się ewentualne ładunki krzyżowe i jeśli
takie wystąpią starami się je eliminować.

6.  Konfirmacja analiza czynniowa (CFA) i model pomiarowy

Ustalamy model $$
\mathbf{x} \;=\; \Lambda \mathbf{f} \;+\; \boldsymbol{\epsilon},
\qquad \mathrm{Cov}(\mathbf{f})=\Phi,\quad \mathrm{Cov}(\boldsymbol{\epsilon})=\Psi,
$$ co implikuje macierz kowariancji $$
\Sigma(\theta) \;=\; \Lambda \,\Phi\, \Lambda^\top \;+\; \Psi.
$$ Estymujemy parametry metodą ML lub odporną (np. MLR), dla danych
porządkowych – DWLS. Ocena globalna dopasowania opiera się na:

-   statystyce $\chi^2$ rozbieżności;
-   RMSEA z 90% PU;
-   CFI i TLI (przyrostowe w stosunku do modelu niezależnego):
    -   $\mathrm{CFI} = 1 - \frac{\max(\chi^2_{\text{model}}-df_{\text{model}},\,0)}{\max(\chi^2_{\text{baseline}}-df_{\text{baseline}},\,0)},$
    -   $\mathrm{TLI} = \frac{\chi^2_{\text{baseline}}/df_{\text{baseline}} - \chi^2_{\text{model}}/df_{\text{model}}}{\chi^2_{\text{baseline}}/df_{\text{baseline}} - 1};$
-   SRMR jako średni moduł reszt standaryzowanych.

7.  Rzetelność skali

W klasycznej teorii testów przyjmuje się, że wynik obserwowany $X$ składa się z dwóch składników: wyniku prawdziwego $T$ oraz błędu pomiaru $E$, czyli $X = T + E$. Wynik prawdziwy należy rozumieć jako stabilny, „rzeczywisty” poziom mierzonej cechy u osoby, natomiast błąd pomiaru obejmuje wszystkie losowe czynniki, które powodują, że pomiar w danym momencie nie jest idealnie powtarzalny (np. przypadkowe wahania uwagi, niejednoznaczność itemów, chwilowe warunki badania). W tym ujęciu rzetelność skali $\rho_{XX’}$ opisuje, na ile zmienność wyników obserwowanych w populacji wynika ze zmienności wyniku prawdziwego, a na ile jest tylko „szumem” pomiarowym.

Wzór
$$
\rho_{XX’} \;=\; \frac{\sigma_{T}^2}{\sigma_{X}^2}
$$
mówi, że rzetelność jest ilorazem wariancji wyniku prawdziwego $\sigma_T^2$ do całkowitej wariancji wyniku obserwowanego $\sigma_X^2$. Jeżeli większość wariancji obserwowanej pochodzi z różnic w $T$, rzetelność jest wysoka, co oznacza, że skala stabilnie różnicuje osoby ze względu na mierzoną cechę. Jeżeli natomiast duża część wariancji obserwowanej pochodzi z błędu, rzetelność spada, a wyniki są mniej powtarzalne i mniej precyzyjne.

Z tego wynika też intuicyjna interpretacja wartości liczbowych: $\rho_{XX’}=1$ oznaczałoby pomiar idealny (brak błędu), $\rho_{XX’}=0$ oznaczałoby, że obserwowane różnice są czystym błędem (brak informacji o prawdziwych różnicach). W praktyce wartość rzetelności interpretuje się jako „odsetek” wariancji obserwowanej, który jest sygnałem, a nie szumem. Przykładowo $\rho_{XX’}=0{,}80$ sugeruje, że około 80% wariancji wyników wynika z różnic prawdziwych, a około 20% stanowi wariancja błędu.

Warto dodać, że $\sigma_T^2$ nie jest bezpośrednio obserwowalna, więc w praktyce rzetelność szacuje się przy pomocy procedur pośrednich, takich jak zgodność wewnętrzna (np. alfa Cronbacha, omega), stabilność czasowa (test–retest) lub rzetelność połówkowa. Wszystkie te metody próbują oszacować, jaka część wariancji $X$ jest powtarzalna i związana z $T$, a jaka wynika z losowych fluktuacji.

Najczęściej używane miary do oceny rzetelności to:

-   alfa Cronbacha (spójność wewnętrzna), dla $k$ pozycji 
$$
    \alpha \;=\; \frac{k}{k-1}\left(1 - \frac{\sum_{i=1}^{k}\sigma_i^2}{\sigma_X^2}\right)\!,
    $$ 
    gdzie $\sigma_i^2$ to wariancja pozycji, a $\sigma_X^2$ wariancja sumy
    skali. $\alpha \ge 0.70$ często uznawane jest za akceptowalne (zależnie od
    celu).

-   omega McDonalda 
$$
    \omega \;=\; \frac{\left(\sum_{i=1}^{k} \lambda_i\right)^2}{\left(\sum_{i=1}^{k} \lambda_i\right)^2 + \sum_{i=1}^{k}\psi_{ii}},
    $$ 
    gdzie $\lambda_i$ to ładunki czynnika ogólnego, a $\psi_{ii}$ wariancje
    unikalne. Dla rozwiązań hierarchicznych używamy $\omega_h$ (udział czynnika
    ogólnego).

8.  Trafność

W analizie CFA/SEM ocenia się nie tylko dopasowanie całego modelu, ale także jakość pomiaru poszczególnych konstruktów latentnych, w szczególności trafność zbieżną i rozbieżną. Trafność zbieżna oznacza, że wskaźniki przypisane do jednego czynnika rzeczywiście „zbiegają się” i mierzą ten sam konstrukt (czyli mają wysokie ładunki i relatywnie małe błędy). Trafność rozbieżna oznacza natomiast, że różne czynniki są od siebie empirycznie odróżnialne (czyli korelacje między konstruktami nie są tak wysokie, aby sugerować, że mierzą to samo). W tym celu wykorzystuje się zestaw indeksów opartych na ładunkach czynnikowych i wariancjach błędu.

Podstawą obliczeń są ładunki czynnikowe $\lambda_i$ (czyli siła związku wskaźnika i z czynnikiem) oraz wariancje błędu $\theta_i$ (czyli wariancje reszt/unikalności wskaźników, będące częścią niewyjaśnioną przez czynnik). Zwykle zakłada się, że korzysta się z ładunków wystandaryzowanych, bo wtedy interpretacja jest bezpośrednia: $\lambda_i^2$ można traktować jako część wariancji wskaźnika wyjaśnianą przez czynnik, a $\theta_i$ jako część „błędu” lub wariancji specyficznej.

Pierwszym indeksem jest *composite reliability* (CR), które opisuje spójność pomiaru czynnika podobnie jak rzetelność, ale w logice CFA (uwzględnia nierówne ładunki). Definiuje się je jako
$$
\mathrm{CR} \;=\; \frac{\left(\sum_{i=1}^{k} \lambda_i\right)^2}{\left(\sum_{i=1}^{k} \lambda_i\right)^2 + \sum_{i=1}^{k} \theta_i},
$$
gdzie $k$ oznacza liczbę wskaźników czynnika, $\lambda_i$ są ładunkami, a $\theta_i$ wariancjami błędu. W liczniku znajduje się „siła sygnału” (łączny wkład wskaźników w pomiar czynnika), a w mianowniku sygnał jest zestawiony z sumarycznym błędem pomiaru. Im większe ładunki i mniejsze $\theta_i$, tym wyższe CR. Wartości rzędu $\ge 0{,}70$ zwykle interpretuje się jako satysfakcjonującą spójność pomiaru; wartości dużo niższe sugerują, że wskaźniki są słabo związane z czynnikiem lub mają duże błędy.

Drugim indeksem jest *average variance extracted* (AVE), który mierzy, ile średnio wariancji wskaźników jest „wyciągane” przez czynnik, czyli jak duża część wariancji wskaźników jest wyjaśniana przez konstrukt latentny. AVE definiuje się jako
$$
\mathrm{AVE} \;=\; \frac{\sum_{i=1}^{k} \lambda_i^2}{\sum_{i=1}^{k} \lambda_i^2 + \sum_{i=1}^{k} \theta_i}.
$$
W liczniku pojawiają się kwadraty ładunków $\lambda_i^2$, czyli wkład czynnika do wariancji każdego wskaźnika. Interpretacja jest następująca: $\mathrm{AVE}=0{,}50$ oznacza, że czynnik wyjaśnia przeciętnie około 50% wariancji swoich wskaźników, a pozostała część to błąd i wariancja specyficzna. Przyjmuje się, że $\mathrm{AVE} \ge 0{,}50$ stanowi przesłankę trafności zbieżnej, ponieważ sygnał konstruktu jest co najmniej tak samo silny jak szum pomiarowy w obrębie jego wskaźników. Niska AVE sugeruje, że wskaźniki nie „zbiegają się” dostatecznie w pomiarze jednego konstruktu.

Trafność rozbieżną często ocenia się kryterium Fornella–Larckera. W tym podejściu porównuje się pierwiastek z AVE danego czynnika z jego korelacjami z innymi czynnikami. Warunek ma postać
$$
\sqrt{\mathrm{AVE}_A} \;>\; |\phi_{A,B}|\quad \text{dla każdego } B \neq A,
$$
gdzie $\phi_{A,B}$ oznacza korelację między czynnikami $A$ i $B$. Intuicja jest taka, że $\sqrt{\mathrm{AVE}_A}$ można czytać jako miarę „typowej” siły związku czynnika z własnymi wskaźnikami, natomiast $|\phi_{A,B}|$ opisuje, jak mocno czynnik $A$ jest powiązany z innym czynnikiem. Jeżeli korelacja między dwoma czynnikami przekracza $\sqrt{\mathrm{AVE}}$, to znaczy, że czynnik jest bardziej podobny do innego konstruktu niż do własnych wskaźników, co osłabia argument o rozróżnialności konstruktów.

Alternatywną i często bardziej czułą miarą trafności rozbieżnej jest HTMT (*heterotrait–monotrait ratio*). Idea polega na porównaniu przeciętnej korelacji między wskaźnikami różnych konstruktów (*heterotrait*) z przeciętną korelacją wskaźników w obrębie tego samego konstruktu (*monotrait*). W uproszczonej postaci można to zapisać jako
$$
\mathrm{HTMT} \;=\; \frac{\text{średnia korelacja między wskaźnikami z różnych konstruktów}}{\text{średnia korelacja między wskaźnikami w obrębie tych konstruktów}}.
$$
Jeżeli konstrukty $A$ i $B$ są rozróżnialne, to korelacje „pomiędzy” konstruktami powinny być istotnie mniejsze niż korelacje „wewnątrz” konstruktów, więc HTMT powinno być wyraźnie poniżej 1. W praktyce wartości mniejsze niż około $0{,}85$ (kryterium bardziej restrykcyjne) lub $0{,}90$ (kryterium bardziej liberalne) interpretuje się jako przesłankę dobrej rozróżnialności, natomiast HTMT bliskie 1 sugeruje, że dwa konstrukty empirycznie nakładają się na siebie.

9.  Skalowanie, punktacja i normy

Decydujemy o sposobie punktowania: suma/średnia pozycji (po ewentualnym
odwróceniu kodowania) czy punktacja czynnikowa (regresyjna/
Bartlett’a[^sem-5]). Ustalamy również normy na podstawie np. siatki stenowej
(niski, przeciętny i wysoki poziom skali).

::: {#exm-4}
Dla ilustracji adaptacji narzędzia pomiarowego, wykorzystamy oszacowaną już
strukturę czynnikową z @exm-1. Mieliśmy tam 13 pozycji opisujących trzy
strategie: zapamiętywania, opracowywania i kontroli dla osób z Wielkiej
Brytanii. Załóżmy, że tą samą strukturę chcemy przenieść na rynek Hiszpański. W
tym celu sprawdzimy dopasowanie modelu konfirmacyjnego na danych hiszpańskich.

```{r}
pisaspa <- PISA09[PISA09$cnt == "ESP", c(alitems, "sex")]
pisaspa <- pisaspa[complete.cases(pisaspa[, c(mitems, 
  eitems, citems)]), ]

# Definicja modelu CFA
model_cfa <- '
  # Definicja czynników
  Zapamiętywanie =~ st27q01 + st27q03 + st27q05 + st27q07
  Opracowywanie =~ st27q04 + st27q08 + st27q10 + st27q12
  Kontrola =~ st27q02 + st27q06 + st27q09 + st27q11 + st27q13
'

# Estymacja modelu CFA
fit_cfa_spa <- cfa(model_cfa, data = pisaspa, auto.var = TRUE, auto.cov.lv.x = TRUE, std.lv = TRUE)
```

```{r}
compare_performance(fit_cfa, fit_cfa_spa, metrics = c("p_Chi2", "GFI", "AGFI", "NFI", "NNFI", "CFI", "RMSEA", "RMR", "SRMR", "RFI")) %>% 
  gt() %>% 
  fmt_number(
    columns = is.double,
    decimals = 3)
```

Ocena jakości dopasowania modelu pokazuje, że przyjęta struktura dla Wielkiej
Brytanii sprawdza się również dla Hiszpanii. To dopiero pierwszy (oczywiście
pominąwszy wszystkie wcześniejsze kroki jak tłumaczenie, czy analiza
eksploracyjna) krok do adaptacji narzędzia do nowych warunków.

Teraz ocenimy rzetelność skali.

```{r}
tab_itemscale(df = pisaspa, factor.groups = c(rep("Zapamiętywanie", 4), rep("Opracowanie", 4), rep("Kontrola", 5)), factor.groups.titles = c("Kontrola", "Opracowanie", "Zapamiętywanie")) 
```

**Spójność wewnętrzna poszczególnych komponentów**

Każda z trzech skal (komponentów) osiąga akceptowalny poziom rzetelności
wewnętrznej. Wartości współczynnika Cronbacha $\alpha$ wynoszą odpowiednio
0.738 dla strategii opracowywania, 0.744 dla kontroli oraz 0.719 dla
zapamiętywania. Są to wartości przekraczające próg 0.70, co w badaniach
psychometrycznych uznaje się za wystarczające dla narzędzi we wczesnym etapie
walidacji. Wskazuje to, że pozycje w każdej ze skal mierzą spójny konstrukt.

Wartości korelacji między pozycjami (*mean inter-item correlation*) mieszczą
się w zakresie 0.37–0.42, co uznaje się za optymalne (wartości zbyt niskie
<0.20 sugerują brak spójności, natomiast zbyt wysokie >0.70 nadmiarowość).
Oznacza to, że pozycje są ze sobą skorelowane w stopniu umiarkowanym,
zachowując jednocześnie różnorodność treściową.

**Analiza jakości pozycji**

Wszystkie pozycje mają trudność (*item difficulty*) w przedziale 0.50–0.79, co
oznacza, że średnie odpowiedzi respondentów oscylują wokół środka skali, bez
efektów podłogowych czy sufitowych. Pozycje mają także umiarkowane lub wysokie
wartości dyskryminacji (*item discrimination* w przedziale 0.43–0.57),
wskazujące, że dobrze różnicują osoby z wyższymi i niższymi wynikami ogólnymi.
Żadna z pozycji nie obniża znacząco rzetelności całej skali (wszystkie wartości
„α if deleted” pozostają na poziomie podobnym lub niższym niż pełne α).

**Związki między komponentami**

Korelacje pomiędzy skalami są wszystkie istotne statystycznie, ale mają
zróżnicowaną siłę. Najsilniejszy związek występuje pomiędzy Kontrolą a
Opracowaniem (r = 0.521, p < .001). Można to interpretować tak, że osoby,
które dbają o planowanie i monitorowanie swojego uczenia się, częściej stosują
także strategie głębszego opracowywania materiału. Skala Zapamiętywanie
koreluje umiarkowanie z Opracowaniem (r = 0.376, p < .001), co jest zgodne z
intuicją: aby skutecznie zapamiętać, często trzeba wcześniej przetworzyć
materiał. Najsłabszy, choć istotny związek obserwujemy między Kontrolą a
Zapamiętywaniem (r = 0.222, p < .001), co sugeruje, że te dwie strategie są
bardziej odrębne, a ich powiązanie jest ograniczone.

**Podsumowanie**

Otrzymane wyniki sugerują, że narzędzie jest psychometrycznie poprawne: ma
akceptowalną spójność wewnętrzną, zrównoważony poziom trudności pozycji, dobre
wskaźniki dyskryminacji oraz pozwala rozróżniać trzy powiązane, ale odrębne
strategie uczenia się. Komponent 2 wydaje się pełnić rolę centralną, ponieważ
jest najwyraźniej powiązany zarówno z komponentem 1, jak i 3. To może sugerować
jego bardziej ogólny charakter lub funkcję „pomostu” między dwoma innymi
wymiarami.

Po wykonaniu analizy CFA i ocenie rzetelności kolejnym etapem adaptacji
narzędzia jest przeprowadzenie rozszerzonych analiz stabilności w czasie, takich jak
test–retest czy współczynnik ICC (ang. *intraclass correlation coefficient*), które pozwalają ocenić powtarzalność wyników
(tych nie wykonamy, ponieważ do tego potrzeba przeprowadzenia ankiety w dwóch
momentach czasowych). Należy także zweryfikować trafność – konwergencyjną,
dyskryminacyjną i kryterialną – aby upewnić się, że narzędzie mierzy to, co
zakładano teoretycznie.

```{r}
library(semTools)
AVE(fit_cfa_spa) 
compRelSEM(fit_cfa_spa)
htmt(model_cfa, data = pisaspa)
```

Wyniki można interpretować na trzech poziomach: rzetelności wewnętrznej (CR),
trafności konwergencyjnej (AVE) oraz trafności dyskryminacyjnej (HTMT).

-   Współczynniki *Composite Reliability* (CR) mieszczą się w przedziale od
    0.72 do 0.75. Są to wartości powyżej progu 0.70, co sugeruje akceptowalną
    trafność wewnętrzną każdej ze skal. Oznacza to, że wskaźniki w ramach
    czynnika zapamiętywania, opracowywania i kontroli dostarczają relatywnie
    stabilnej informacji o zmiennej latentnej.
-   Średnia wyjaśniona wariancja (AVE) dla wszystkich trzech czynników jest
    niska: 0.395, 0.418 i 0.373. Kryterium akceptowalne to zwykle AVE ≥ 0.50,
    co oznacza, że czynnik powinien wyjaśniać przynajmniej połowę wariancji
    swoich wskaźników. Tutaj wartości poniżej 0.5 wskazują, że wyjaśniona część
    wariancji jest mniejsza niż ta przypisana błędowi. Może to oznaczać, że
    wskaźniki są dość zróżnicowane, a ich wspólna treść (latentna) nie jest
    wystarczająco silnie uchwycona. W praktyce oznacza to ograniczoną trafność
    konwergencyjną – czyli wskaźniki nie „zbiegają się” wystarczająco na
    wspólny konstrukt.
-   Macierz HTMT wskazuje na poziom rozróżnialności czynników (trafności
    dyskryminacyjnej). Przyjmuje się, że wartości HTMT < 0.85 (lub bardziej
    liberalnie < 0.90) oznaczają satysfakcjonującą rozróżnialność. W tym
    przypadku:
    -   Zapamiętywanie–Opracowywanie = 0.288 – bardzo niski współczynnik, dobra
        rozróżnialność,
    -   Zapamiętywanie–Kontrolne = 0.482 – umiarkowany, nadal bezpieczny,
    -   Opracowywanie–Kontrolne = 0.680 – wyższy, ale poniżej progu 0.85, więc
        rozróżnialność jest zachowana.

Podsumowując, model charakteryzuje się akceptowalną rzetelnością i zadowalającą
trafnością dyskryminacyjną, ale ograniczoną trafnością konwergencyjną. W
praktyce oznacza to, że choć skale mierzą różne konstrukty i są spójne
wewnętrznie, to konstrukty te nie są jeszcze w pełni „czysto” uchwycone przez
zestaw wskaźników – być może potrzebna byłaby rewizja niektórych pozycji, ich
dodanie lub modyfikacja.

Istotnym krokiem jest również badanie równoważności pomiaru (*measurement
invariance*) przy użyciu CFA wielogrupowej, co umożliwia porównywanie wyników
między grupami, np. ze względu na płeć czy wiek. My wykonamy analizę w podziale
ze względu na płeć, aby dowiedzieć się czy narzędzie mierzy badane konstrukty
podobnie w obu grupach.

Równoważność pomiaru, oznacza sprawdzenie, czy ten sam model pomiarowy (CFA) działa w ten sam sposób w różnych grupach. W praktyce chodzi o odpowiedź na pytanie, czy porównywanie wyników między grupami (np. kobietami i mężczyznami) jest uczciwe metodologicznie: czy różnice w wynikach odzwierciedlają rzeczywiste różnice w konstrukcie latentnym, a nie to, że pozycje są inaczej rozumiane, mają inną „siłę” pomiaru lub inny poziom bazowy w danej grupie.

W CFA wielogrupowej estymuje się ten sam model w kilku grupach jednocześnie (tu: `group = "sex"`), a następnie narzuca się coraz silniejsze ograniczenia równości parametrów pomiarowych między grupami. Każdy kolejny krok odpowiada wyższemu poziomowi równoważności i pozwala na coraz „mocniejsze” porównania między grupami.

Równoważność konfiguracyjna (*configural invariance*) polega na tym, że w obu grupach obowiązuje ta sama struktura czynnikowa: te same pozycje ładują na te same czynniki, ale wartości ładunków, przecięć i błędów mogą się różnić. Jeżeli ten model ma akceptowalne dopasowanie, oznacza to, że w obu grupach da się opisać dane tą samą „mapą” konstruktów, co jest warunkiem bazowym dalszych kroków.

Równoważność metryczna (*metric invariance*, nazywana też „słabą”) dodaje ograniczenie równości ładunków czynnikowych między grupami: `group.equal = "loadings"`. Oznacza to, że relacja między czynnikiem a wskaźnikiem ma tę samą siłę w obu grupach. Jeżeli metryczność się utrzymuje, można porównywać zależności strukturalne między konstruktami w grupach, na przykład porównywać regresje (ścieżki) lub korelacje między czynnikami, bo skala czynnika jest w obu grupach „taka sama” w sensie jednostki miary.

Równoważność skalowa (*scalar invariance*, „silna”) narzuca równość zarówno ładunków, jak i przecięć (*intercepts*): `group.equal = c("loadings","intercepts")`. Przecięcie jest poziomem oczekiwanej odpowiedzi na pozycję, gdy czynnik latentny ma wartość 0. Jeżeli przecięcia są równe, oznacza to, że przy tym samym poziomie cechy latentnej osoby z obu grup mają tę samą „bazową” tendencję do udzielania odpowiedzi. Ten poziom równoważności jest kluczowy, aby porównywać średnie czynników latentnych między grupami. Bez równoważności skalowej różnice średnich mogłyby wynikać z systematycznego przesunięcia pozycji, a nie z realnych różnic w konstrukcie.

Równoważność ścisła (*strict invariance*) dodatkowo wymusza równość wariancji resztowych (błędów pomiaru) wskaźników: `group.equal = c("loadings","intercepts","residuals").` Oznacza to, że precyzja pomiaru pozycji jest taka sama w obu grupach. Jest to najsilniejsze i najtrudniejsze do spełnienia założenie; bywa wymagane, jeśli chce się porównywać wyniki obserwowalne (sumy/średnie) wprost między grupami lub gdy chce się wykazać pełną porównywalność pomiaru, ale w praktyce wiele badań zatrzymuje się na poziomie skalowym.

```{r}
# równoważność konfiguracyjna 
fit_config <- cfa(model_cfa, data = pisaspa, group = "sex", std.lv = TRUE)

# równoważność metryczna (równe ładunki czynnikowe)
fit_metric <- cfa(model_cfa, data = pisaspa, group = "sex", group.equal = "loadings", std.lv = TRUE)

# równoważność skalowa (równe ładunki i przecięcia)
fit_scalar <- cfa(model_cfa, data = pisaspa, group = "sex", group.equal = c("loadings", "intercepts"), std.lv = TRUE)

# równoważność ścisła (ładunki, przecięcia i błędy pomiarowe)
fit_strict <- cfa(model_cfa, data = pisaspa, group = "sex", group.equal = c("loadings", "intercepts", "residuals"), std.lv = TRUE)

# Porównania dopasowania
anova(fit_config, fit_metric, fit_scalar, fit_strict)

fitMeasures(fit_config, c("cfi","rmsea","srmr"))
fitMeasures(fit_metric, c("cfi","rmsea","srmr"))
fitMeasures(fit_scalar, c("cfi","rmsea","srmr"))
fitMeasures(fit_strict, c("cfi","rmsea","srmr"))
```

Powyższe wyniki uwidaczniają się dwie rzeczy: (1) testy różnicowe $\chi^2$ wskazują na „istotne” pogorszenie dopasowania po każdym zaostrzeniu ograniczeń, oraz (2) zmiany wskaźników przybliżonego dopasowania (CFI/RMSEA/SRMR) są małe. W praktyce, przy dużych próbach, testy $\chi^2$ są bardzo czułe i często „wychodzą istotne” nawet wtedy, gdy pogorszenie dopasowania jest znikome z punktu widzenia zastosowań. Dlatego w analizie równoważności pomiaru zwykle interpretuje się oba typy informacji, ale większą wagę przykłada się do zmian CFI, RMSEA i SRMR.

Najpierw warto ocenić dopasowanie modelu bazowego (konfiguracyjnego), bo ono wyznacza „punkt startowy” całej procedury. U nas `fit_config` ma CFI = 0.886, RMSEA = 0.079, SRMR = 0.054. To oznacza dopasowanie umiarkowane: SRMR jest akceptowalne, natomiast CFI jest wyraźnie poniżej 0.90, a RMSEA jest na granicy wartości, które często uznaje się za „przeciętne” (około 0.08). Wniosek jest taki, że sama struktura pomiarowa w obu grupach działa podobnie (bo model się estymuje i ma umiarkowane dopasowanie), ale model nie opisuje danych idealnie już na poziomie bazowym. To nie przekreśla testu równoważności, ale każe ostrożnie formułować wnioski: równoważność można uznać za wspieraną, natomiast jakość samego modelu pomiarowego nadal może wymagać dopracowania.

Przejście z równoważności konfiguracyjnej do metrycznej (równe ładunki) daje: CFI 0.886 → 0.884 (spadek $\Delta CFI = −0.002$), RMSEA 0.079 → 0.076 ($\Delta RMSEA = −0.003$), SRMR 0.054 → 0.056 ($\Delta SRMR = 0.002$). To są zmiany bardzo małe, czyli ładunki czynnikowe można traktować jako zbliżone w obu grupach, a więc jednostka miary czynnika jest porównywalna. Istotny test $\chi^2$ różnic ($p \ll 0.001$) prawdopodobnie wynika tu głównie z czułości testu, bo wskaźniki przybliżonego dopasowania prawie się nie zmieniają.

Przejście z metrycznej do skalowej (równe ładunki i przecięcia) daje: CFI 0.884 → 0.875 ($\Delta CFI = −0.009$), RMSEA 0.076 → 0.076 ($\Delta RMSEA \approx 0.000$), SRMR 0.056 → 0.058 ($\Delta SRMR = 0.002$). To jest najbardziej „kosztowny” krok, co jest typowe, bo przecięcia często różnią się między grupami. Jednocześnie spadek CFI o 0.009 nadal jest niewielki i zwykle mieści się w praktycznych kryteriach akceptacji. W efekcie można powiedzieć, że równoważność skalowa jest w przybliżeniu spełniona, czyli porównywanie średnich latentnych między płciami ma metodologiczne uzasadnienie (z zastrzeżeniem, że model bazowy nie jest jakoś świetnie dopasowany).

Przejście do równoważności ścisłej (dodatkowo równe reszty) daje: CFI 0.875 → 0.873 ($\Delta CFI = −0.002$), RMSEA 0.076 → 0.074 ($\Delta RMSEA = −0.002$), SRMR 0.058 → 0.059 ($\Delta SRMR = 0.001$). Zmiany są minimalne, więc także ścisłość wygląda na akceptowalną w sensie praktycznym. Oznacza to, że precyzja pomiaru wskaźników (wariancje reszt) jest podobna w obu grupach, co wzmacnia argument o porównywalności narzędzia.

AIC i BIC rosną wraz z narzucaniem ograniczeń, co jest normalne, bo modele stają się bardziej restrykcyjne; w testach równoważności i tak kluczowe są zmiany dopasowania oraz interpretacja merytoryczna, a nie wybór „najlepszego” modelu według AIC/BIC. Wynik anova mówi tu przede wszystkim, że każde dodatkowe ograniczenie ma wykrywalny koszt w $\chi^2$, ale wskaźniki przybliżonego dopasowania sugerują, że koszt jest mały.

Podsumowując, mamy przesłanki do przyjęcia równoważności metrycznej, a skalową i ścisłą możesz uznać za spełnione w sensie przybliżonym (praktycznym). Jednocześnie warto zaznaczyć w raporcie, że dopasowanie modelu konfiguracyjnego jest umiarkowane (CFI < 0.90), więc wnioski o równoważności są tak dobre, jak dobry jest sam model pomiarowy. Jeżeli chcesz wzmocnić część pomiarową, sensownie jest przejrzeć reszty i wskaźniki modyfikacji osobno w grupach, a w razie potrzeby zastosować równoważność częściową, czyli zwolnić pojedyncze intercepty lub ładunki, które najbardziej „psują” krok skalowy, zamiast odrzucać porównywalność całego narzędzia.

Na koniec utworzymy skale, które można łatwo intepretować przez osoby, które
nie znają narzędzia i jego konstrukcji dobrze.

```{r}
# --- KLUCZE SKAL (dokładnie jak w modelu) ---
zap_items <- c("st27q01","st27q03","st27q05","st27q07")                 # Zapamiętywanie
opr_items <- c("st27q04","st27q08","st27q10","st27q12")                 # Opracowywanie
kon_items <- c("st27q02","st27q06","st27q09","st27q11","st27q13")       # Kontrola

# Uwaga: jeśli jakieś pozycje wymagają odwrócenia, zastosować recoding przed agregacją.

scores_simple <- pisaspa %>%
  mutate(
    Zapam_mean = rowMeans(across(all_of(zap_items)), na.rm = TRUE),
    Oprac_mean = rowMeans(across(all_of(opr_items)), na.rm = TRUE),
    Kontr_mean = rowMeans(across(all_of(kon_items)), na.rm = TRUE),
    Zapam_sum  = rowSums(across(all_of(zap_items)), na.rm = TRUE),
    Oprac_sum  = rowSums(across(all_of(opr_items)), na.rm = TRUE),
    Kontr_sum  = rowSums(across(all_of(kon_items)), na.rm = TRUE)
  )

# Wyniki czynnikowe – metoda Bartletta (bardziej "czyste" wobec błędów specyficznych)
fs_bartlett <- lavPredict(fit_cfa_spa, method = "Bartlett")

# Złożyć do wspólnej ramki (zachowując ewentualne zmienne grupujące)
scores_latent <- cbind(
  pisaspa %>% select(any_of(c("sex","age"))),
  as.data.frame(fs_bartlett)
)
```

```{r}
to_sten <- function(z){
  # transformacja przybliżona; wyniki przycięte do 1..10
  s <- round(2*z + 5.5)
  pmin(10, pmax(1, s))
}

# Percentyle z ECDF
perc_ecdf <- function(x) round(ecdf(x)(x)*100, 1)

# --- NORMY GLOBALNE dla wyników latentnych Bartletta ---
latent_names <- c("Zapamiętywanie","Opracowywanie","Kontrola")

norms_global <- scores_latent %>%
  mutate(
    across(all_of(latent_names), scale, .names = "{.col}_z") %>% as.data.frame()
  )

# Dla wygody wylicz stens, percentyle dla każdej skali latentnej
for(lat in latent_names){
  zcol <- paste0(lat, "_z")
  norms_global[[paste0(lat,"_sten")]]    <- to_sten(norms_global[[zcol]])
  norms_global[[paste0(lat,"_pct")]]     <- perc_ecdf(scores_latent[[lat]])
}

# Podgląd wybranych kolumn
head(norms_global %>% select(any_of(c("sex","age")),
                             ends_with("_z"),
                             ends_with("_sten"),
                             ends_with("_pct")), n = 20) %>% 
  gt() %>% 
  fmt_number(columns = is.double, decimals = 2) %>% 
  tab_options(
    table.font.size = px(10), 
  )

# --- NORMY WEDŁUG PŁCI (grupowe) ---
norms_by_sex <- scores_latent %>%
  group_by(sex) %>%
  mutate(
    # z-score wewnątrz płci
    across(all_of(latent_names),
           ~ as.numeric(scale(.x)), .names = "{.col}_z_g"),
    # stens wewnątrz płci
    across(ends_with("_z_g"),
           ~ to_sten(.x), .names = "{.col}_sten"),
  ) %>%
  # percentyle z ECDF wewnątrz płci
  mutate(
    across(all_of(latent_names),
           ~ perc_ecdf(.x), .names = "{.col}_pct_g")
  ) %>%
  ungroup()

# Podgląd
head(norms_by_sex %>%
       select(sex, starts_with("Zapamiętywanie_"),
                    starts_with("Opracowywanie_"),
                    starts_with("Kontrola_")), n = 20)%>% 
  gt() %>% 
  fmt_number(columns = is.double, decimals = 2) %>% 
  tab_options(
    table.font.size = px(10), 
  )
```
:::

[^sem-4]: Model refleksyjny zakłada, że konstrukt latentny wywołuje pewien
    poziom odpowiedzi na pozycje: zmienne obserwowalne są efektami wspólnej
    przyczyny, ich błędy są specyficzne i niepowiązane, a wysoka współzależność
    pozycji jest oczekiwana. Model formatywny zakłada przeciwny kierunek
    przyczynowy: wskaźniki „tworzą” konstrukt (kompozyt), więc itemy nie muszą
    być skorelowane, a miary spójności wewnętrznej nie mają zastosowania.

[^sem-5]: Bartlett scores są nieobciążonymi estymatorami czynników latentnych,
    ale mogą być mniej stabilne w małych próbach i przy słabych ładunkach.
