[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wielowymiarowa analiza danych",
    "section": "",
    "text": "WstÄ™p\nWielowymiarowa analiza danych stanowi jeden z filarÃ³w wspÃ³Å‚czesnej statystyki i eksploracji danych, oferujÄ…c metody pozwalajÄ…ce zrozumieÄ‡ strukturÄ™ i zaleÅ¼noÅ›ci w zbiorach danych, w ktÃ³rych kaÅ¼da obserwacja jest opisana wieloma zmiennymi jednoczeÅ›nie. W dobie powszechnego dostÄ™pu do danych oraz rosnÄ…cego zapotrzebowania na ich zaawansowanÄ… analizÄ™, umiejÄ™tnoÅ›Ä‡ stosowania metod wielowymiarowych staje siÄ™ nieodzowna zarÃ³wno w badaniach naukowych, jak i w analizie danych stosowanej w przemyÅ›le, finansach, biologii, medycynie czy naukach spoÅ‚ecznych.\nNiniejsza ksiÄ…Å¼ka zostaÅ‚a opracowana z myÅ›lÄ… o dwÃ³ch kierunkach ksztaÅ‚cenia akademickiego: matematyce oraz inÅ¼ynierii i analizie danych. Jej celem jest zapewnienie solidnych podstaw teoretycznych oraz praktycznych umiejÄ™tnoÅ›ci niezbÄ™dnych do stosowania metod wielowymiarowych w rzeczywistych problemach badawczych i aplikacyjnych. Zakres tematyczny ksiÄ…Å¼ki zostaÅ‚ dobrany tak, aby uwzglÄ™dniaÄ‡ zarÃ³wno klasyczne metody statystyczne, jak i techniki wykorzystywane we wspsÃ³Å‚czesnej analizie danych.\nW pierwszej czÄ™Å›ci ksiÄ…Å¼ki omÃ³wione zostanÄ… testy wielowymiarowe, ktÃ³re stanowiÄ… rozszerzenie klasycznych metod statystycznych na przypadki, w ktÃ³rych kaÅ¼da obserwacja opisana jest wieloma zmiennymi. SzczegÃ³lna uwaga zostanie poÅ›wiÄ™cona testowi Hotellinga TÂ², bÄ™dÄ…cemu odpowiednikiem testu t dla wielu zmiennych, oraz analizie wariancji dla wielu zmiennych (MANOVA), pozwalajÄ…cej na badanie rÃ³Å¼nic miÄ™dzy grupami z uwzglÄ™dnieniem wspÃ³Å‚zaleÅ¼noÅ›ci zmiennych. Celem tej czÄ™Å›ci bÄ™dzie zrozumienie podstaw inferencji w przestrzeni wielowymiarowej i interpretacji wynikÃ³w testÃ³w z uwzglÄ™dnieniem macierzy kowariancji.\nNastÄ™pnie przedstawiona zostanie analiza kanoniczna, ktÃ³ra sÅ‚uÅ¼y do badania zaleÅ¼noÅ›ci pomiÄ™dzy dwoma zestawami zmiennych. Czytelnik pozna konstrukcjÄ™ zmiennych kanonicznych, sposoby ich interpretacji oraz znaczenie wag i korelacji kanonicznych. Analiza ta ma kluczowe znaczenie wszÄ™dzie tam, gdzie celem jest znalezienie skorelowanych struktur w dwÃ³ch grupach cech, np. w badaniach biologicznych, spoÅ‚ecznych lub psychometrycznych.\nKolejna czÄ™Å›Ä‡ ksiÄ…Å¼ki bÄ™dzie poÅ›wiÄ™cona analizie czynnikowej (FA), ktÃ³ra umoÅ¼liwia modelowanie wspÃ³Å‚zmiennoÅ›ci zestawu zmiennych za pomocÄ… mniejszej liczby zmiennych ukrytych, zwanych czynnikami. Przedstawione zostanÄ… metody estymacji, kryteria wyboru liczby czynnikÃ³w oraz techniki rotacji, ktÃ³re sÅ‚uÅ¼Ä… lepszej interpretacji wynikÃ³w. Analiza czynnikowa jest czÄ™sto stosowana w badaniach ankietowych i psychometrycznych, ale znajduje rÃ³wnieÅ¼ zastosowanie w analizie danych ekonomicznych i marketingowych.\nW dalszej kolejnoÅ›ci wprowadzony zostanie model Å›cieÅ¼kowy oraz jego uogÃ³lnienie w postaci modeli rÃ³wnaÅ„ strukturalnych (SEM). Modele te pozwalajÄ… na modelowanie zarÃ³wno obserwowalnych, jak i ukrytych zmiennych oraz relacji przyczynowych pomiÄ™dzy nimi. Czytelnik pozna strukturÄ™ modelu Å›cieÅ¼kowego, pojÄ™cie identyfikowalnoÅ›ci, miary dopasowania oraz techniki estymacji parametrÃ³w. Modele SEM sÄ… obecnie szeroko stosowane w naukach spoÅ‚ecznych, biologii, psychologii i ekonomii.\nNastÄ™pnie omÃ³wione zostanÄ… metody redukcji wymiarowoÅ›ci, ktÃ³rych celem jest uproszczenie reprezentacji danych bez utraty istotnej informacji. KluczowÄ… technikÄ… bÄ™dzie analiza skÅ‚adowych gÅ‚Ã³wnych (PCA), ktÃ³ra pozwala na znalezienie nowych osi zmiennoÅ›ci w danych. Kolejno zaprezentowana zostanie analiza niezaleÅ¼nych skÅ‚adowych (ICA), ktÃ³ra poszukuje skÅ‚adnikÃ³w statystycznie niezaleÅ¼nych, co jest szczegÃ³lnie uÅ¼yteczne w analizie sygnaÅ‚Ã³w. Obie metody znajdÄ… zastosowanie zarÃ³wno w przygotowaniu danych, jak i w ich eksploracji.\nKolejna czÄ™Å›Ä‡ ksiÄ…Å¼ki poÅ›wiÄ™cona bÄ™dzie metodom skalowania wielowymiarowego (Multidimensional Scaling, MDS), ktÃ³re umoÅ¼liwiajÄ… odwzorowanie relacji odlegÅ‚oÅ›ciowych pomiÄ™dzy obiektami w przestrzeni o mniejszym wymiarze. Wariant metric zakÅ‚ada zachowanie rzeczywistych wartoÅ›ci odlegÅ‚oÅ›ci, natomiast non-metric koncentruje siÄ™ na porzÄ…dku dystansÃ³w. Metody te pozwalajÄ… uzyskaÄ‡ intuicyjne wizualizacje struktur danych, szczegÃ³lnie przydatne w psychologii, socjologii czy analizie rynku.\nW uzupeÅ‚nieniu do klasycznych technik przedstawione zostanÄ… nieliniowe metody redukcji wymiarowoÅ›ci, takie jak t-distributed Stochastic Neighbor Embedding (t-SNE) oraz Uniform Manifold Approximation and Projection (UMAP). Obie techniki pozwalajÄ… na odwzorowanie skomplikowanych struktur danych w przestrzeniach dwu- lub trÃ³jwymiarowych, zachowujÄ…c lokalne sÄ…siedztwa. ChoÄ‡ sÄ… to metody przede wszystkim eksploracyjne i wizualizacyjne, ich wartoÅ›Ä‡ w analizie duÅ¼ych zbiorÃ³w danych jest trudna do przecenienia.\nNastÄ™pnie przedstawiona zostanie analiza skupieÅ„, ktÃ³rej celem jest odkrywanie naturalnych grup w zbiorze danych. OmÃ³wione zostanÄ… zarÃ³wno metody hierarchiczne, jak i niehierarchiczne, w tym popularna metoda k-Å›rednich. Poruszona zostanie problematyka doboru liczby skupieÅ„ oraz oceny stabilnoÅ›ci i jakoÅ›ci otrzymanych rozwiÄ…zaÅ„. Analiza skupieÅ„ znajduje zastosowanie w segmentacji rynku, biologii molekularnej, diagnostyce medycznej i wielu innych dziedzinach.\nKolejna czÄ™Å›Ä‡ ksiÄ…Å¼ki poÅ›wiÄ™cona bÄ™dzie analizie korespondencji, stosowanej do eksploracji zwiÄ…zkÃ³w pomiÄ™dzy zmiennymi jakoÅ›ciowymi przedstawionymi w postaci tablicy kontyngencji. Przedstawiona zostanie zarÃ³wno analiza korespondencji prosta (dla dwÃ³ch zmiennych), jak i zÅ‚oÅ¼ona (dla wiÄ™cej niÅ¼ dwÃ³ch). OmÃ³wione zostanÄ… interpretacja map percepcyjnych, odwzorowanie profili oraz zwiÄ…zki z metodami takimi jak PCA czy MDS.\nOstatni rozdziaÅ‚ poÅ›wiÄ™cony bÄ™dzie analizie log-liniowej, ktÃ³ra umoÅ¼liwia modelowanie czÄ™stoÅ›ci w tablicach wielodzielczych na podstawie interakcji pomiÄ™dzy zmiennymi kategorycznymi. ZostanÄ… zaprezentowane modele peÅ‚ne i uproszczone, zasady testowania zÅ‚oÅ¼onoÅ›ci modeli oraz interpretacji parametrÃ³w. Analiza log-liniowa jest szczegÃ³lnie przydatna przy badaniu wielowymiarowych zaleÅ¼noÅ›ci miÄ™dzy zmiennymi kategorycznymi w badaniach spoÅ‚ecznych, medycznych oraz w analizie zachowaÅ„ konsumenckich.\nWszystkie metody zostanÄ… zilustrowane przykÅ‚adami praktycznymi, realizowanymi w jÄ™zyku R. Pozwoli to Czytelnikowi nie tylko zrozumieÄ‡ teoretyczne podstawy omawianych technik, ale takÅ¼e nabyÄ‡ umiejÄ™tnoÅ›Ä‡ ich stosowania w praktyce analitycznej.",
    "crumbs": [
      "WstÄ™p"
    ]
  },
  {
    "objectID": "multi_tests.html",
    "href": "multi_tests.html",
    "title": "Testy wielowymiarowe",
    "section": "",
    "text": "Test Hotellinga dla znanej macierzy kowariancji\nW tradycyjnej analizie statystycznej czÄ™sto koncentrujemy siÄ™ na porÃ³wnywaniu grup ze wzglÄ™du na jednÄ… zmiennÄ… â€“ np. porÃ³wnujemy Å›redni wzrost kobiet i mÄ™Å¼czyzn, wykorzystujÄ…c test t-Studenta. Jednak w rzeczywistoÅ›ci badawczej rzadko interesuje nas tylko jedna cecha. PrzykÅ‚adowo, porÃ³wnujÄ…c grupy pacjentÃ³w, moÅ¼emy jednoczeÅ›nie rozwaÅ¼aÄ‡ poziom ciÅ›nienia, cholesterolu i BMI. Albo, analizujÄ…c dane socjologiczne, chcemy porÃ³wnaÄ‡ grupy pod wzglÄ™dem dochodÃ³w, wyksztaÅ‚cenia i poziomu zadowolenia z Å¼ycia.\nUÅ¼ycie wielu testÃ³w jednowymiarowych wydaje siÄ™ kuszÄ…ce â€“ testujemy kaÅ¼dÄ… zmiennÄ… osobno. Jednak prowadzi to do trzech istotnych problemÃ³w:\n\\[\n\\mathbb{P}(\\text{co najmniej jeden bÅ‚Ä…d I rodzaju}) = 1 - (1 - \\alpha)^p = 1 - 0.95^{10} \\approx 0.40\n\\]\nPowyÅ¼sze problemy uzasadniajÄ… potrzebÄ™ stosowania testÃ³w wielowymiarowych â€“ uwzglÄ™dniajÄ…cych strukturÄ™ wspÃ³Å‚zmiennoÅ›ci miÄ™dzy cechami oraz pozwalajÄ…cych na testowanie hipotez dotyczÄ…cych caÅ‚ych wektorÃ³w Å›rednich.\nRozwaÅ¼my prÃ³bkÄ™ \\(\\boldsymbol{y}_1, \\boldsymbol{y}_2, \\ldots, \\boldsymbol{y}_n \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), gdzie \\(\\boldsymbol{\\Sigma}\\) jest znana. Oznacza to, Å¼e mamy do czynienia z ciÄ…giem niezaleÅ¼nych losowych wektorÃ³w \\(\\boldsymbol{y}_i\\), z ktÃ³rych kaÅ¼dy ma ten sam wielowymiarowy rozkÅ‚ad normalny o wymiarze \\(p\\), Å›redniej \\(\\boldsymbol{\\mu}\\) i macierzy kowariancji \\(\\boldsymbol{\\Sigma}\\). KaÅ¼dy wektor \\(\\boldsymbol{y}_i\\) moÅ¼na interpretowaÄ‡ jako punkt w przestrzeni \\(\\mathbb{R}^p\\), opisujÄ…cy \\(p\\) cech (zmiennych) dla jednej obserwacji. Formalnie jest to wektor kolumnowy postaci \\(\\boldsymbol{y}_i = [y_{i1}, y_{i2}, \\ldots, y_{ip}]^\\top\\), gdzie indeks \\(i\\) numeruje jednostki (np. osoby, obiekty pomiaru), a indeksy \\(j = 1, \\ldots, p\\) odpowiadajÄ… poszczegÃ³lnym zmiennym. Wektor ten traktowany jest jako zmienna losowa, poniewaÅ¼ jego wartoÅ›ci sÄ… wynikiem losowego procesu generujÄ…cego dane. RozkÅ‚ad \\(\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) jest wielowymiarowÄ… wersjÄ… rozkÅ‚adu normalnego. Opisuje on sytuacjÄ™, w ktÃ³rej kaÅ¼da kombinacja liniowa zmiennych losowych w \\(\\boldsymbol{y}_i\\) rÃ³wnieÅ¼ ma rozkÅ‚ad normalny, a funkcja gÄ™stoÅ›ci prawdopodobieÅ„stwa ma postaÄ‡ zaleÅ¼nÄ… od wartoÅ›ci wektora Å›rednich oraz struktury kowariancji. Jest to fundamentalne zaÅ‚oÅ¼enie w klasycznej analizie statystycznej, pozwalajÄ…ce na stosowanie wielu narzÄ™dzi statystycznych.\nParametr \\(\\boldsymbol{\\mu} = [\\mu_1, \\mu_2, \\ldots, \\mu_p]^\\top\\) to wektor wartoÅ›ci oczekiwanych kaÅ¼dej z analizowanych zmiennych. Oznacza on przeciÄ™tny poziom zmiennej \\(y_{ij}\\) w populacji dla kaÅ¼dej cechy \\(j\\). Jest to parametr istotny z punktu widzenia testowania hipotez, poniewaÅ¼ wiele testÃ³w statystycznych dotyczy wÅ‚aÅ›nie rÃ³wnoÅ›ci lub rÃ³Å¼nic wektorÃ³w Å›rednich miÄ™dzy grupami.\nZ kolei macierz \\(\\boldsymbol{\\Sigma}\\) to dodatnio okreÅ›lona, symetryczna macierz kowariancji o wymiarach \\(p \\times p\\). Jej elementy \\(\\sigma_{jj}\\) opisujÄ… wariancje poszczegÃ³lnych zmiennych, natomiast elementy poza gÅ‚Ã³wnÄ… przekÄ…tnÄ… \\(\\sigma_{jk}\\) (dla \\(j \\ne k\\)) opisujÄ… kowariancje, czyli wspÃ³Å‚zmiennoÅ›Ä‡ pomiÄ™dzy zmiennymi \\(y_{ij}\\) i \\(y_{ik}\\). W analizie wielowymiarowej uwzglÄ™dnienie tych zaleÅ¼noÅ›ci miÄ™dzy cechami jest kluczowe, poniewaÅ¼ pozwala lepiej zrozumieÄ‡ strukturÄ™ danych i dokonywaÄ‡ bardziej trafnych wnioskÃ³w statystycznych.\nO prÃ³bie \\(\\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_n\\) zakÅ‚adamy, Å¼e wszystkie obserwacje sÄ… niezaleÅ¼ne oraz pochodzÄ… z tego samego rozkÅ‚adu. Oznacza to, Å¼e mamy do czynienia z prÃ³bÄ… losowÄ…, niezaleÅ¼nÄ… o identycznych rozkÅ‚adach (i.i.d.), co jest podstawowym zaÅ‚oÅ¼eniem wielu testÃ³w i metod estymacji. CaÅ‚Ä… prÃ³bkÄ™ moÅ¼na przedstawiÄ‡ jako macierz danych o wymiarach \\(n \\times p\\), w ktÃ³rej wiersze odpowiadajÄ… jednostkom, a kolumny cechom.\nW przypadku, gdy macierz kowariancji \\(\\boldsymbol{\\Sigma}\\) jest znana, moÅ¼emy zastosowaÄ‡ uproszczone wersje testÃ³w statystycznych, takie jak klasyczny test Hotellinga \\(T^2\\) dla jednej prÃ³by. Jest to jednak sytuacja czysto teoretyczna, poniewaÅ¼ w praktyce \\(\\boldsymbol{\\Sigma}\\) musi byÄ‡ zazwyczaj estymowana na podstawie danych. Pomimo tego, przypadek znanej macierzy jest uÅ¼yteczny do budowania intuicji, zrozumienia rÃ³l poszczegÃ³lnych parametrÃ³w i wyprowadzania wÅ‚asnoÅ›ci statystyk testowych.\nChcemy przetestowaÄ‡ hipotezÄ™:\n\\[\nH_0: \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_0 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu} \\neq \\boldsymbol{\\mu}_0\n\\]\nStatystyka testowa opiera siÄ™ na uogÃ³lnionej odlegÅ‚oÅ›ci Mahalanobisa:\n\\[\nT^2 = n (\\bar{\\boldsymbol{y}} - \\boldsymbol{\\mu}_0)^\\top \\boldsymbol{\\Sigma}^{-1} (\\bar{\\boldsymbol{y}} - \\boldsymbol{\\mu}_0)\n\\]\nPod warunkiem speÅ‚nienia \\(H_0\\), statystyka \\(T^2 \\sim \\chi^2_p\\). Zatem moÅ¼emy porÃ³wnaÄ‡ wartoÅ›Ä‡ \\(T^2\\) z odpowiednim kwantylem rozkÅ‚adu chi-kwadrat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#zaÅ‚oÅ¼enia",
    "href": "multi_tests.html#zaÅ‚oÅ¼enia",
    "title": "Testy wielowymiarowe",
    "section": "ZaÅ‚oÅ¼enia",
    "text": "ZaÅ‚oÅ¼enia\n\nPrÃ³by sÄ… niezaleÅ¼ne;\nObserwacje w kaÅ¼dej grupie pochodzÄ… z rozkÅ‚adu wielowymiarowego normalnego;\n\nMacierze kowariancji sÄ… rÃ³wne \\(\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}\\). Jest to kluczowe zaÅ‚oÅ¼enie umoÅ¼liwiajÄ…ce zbudowanie wspÃ³lnego estymatora kowariancji i zastosowanie rozkÅ‚adu \\(T^2\\) Hotellinga. ChoÄ‡ moÅ¼e byÄ‡ ono naruszone w praktyce, to dla duÅ¼ych prÃ³b test zachowuje swoje wÅ‚aÅ›ciwoÅ›ci asymptotyczne (Rencher 1998).\n\nWektory Å›rednich z prÃ³by wyraÅ¼amy jako:\n\\[\n\\bar{\\boldsymbol{y}}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} \\boldsymbol{y}_{1,i}, \\quad\n\\bar{\\boldsymbol{y}}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} \\boldsymbol{y}_{2,i}\n\\]\nNieobciÄ…Å¼onym estymatorem macierzy kowariancji (\\(\\boldsymbol{\\Sigma}\\)) jest tzw. poÅ‚Ä…czony estymator kowariancji:\n\\[\n\\mathbf{S} =\n\\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\] gdzie \\[\n\\mathbf{S}_1 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top\n\\]\n\\[\n\\mathbf{S}_2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top\n\\]\nZatem:\n\\[\n\\mathbf{S} = \\frac{\\mathbf{W}_1 + \\mathbf{W}_2}{n_1 + n_2 - 2}\n\\] gdzie: \\[\n\\mathbf{W}_1 = \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top = (n_1 - 1)\\mathbf{S}_1\n\\]\n\\[\n\\mathbf{W}_2 = \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top = (n_2 - 1)\\mathbf{S}_2\n\\] Statystyka testowa Hotellinga wÃ³wczas ma postaÄ‡:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)\n\\]\nA gdy \\(H_0\\) jest prawdziwa, to po przeksztaÅ‚ceniu: \\[\nF = \\frac{(n_1 + n_2 - p - 1)}{p(n_1 + n_2 - 2)} T^2 \\sim F_{p, n_1 + n_2 - p - 1}\n\\]\nAlternatywnie, moÅ¼na zapisaÄ‡, Å¼e: \\[\nT^2 \\sim \\frac{p(n_1 + n_2 - 2)}{n_1 + n_2 - p - 1} F_{p, n_1 + n_2 - p - 1}\n\\]\nHipotezÄ™ zerowÄ… \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) odrzucamy na poziomie istotnoÅ›ci \\(\\alpha\\), jeÅ›li: \\[\nT^2 &gt; T^2_{\\alpha, p, n_1 + n_2 - 2}\n\\] lub rÃ³wnowaÅ¼nie: \\[\nF &gt; F_{\\alpha, p, n_1 + n_2 - p - 1}\n\\]\nAby test byÅ‚ moÅ¼liwy do przeprowadzenia, konieczne jest, aby \\(n_1 + n_2 - 2 &gt; p\\), czyli liczba stopni swobody w estymacji wspÃ³lnej kowariancji byÅ‚a wiÄ™ksza niÅ¼ wymiar przestrzeni cech.\n\n\n\n\n\n\nAdnotacja\n\n\n\nW praktyce istotne jest, aby przed zastosowaniem testu \\(T^2\\) Hotellinga dla dwÃ³ch prÃ³b zweryfikowaÄ‡ zaÅ‚oÅ¼enie o rÃ³wnoÅ›ci macierzy kowariancji â€” np. za pomocÄ… testu Boxa. Test M Boxa (ang. Boxâ€™s M test) sÅ‚uÅ¼y do statystycznej weryfikacji hipotezy rÃ³wnoÅ›ci macierzy kowariancji w wielu grupach.\nZaÅ‚Ã³Å¼my, Å¼e mamy \\(G\\) niezaleÅ¼nych prÃ³b z wielowymiarowego rozkÅ‚adu normalnego:\n\\[\n\\boldsymbol{y}_{g} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_g, \\boldsymbol{\\Sigma}_g), \\quad g = 1, \\ldots, G\n\\] Testujemy hipotezÄ™: \\[\nH_0: \\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\ldots = \\boldsymbol{\\Sigma}_G = \\boldsymbol{\\Sigma}\n\\] przeciwko alternatywie: \\[\nH_1: \\exists\\, g, h: \\boldsymbol{\\Sigma}_g \\ne \\boldsymbol{\\Sigma}_h\n\\] Niech\n\n\n\\(\\mathbf{S}_g\\) â€“ macierz kowariancji w grupie \\(g\\),\n\n\\(n_g\\) â€“ liczba obserwacji w grupie \\(g\\),\n\n\\(\\mathbf{S}_p\\) â€“ poÅ‚Ä…czony estymator macierzy kowariancji:\n\n\\[\n\\mathbf{S}_p = \\frac{1}{N - G} \\sum_{g=1}^G (n_g - 1)\\mathbf{S}_g\n\\] gdzie \\(N = \\sum_{g=1}^G n_g\\) â€“ Å‚Ä…czna liczba obserwacji. WÃ³wczas, statystyka testowa Boxa ma postaÄ‡: \\[\nM = (N - G) \\cdot \\ln|\\mathbf{S}_p| - \\sum_{g=1}^G (n_g - 1) \\cdot \\ln|\\mathbf{S}_g|\n\\] Poprawka na skoÅ„czonÄ… prÃ³bkÄ™ prowadzi do statystyki: \\[\nC = \\left(1 - c\\right) \\cdot M\n\\] gdzie: \\[\nc = \\frac{1}{3(p + 1)(G - 1)} \\left[ \\sum_{g=1}^G \\frac{1}{n_g - 1} - \\frac{1}{N - G} \\right]\n\\] Statystyka \\(C\\) jest asymptotycznie zbierzna do rozkÅ‚adu \\(\\chi^2\\left(\\frac{p}{2}(p + 1)(G - 1)\\right)\\) liczbÄ… stopni swobody.\nHipotezÄ™ \\(H_0\\) o rÃ³wnoÅ›ci macierzy kowariancji odrzuca siÄ™, jeÅ›li: \\[\nC &gt; \\chi^2_{1 - \\alpha, df}\n\\] lub gdy \\(p\\) testu jest mniejsza od poziomu istotnoÅ›ci \\(\\alpha\\).\nUwagi praktyczne\n\nTest M Boxa jest wraÅ¼liwy na odchylenia od normalnoÅ›ci â€“ jeÅ›li dane nie sÄ… zbliÅ¼one do normalnych, test moÅ¼e dawaÄ‡ mylÄ…ce wyniki.\nW duÅ¼ych prÃ³bach nawet drobne rÃ³Å¼nice miÄ™dzy macierzami kowariancji mogÄ… prowadziÄ‡ do odrzucenia \\(H_0\\), choÄ‡ nie majÄ… istotnego wpÅ‚ywu praktycznego.\nW maÅ‚ych prÃ³bach test moÅ¼e byÄ‡ niestabilny â€“ zaleca siÄ™ ostroÅ¼noÅ›Ä‡ przy interpretacji.\n\n\n\n\nPrzykÅ‚ad 4.1 (PorÃ³wnanie dwÃ³ch grup za pomocÄ… testu \\(T^2\\) Hotellinga) Â \n\nKodlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkÅ‚adu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Åšrednie z prÃ³by\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# WspÃ³lna kowariancja (poÅ‚Ä…czona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# PrzeksztaÅ‚cenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# WartoÅ›Ä‡ krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartoÅ›Ä‡\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka TÂ² = %.3f\", T2)\n\n[1] \"Statystyka TÂ² = 17.340\"\n\nKodsprintf(\"Statystyka F = %.3f\", F_stat)\n\n[1] \"Statystyka F = 8.532\"\n\nKodsprintf(\"WartoÅ›Ä‡ krytyczna F = %.3f\", F_crit)\n\n[1] \"WartoÅ›Ä‡ krytyczna F = 3.145\"\n\nKodsprintf(\"p-value = %e\", p_val)\n\n[1] \"p-value = 5.330310e-04\"\n\nKod# Wizualizacja \ndf1 &lt;- as.data.frame(Y1) %&gt;%\n  mutate(grupa = \"Grupa 1\")\n\ndf2 &lt;- as.data.frame(Y2) %&gt;%\n  mutate(grupa = \"Grupa 2\")\n\ndf_all &lt;- bind_rows(df1, df2)\ncolnames(df_all)[1:2] &lt;- c(\"X1\", \"X2\")\n\n# Ramka danych ze Å›rednimi\nmeans &lt;- data.frame(\n  X1 = c(y1_bar[1], y2_bar[1]),\n  X2 = c(y1_bar[2], y2_bar[2]),\n  grupa = c(\"Grupa 1\", \"Grupa 2\")\n)\n\n# Wykres\nggplot(df_all, aes(x = X1, y = X2, color = grupa, shape = grupa)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_point(data = means, aes(x = X1, y = X2),\n             shape = c(1, 2), size = 5, stroke = 1.2, show.legend = FALSE) +\n  scale_shape_manual(values = c(16, 17)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"PorÃ³wnanie dwÃ³ch grup\",\n       x = \"X1\", y = \"X2\", color = \"Grupa\", shape = \"Grupa\")\n\n\n\n\n\n\n\n\nKod# Alternatywnie, uÅ¼ycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)\n\n\nW analizowanym przykÅ‚adzie zdefiniowaliÅ›my macierze kowariancji identycznie ale w rzeczywistoÅ›ci naleÅ¼aÅ‚oby testowaÄ‡ hipotezÄ™ o rÃ³wnoÅ›ci macierzy kowariancji. Tylko dla celÃ³w Ä‡wiczeniowych pokaÅ¼Ä™ jak to zrobiÄ‡.\n\nKod# Test Boxa na rÃ³wnoÅ›Ä‡ macierzy kowariancji\nlibrary(biotools)\nboxM(rbind(Y1, Y2), factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  rbind(Y1, Y2)\nChi-Sq (approx.) = 2.1261, df = 3, p-value = 0.5466\n\nKod# lub z wykorzystaniem pakietu rstatix\nlibrary(rstatix)\nbox_m(df_all[,-3], df_all[,3])\n\n# A tibble: 1 Ã— 4\n  statistic p.value parameter method                                            \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                             \n1      2.13   0.547         3 Box's M-test for Homogeneity of Covariance Matricâ€¦\n\n\n\n\n\n\n\n\n\nWskazÃ³wka\n\n\n\nW sytuacji, gdy zaÅ‚oÅ¼enie o rÃ³wnoÅ›ci macierzy kowariancji jest naruszone, moÅ¼na stosowaÄ‡ alternatywne metody, takie jak:\n\nTesty permutacyjne (Hotelling::hotelling.test(Y~Group, perm = TRUE, B = 5000)).\nUogÃ³lniony test Hotellinga - test Jamesa (ang. Jamesâ€™s second-order test) lub czasami nazywany rÃ³wnieÅ¼ testem Welch-type Hotelling test (Hotelling::hotelling.test(Y~Group, var.equal = FALSE)).\nW przypadku danych charakteryzujÄ…cych siÄ™ duÅ¼Ä… liczbÄ… zmiennych w stosunku do liczby obserwacji, moÅ¼na rozwaÅ¼yÄ‡ uÅ¼ycie estymatora Jamesa-Steina do stabilizaji macierzy kowariancji (Hotelling::hotelling.test(Y~Group, shrinkage = TRUE)).\n\n\n\n\n\n\n\n\n\nAdnotacja\n\n\n\nOdrzucenie hipotezy zerowej \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) w teÅ›cie Hotellinga \\(T^2\\) oznacza, Å¼e mamy statystycznie istotny dowÃ³d na to, iÅ¼ rozkÅ‚ady Å›rednich wektorÃ³w dwÃ³ch populacji wielowymiarowych rÃ³Å¼niÄ… siÄ™, biorÄ…c pod uwagÄ™ wspÃ³Å‚zmiennoÅ›Ä‡ miÄ™dzy zmiennymi. W kontekÅ›cie zastosowaÅ„ praktycznych, oznacza to, Å¼e przynajmniej jedna zmienna (lub kombinacja zmiennych) odrÃ³Å¼nia grupy, nawet jeÅ›li nie da siÄ™ tego wykazaÄ‡ za pomocÄ… testÃ³w jednowymiarowych.\nW sytuacji, gdy mamy dane wielowymiarowe \\(\\boldsymbol{y}_{gi} \\in \\mathbb{R}^p\\) z dwÃ³ch niezaleÅ¼nych grup (\\(g = 1,2\\)), testujemy:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu}_1 \\neq \\boldsymbol{\\mu}_2.\n\\]\nOdrzucenie \\(H_0\\) sugeruje, Å¼e istnieje rÃ³Å¼nica pomiÄ™dzy Å›rednimi wektorami, ale nie musi oznaczaÄ‡, Å¼e ktÃ³rakolwiek ze Å›rednich poszczegÃ³lnych zmiennych \\(\\mu_{1j}, \\mu_{2j}\\) rÃ³Å¼ni siÄ™ istotnie â€” zwÅ‚aszcza jeÅ›li uwzglÄ™dnimy korelacje miÄ™dzy zmiennymi.\nTesty jednowymiarowe ignorujÄ… te wspÃ³Å‚zaleÅ¼noÅ›ci, dlatego mogÄ… nie wykazaÄ‡ istotnych rÃ³Å¼nic, mimo Å¼e ogÃ³lny profil wielowymiarowy siÄ™ rÃ³Å¼ni. Innymi sÅ‚owy, moÅ¼e nie istnieÄ‡ Å¼adna istotna rÃ³Å¼nica w poszczegÃ³lnych zmiennych, ale pewna kombinacja liniowa tych zmiennych pozwala na rozrÃ³Å¼nienie grup.\nRozwaÅ¼my kombinacjÄ™ liniowÄ…:\n\\[\nz = \\boldsymbol{a}^\\top \\boldsymbol{y},\n\\]\ngdzie \\(\\boldsymbol{a} \\in \\mathbb{R}^p\\) to niezerowy wektor wag. WÃ³wczas \\(z\\) jest jednowymiarowÄ… zmiennÄ… losowÄ… bÄ™dÄ…cÄ… projekcjÄ… obserwacji \\(\\boldsymbol{y}\\) na kierunek \\(\\boldsymbol{a}\\).\nJeÅ›li hipoteza \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) jest faÅ‚szywa, to istnieje taki wektor \\(\\boldsymbol{a}\\), dla ktÃ³rego:\n\\[\nH_0: \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_1 = \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_2\n\\]\nzostanie odrzucona w teÅ›cie jednowymiarowym. Dla takiej kombinacji liniowej moÅ¼emy zdefiniowaÄ‡ statystykÄ™ \\(t\\)-Studenta:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\bar{z}_1 - \\bar{z}_2}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) s_z^2}},\n\\]\ngdzie:\n\n\n\\(\\bar{z}_g = \\boldsymbol{a}^\\top \\bar{\\boldsymbol{y}}_g\\) â€“ Å›rednia z projekcji grupy \\(g\\),\n\n\\(s_z^2\\) â€“ nieobciÄ…Å¼ony estymator wariancji \\(z\\), czyli:\n\n\\[\ns_z^2 = \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a},\n\\]\na \\(\\mathbf{S}\\) to wspÃ³lna macierz kowariancji.\nStÄ…d peÅ‚na postaÄ‡ statystyki:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\boldsymbol{a}^\\top (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a}}}.\n\\]\nPoniewaÅ¼ statystyka \\(t(\\boldsymbol{a})\\) moÅ¼e byÄ‡ zarÃ³wno dodatnia, jak i ujemna, stosuje siÄ™ czÄ™sto jej kwadrat jako miarÄ™ istotnoÅ›ci:\n\\[\nT^2 = t^2(\\boldsymbol{a}).\n\\]\nStatystyka Hotellinga \\(T^2\\) przyjmuje postaÄ‡:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nJest to forma uogÃ³lnionej odlegÅ‚oÅ›ci Mahalanobisa miÄ™dzy Å›rednimi wektorami. MoÅ¼na pokazaÄ‡, Å¼e istnieje taki wektor \\(\\boldsymbol{a}\\), ktÃ³ry maksymalizuje rÃ³Å¼nicÄ™ \\(t(\\boldsymbol{a})\\) â€” to tzw. funkcja dyskryminacyjna:\n\\[\n\\boldsymbol{a} = \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nDla tej wartoÅ›ci wektora \\(\\boldsymbol{a}\\), statystyka \\(T^2\\) przyjmuje najwiÄ™kszÄ… wartoÅ›Ä‡ i jest najbardziej czuÅ‚a na rÃ³Å¼nice miÄ™dzy grupami.\nOdrzucenie \\(H_0\\) oznacza wiÄ™c, Å¼e w przestrzeni \\(\\mathbb{R}^p\\) istnieje kierunek \\(\\boldsymbol{a}\\), dla ktÃ³rego grupy majÄ… rÃ³Å¼ne Å›rednie projekcje. To otwiera drogÄ™ do:\n\nkonstrukcji funkcji dyskryminacyjnych (jak w analizie dyskryminacyjnej),\nidentyfikacji zmiennych lub ich kombinacji odpowiedzialnych za rÃ³Å¼nicÄ™,\ndalszych analiz jednowymiarowych dla projekcji \\(z = \\boldsymbol{a}^\\top \\boldsymbol{y}\\).\n\n\nKodlibrary(gridExtra)  # dla strzaÅ‚ki jako warstwy\n\nset.seed(42)\n\n# Parametry\nn1 &lt;- n2 &lt;- 100\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1.5, 0.5)\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), ncol = 2)\n\n# Dane\nY1 &lt;- mvrnorm(n1, mu1, Sigma)\nY2 &lt;- mvrnorm(n2, mu2, Sigma)\n\n# Åšrednie\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymacja wspÃ³lnej kowariancji\nS_pooled &lt;- ((n1 - 1) * cov(Y1) + (n2 - 1) * cov(Y2)) / (n1 + n2 - 2)\n\n# Kierunek dyskryminacyjny a\ndiff &lt;- y1_bar - y2_bar\na &lt;- solve(S_pooled, diff)\na_norm &lt;- a / sqrt(sum(a^2))  # normalizacja\n\n# Punkt startowy strzaÅ‚ki (Å›rodek miÄ™dzy Å›rednimi)\norigin &lt;- (y1_bar + y2_bar) / 2\nscale &lt;- 3  # dÅ‚ugoÅ›Ä‡ strzaÅ‚ki\narrow_end &lt;- origin + scale * a_norm\n\n# Ramka danych do wykresu\ndf &lt;- rbind(\n  data.frame(X1 = Y1[,1], X2 = Y1[,2], Grupa = \"Grupa 1\"),\n  data.frame(X1 = Y2[,1], X2 = Y2[,2], Grupa = \"Grupa 2\")\n)\n\n# Wektory Å›rednich i strzaÅ‚ka\nmeans_df &lt;- data.frame(rbind(y1_bar, y2_bar))\ncolnames(means_df) &lt;- c(\"X1\", \"X2\")\nmeans_df$Grupa &lt;- c(\"Grupa 1\", \"Grupa 2\")  # te same etykiety co w danych punktÃ³w\n\narrow_df &lt;- data.frame(\n  x = origin[1],\n  y = origin[2],\n  xend = arrow_end[1],\n  yend = arrow_end[2]\n)\n\n# Wykres\nggplot(df, aes(x = X1, y = X2, color = Grupa)) +\n  geom_point(alpha = 0.5) +\n  geom_point(data = means_df, aes(x = X1, y = X2),\n             size = 4, shape = 16, show.legend = FALSE) +  # Å›rednie tym samym kolorem; bez legendy\n  geom_segment(data = arrow_df, \n               aes(x = x, y = y, xend = xend, yend = yend),\n               arrow = arrow(length = unit(0.25, \"cm\")), color = \"black\", size = 1, show.legend = FALSE) +\n  labs(\n    title = latex2exp::TeX(r\"(Ilustracja kierunku dyskryminacyjnego $a = S^{-1} (\\bar{y}_1 - \\bar{y}_2)$)\"),\n    x = latex2exp::TeX(r\"($X_1$)\"),\n    y = latex2exp::TeX(r\"($X_2$)\")\n  ) +\n  coord_equal() +\n  theme_minimal() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#zaÅ‚oÅ¼enia-i-testowane-hipotezy",
    "href": "multi_tests.html#zaÅ‚oÅ¼enia-i-testowane-hipotezy",
    "title": "Testy wielowymiarowe",
    "section": "ZaÅ‚oÅ¼enia i testowane hipotezy",
    "text": "ZaÅ‚oÅ¼enia i testowane hipotezy\nZakÅ‚ada siÄ™, Å¼e obserwacje sÄ… niezaleÅ¼ne i pochodzÄ… z wielowymiarowego rozkÅ‚adu normalnego w kaÅ¼dej grupie, tj.:\n\\[\n\\boldsymbol{y}_{ij} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}), \\quad i = 1, \\dots, g,\\ j = 1, \\dots, n_i,\n\\]\ngdzie:\n\n\n\\(\\boldsymbol{y}_{ij} \\in \\mathbb{R}^p\\) â€” wektor obserwacji w grupie \\(i\\),\n\n\\(\\boldsymbol{\\mu}_i\\) â€” wektor Å›rednich dla grupy \\(i\\),\n\n\\(\\boldsymbol{\\Sigma}\\) â€” wspÃ³lna macierz kowariancji we wszystkich grupach (zaÅ‚oÅ¼enie homogenicznoÅ›ci).\n\nTestowana jest hipoteza zerowa:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = \\dots = \\boldsymbol{\\mu}_g\n\\]\nwobec alternatywy:\n\\[\nH_1: \\exists\\ i,j\\ \\text{takie, Å¼e}\\ \\boldsymbol{\\mu}_i \\ne \\boldsymbol{\\mu}_j.\n\\]\nModel MANOVA opiera siÄ™ na kilku fundamentalnych zaÅ‚oÅ¼eniach dotyczÄ…cych danych, ktÃ³rych speÅ‚nienie warunkuje poprawnoÅ›Ä‡ i wiarygodnoÅ›Ä‡ uzyskanych wynikÃ³w. Ich naruszenie moÅ¼e prowadziÄ‡ do faÅ‚szywych wnioskÃ³w, zbyt duÅ¼ej liczby odrzuceÅ„ hipotezy zerowej lub do bÅ‚Ä™dnych ocen efektÃ³w czynnikÃ³w. PoniÅ¼ej przedstawiono szczegÃ³Å‚owo kaÅ¼de z tych zaÅ‚oÅ¼eÅ„.\n\nPierwszym kluczowym zaÅ‚oÅ¼eniem jest odpowiednia wielkoÅ›Ä‡ prÃ³by. Przyjmuje siÄ™, Å¼e liczba obserwacji w kaÅ¼dej grupie (komÃ³rce) powinna przekraczaÄ‡ liczbÄ™ zmiennych zaleÅ¼nych, ktÃ³re sÄ… jednoczeÅ›nie analizowane. To praktyczne zalecenie pozwala uniknÄ…Ä‡ problemÃ³w z oszacowaniem macierzy kowariancji i zapewnia dostatecznÄ… moc statystycznÄ….\nKolejnym istotnym zaÅ‚oÅ¼eniem jest niezaleÅ¼noÅ›Ä‡ obserwacji. Oznacza to, Å¼e kaÅ¼da jednostka obserwacyjna (np. osoba) powinna przynaleÅ¼eÄ‡ wyÅ‚Ä…cznie do jednej grupy. Obserwacje wewnÄ…trz i pomiÄ™dzy grupami nie mogÄ… byÄ‡ ze sobÄ… powiÄ…zane. W szczegÃ³lnoÅ›ci, model MANOVA nie jest odpowiedni dla danych z pomiarami powtarzanymi u tych samych obiektÃ³w. DobÃ³r prÃ³by powinien byÄ‡ dokonany w sposÃ³b losowy, bez systematycznych zaleÅ¼noÅ›ci.\nTrzecim wymogiem jest brak obserwacji odstajÄ…cych, zarÃ³wno w sensie jednowymiarowym (dla kaÅ¼dej zmiennej z osobna), jak i wielowymiarowym (dla kombinacji wszystkich zmiennych zaleÅ¼nych). Obserwacje odstajÄ…ce mogÄ… silnie znieksztaÅ‚caÄ‡ wartoÅ›ci Å›rednich i macierzy kowariancji, przez co wyniki MANOVA stajÄ… siÄ™ niestabilne.\nFundamentalnym zaÅ‚oÅ¼eniem MANOVA jest wielowymiarowa normalnoÅ›Ä‡ rozkÅ‚adu danych w kaÅ¼dej z grup. Oznacza to, Å¼e wektor zmiennych zaleÅ¼nych w kaÅ¼dej grupie powinien mieÄ‡ rozkÅ‚ad wielowymiarowy normalny. W R moÅ¼na zastosowaÄ‡ funkcjÄ™ mshapiro_test() z pakietu rstatix, aby przeprowadziÄ‡ test Shapiroâ€“Wilka dla sprawdzenia normalnoÅ›ci wielowymiarowej.\nKolejne zaÅ‚oÅ¼enie dotyczy braku wspÃ³Å‚liniowoÅ›ci. Oczekuje siÄ™, Å¼e zmienne zaleÅ¼ne bÄ™dÄ… ze sobÄ… skorelowane w umiarkowany sposÃ³b, ale nie nadmiernie. WartoÅ›ci wspÃ³Å‚czynnikÃ³w korelacji przekraczajÄ…ce \\(r = 0,90\\) sÄ… uznawane za niepoÅ¼Ä…dane i mogÄ… powodowaÄ‡ problemy numeryczne oraz bÅ‚Ä™dnÄ… interpretacjÄ™ wynikÃ³w. Jak podajÄ… Tabachnick i Fidell (2012), zmienne powinny wnosiÄ‡ unikalne informacje do modelu.\nWaÅ¼nym wymogiem jest rÃ³wnieÅ¼ liniowoÅ›Ä‡ zaleÅ¼noÅ›ci miÄ™dzy zmiennymi zaleÅ¼nymi w kaÅ¼dej grupie. Oznacza to, Å¼e zaleÅ¼noÅ›ci pomiÄ™dzy kaÅ¼dÄ… parÄ… zmiennych muszÄ… byÄ‡ dobrze opisane przez funkcjÄ™ liniowÄ… â€” jest to konieczne, aby poprawnie oszacowaÄ‡ strukturÄ™ kowariancji.\nDla poprawnego dziaÅ‚ania MANOVA zakÅ‚ada siÄ™ takÅ¼e jednorodnoÅ›Ä‡ wariancji dla kaÅ¼dej zmiennej zaleÅ¼nej miÄ™dzy grupami. MoÅ¼na to testowaÄ‡ za pomocÄ… testu Leveneâ€™a. Nieistotny wynik testu Leveneâ€™a sugeruje, Å¼e wariancje sÄ… porÃ³wnywalne w grupach.\nOstatnie, ale bardzo istotne, jest zaÅ‚oÅ¼enie o jednorodnoÅ›ci macierzy kowariancji (homogenicznoÅ›ci macierzy wariancjiâ€“kowariancji) pomiÄ™dzy grupami. Oznacza to, Å¼e struktura wspÃ³Å‚zaleÅ¼noÅ›ci miÄ™dzy zmiennymi powinna byÄ‡ podobna w kaÅ¼dej grupie. WeryfikacjÄ™ tego zaÅ‚oÅ¼enia umoÅ¼liwia test Boxa (Boxâ€™s M test), ktÃ³ry stanowi wielowymiarowy odpowiednik testu Leveneâ€™a. Ze wzglÄ™du na duÅ¼Ä… czuÅ‚oÅ›Ä‡ testu Boxa na odstÄ™pstwa od zaÅ‚oÅ¼eÅ„, przyjmuje siÄ™ konserwatywny poziom istotnoÅ›ci \\(\\alpha = 0,001\\) dla weryfikacji jego wyniku.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#konstrukcja-modelu-i-statystyki-testowe",
    "href": "multi_tests.html#konstrukcja-modelu-i-statystyki-testowe",
    "title": "Testy wielowymiarowe",
    "section": "Konstrukcja modelu i statystyki testowe",
    "text": "Konstrukcja modelu i statystyki testowe\nPodobnie jak w jednowymiarowym przypadku, w MANOVA analizuje siÄ™ rozkÅ‚ad wariancji caÅ‚kowitej na wariancjÄ™ miÄ™dzygrupowÄ… i wewnÄ…trzgrupowÄ…, ale w postaci macierzy kowariancji:\n\nMacierz wariancji miÄ™dzygrupowej (ang. between-group SSCP):\n\n\\[\n\\mathbf{B} = \\sum_{i=1}^{g} n_i (\\bar{\\boldsymbol{y}}_i - \\bar{\\boldsymbol{y}})(\\bar{\\boldsymbol{y}}_i - \\bar{\\boldsymbol{y}})^\\top\n\\]\n\nMacierz wariancji wewnÄ…trzgrupowej (ang. within-group SSCP):\n\n\\[\n\\mathbf{W} = \\sum_{i=1}^{g} \\sum_{j=1}^{n_i} (\\boldsymbol{y}_{ij} - \\bar{\\boldsymbol{y}}_i)(\\boldsymbol{y}_{ij} - \\bar{\\boldsymbol{y}}_i)^\\top\n\\]\nMacierz wariancji caÅ‚kowitej to: \\(\\mathbf{T} = \\mathbf{B} + \\mathbf{W}\\).\nW celu przeprowadzenia testu MANOVA, wykorzystuje siÄ™ statystyki oparte na stosunku macierzy:\n\\[\n\\mathbf{W}^{-1} \\mathbf{B}\n\\]\nNajczÄ™Å›ciej spotykane statystyki testowe to:\n\nWilksâ€™ Lambda:\n\n\\[\n\\Lambda = \\frac{\\det(\\mathbf{W})}{\\det(\\mathbf{B} + \\mathbf{W})}\n\\]\n\nStatystyka Pillai-Bartletta (Trace):\n\n\\[\nV = \\mathrm{tr}\\left[(\\mathbf{B} + \\mathbf{W})^{-1} \\mathbf{B}\\right]\n\\]\n\nStatystyka Hotellingaâ€“Lawleya (Trace):\n\n\\[\nT = \\mathrm{tr}(\\mathbf{W}^{-1} \\mathbf{B})\n\\]\n\nNajwiÄ™kszy pierwiastek Royâ€™a:\n\n\\[\n\\theta_{\\text{max}} = \\text{najwiÄ™ksza wartoÅ›Ä‡ wÅ‚asna}\\ (\\mathbf{W}^{-1} \\mathbf{B})\n\\]\nWybÃ³r konkretnej statystyki zaleÅ¼y od liczebnoÅ›ci prÃ³b, wymiaru przestrzeni i liczby grup. W praktyce Wilksâ€™ Lambda jest najczÄ™Å›ciej stosowana.\n\nPrzykÅ‚ad 5.1 Na poziomie istotnoÅ›ci \\(\\alpha=0.05\\) zweryfikuj hipotezÄ™, Å¼e czynnik grupujÄ…cy (Group) istotnie rÃ³Å¼nicuje zmienne Actions i Thoughts jednoczeÅ›nie.\n\nKodlibrary(gtsummary)\nlibrary(rstatix)\nlibrary(easystats)\nlibrary(gt)\ndane &lt;- rio::import(\"data/OCD.dat\")\n\n\nStatystyki opisowe grup\n\nKoddane %&gt;% \n  tbl_summary(by = Group,\n              statistic = list(where(is.numeric) ~ \"{mean} ({sd})\"),\n              type = list(Actions ~ \"continuous\"),\n              digits = list(everything() ~ 2))\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nBT\nN = 101\n\n\nCBT\nN = 101\n\n\nNo Treatment Control\nN = 101\n\n\n\n\nActions\n3.70 (1.77)\n4.90 (1.20)\n5.00 (1.05)\n\n\nThoughts\n15.20 (2.10)\n13.40 (1.90)\n15.00 (2.36)\n\n\n\n\n1 Mean (SD)\n\n\n\n\nKodp &lt;- dane %&gt;% \n  select(-Group) %&gt;% \n  correlation()\n\np %&gt;% print_html()\n\n\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\nParameter1\nParameter2\nr\n95% CI\nt(28)\np\n\n\n\nActions\nThoughts\n0.06\n(-0.31, 0.41)\n0.31\n0.758\n\n\np-value adjustment method: Holm (1979); Observations: 30\n\n\n\n\n\nW kontekÅ›cie zmiennej Actions widzimy najwyÅ¼szy poziom w grupie No treatment, natomiast najniÅ¼szy w grupie BT. Dla zmiennej Thoughts najwyÅ¼szy poziom osiÄ…gniÄ™to w grupie BT a najniÅ¼szy w grupie CBT. Grupy rÃ³Å¼niÄ… siÄ™ rÃ³wnieÅ¼ zmiennoÅ›ciÄ… obu cech. ZwiÄ…zek pomiÄ™dzy zmiennymi Actions i Thoughts jest niemal niezauwaÅ¼alny. Korelacja pomiÄ™dzy tymi cechami jest nieistotnie rÃ³Å¼na od zera.\n\nKoddane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  ggplot(aes(x = Group, y = value, fill = name)) +\n  geom_boxplot() +\n  geom_jitter() +\n  labs(fill = \"Variable\", y = \"Response\") +\n  theme_minimal()\n\n\n\n\n\n\n\nPowyÅ¼sze wykresy potwierdzajÄ… znaczne rÃ³Å¼nice pomiÄ™dzy grupami w kontekÅ›cie analizowanych cech.\nZaÅ‚oÅ¼enia\n\nKoddane %&gt;% \n  group_split(Group) %&gt;% \n  map_df(~mshapiro_test(.x[,2:3])) %&gt;% \n  mutate(Group = dane %&gt;% \n           group_keys(Group) %&gt;% \n           pull(Group),\n         .before = statistic) %&gt;%\n  gt() %&gt;% \n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nstatistic\np.value\n\n\n\nBT\n0.891\n0.175\n\n\nCBT\n0.959\n0.777\n\n\nNo Treatment Control\n0.826\n0.030\n\n\n\n\n\n\nJedynie w grupie No treatment nie jest zachowana wielowymiarowa normalnoÅ›Ä‡ rozkÅ‚adu analizowanych cech. MoÅ¼na teÅ¼ przeprowadziÄ‡ testy normalnoÅ›ci poszczegÃ³lnych zmiennych, ale naleÅ¼y pamiÄ™taÄ‡, Å¼e brak podstaw do odrzucenia hipotezy o normalnoÅ›ci brzegowych zmiennych nie jest warunkiem dostatecznym, a jedynie koniecznym.\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  shapiro_test(Actions) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nvariable\nstatistic\np\n\n\n\nBT\nActions\n0.872\n0.106\n\n\nCBT\nActions\n0.952\n0.691\n\n\nNo Treatment Control\nActions\n0.859\n0.074\n\n\n\n\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  shapiro_test(Thoughts) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nvariable\nstatistic\np\n\n\n\nBT\nThoughts\n0.877\n0.120\n\n\nCBT\nThoughts\n0.914\n0.310\n\n\nNo Treatment Control\nThoughts\n0.826\n0.030\n\n\n\n\n\n\nPodobnie jak w przypadku wielowymiarowym brak normalnoÅ›ci zarysowaÅ‚ siÄ™ w grupie No treatment i to tylko dla zmiennej Thoughts. Teraz przechodzimy do testowania jednorodnoÅ›ci kowariancji.\n\nKodbox_m(dane[,2:3], dane$Group)  %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n8.893\n0.180\n6.000\nBox's M-test for Homogeneity of Covariance Matrices\n\n\n\n\n\nNa podstawie powyÅ¼szego testu moÅ¼na stwierdziÄ‡, iÅ¼ nie ma podstaw do odrzucenia hipotezy o jednorodnoÅ›ci macierzy kowariancji.\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  identify_outliers(Actions) \n\n[1] Group      Actions    Thoughts   is.outlier is.extreme\n&lt;0 rows&gt; (or 0-length row.names)\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  identify_outliers(Thoughts) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nActions\nThoughts\nis.outlier\nis.extreme\n\n\nNo Treatment Control\n4\n20\nTRUE\nFALSE\n\n\n\n\nKodwhich(dane$Actions == 4 & dane$Thoughts == 20)\n\n[1] 26\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  mahalanobis_distance() %&gt;% \n  filter(is.outlier==TRUE)\n\n# A tibble: 0 Ã— 4\n# â„¹ 4 variables: Actions &lt;int&gt;, Thoughts &lt;int&gt;, mahal.dist &lt;dbl&gt;,\n#   is.outlier &lt;lgl&gt;\n\n\nIstnieje jedna obserwacja odstajÄ…ca w grupie No treatment (obserwacja nr 26). Test wielowymiarowy nie wykryÅ‚ Å¼adnego elementu odstajÄ…cego.\nPomimo niespeÅ‚nienia zaÅ‚oÅ¼enia o wielowymiarowej normalnoÅ›ci cech w grupach, zastosujemy test MANOVA.\nManova\n\nKodmod &lt;- manova(cbind(Actions, Thoughts)~Group, data = dane)\nManova(mod) %&gt;% \n  parameters() %&gt;%\n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.32\n4\n54\n2.56\n0.049\n\n\nPillai test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Wilk\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.70\n4\n52\n2.55\n0.050\n\n\nWilks test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Roy\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.33\n2\n27\n4.52\n0.020\n\n\nRoy test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Hotelling\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.41\n4\n50\n2.55\n0.051\n\n\nHotelling-Lawley test statistic Anova Table (Type 2 tests)\n\n\n\n\nKod# model bez obserawcji odstajÄ…cej\nmod2 &lt;- manova(cbind(Actions, Thoughts)~Group, data = dane[-26,])\nManova(mod2) %&gt;% \n  parameters() %&gt;%\n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.36\n4\n52\n2.87\n0.032\n\n\nPillai test statistic Anova Table (Type 2 tests)\n\n\n\n\n\nAnalizujÄ… wszystkie rodzaje testÃ³w Manova, widzimy, Å¼e jedynie test Hotellinga-Laweya nie daje podstaw do odrzucenia hipotezy o rÃ³wnoÅ›ci wektorÃ³w Å›rednich. Natomiast poniewaÅ¼ co najmniej jeden z nich wskazaÅ‚ istotnoÅ›Ä‡ rÃ³Å¼nic, to przyjmujemy, Å¼e sÄ… podstawy aby odrzuciÄ‡ hipotezÄ™ o rÃ³wnoÅ›ci wektorÃ³w Å›rednich pomiÄ™dzy grupami. Test wykluczajÄ…cy obserwacjÄ™ odstajÄ…cÄ… rÃ³wnieÅ¼ kaÅ¼e odrzuciÄ‡ hipotezÄ™ \\(H_0\\).\nPrzeprowadzimy zatem analizÄ™ brzegowÄ….\n\nKoddane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  group_by(name) %&gt;% \n  anova_test(value~Group) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nname\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\nActions\nGroup\n2.000\n27.000\n2.771\n0.080\n\n0.170\n\n\nThoughts\nGroup\n2.000\n27.000\n2.154\n0.136\n\n0.138\n\n\n\n\n\n\nAnaliza brzegowa pokazuje ciekawy wynik, mianowicie, dla Å¼adnej z analizowanych cech testy brzegowe nie wykazaÅ‚y istotnych rÃ³Å¼nic. To pokazuje jak waÅ¼ne jest stosowanie testÃ³w wielowymiarowych w kontekÅ›cie porÃ³wnaÅ„ grup.\nPost-hoc\nPoniewaÅ¼ testy brzegowe ANOVA nie wykazaÅ‚y rÃ³Å¼nic, to testÃ³w post-hoc nie powinno siÄ™ wykonywaÄ‡, ale dla celÃ³w Ä‡wiczeniowych pokaÅ¼Ä™ jak je wykonaÄ‡.\n\nKodpwc &lt;- dane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  group_by(name) %&gt;% \n  games_howell_test(value~Group)\npwc %&gt;% \n  select(-.y.) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nname\ngroup1\ngroup2\nestimate\nconf.low\nconf.high\np.adj\np.adj.signif\n\n\n\nActions\nBT\nCBT\n1.200\nâˆ’0.544\n2.944\n0.209\nns\n\n\nActions\nBT\nNo Treatment Control\n1.300\nâˆ’0.394\n2.994\n0.148\nns\n\n\nActions\nCBT\nNo Treatment Control\n0.100\nâˆ’1.189\n1.389\n0.979\nns\n\n\nThoughts\nBT\nCBT\nâˆ’1.800\nâˆ’4.085\n0.485\n0.138\nns\n\n\nThoughts\nBT\nNo Treatment Control\nâˆ’0.200\nâˆ’2.749\n2.349\n0.978\nns\n\n\nThoughts\nCBT\nNo Treatment Control\n1.600\nâˆ’0.852\n4.052\n0.244\nns\n\n\n\n\n\n\nTesty post-hoc potwierdzajÄ… wyniki testÃ³w brzegowych ANOVA, poniewaÅ¼ brakuje rÃ³Å¼nic pomiÄ™dzy poziomami zmiennych grupujÄ…cych.\n\n\n\n\n\nRencher, Alvin C. 1998. Multivariate statistical inference and applications. T. 635. Wiley New York.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Rencher, Alvin C. 1998. Multivariate Statistical Inference and\nApplications. Vol. 635. Wiley New York.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "cca.html",
    "href": "cca.html",
    "title": "Analiza kanoniczna",
    "section": "",
    "text": "Przypomnienie z algebry ğŸ˜‰\nAnaliza kanoniczna (ang. Canonical Correlation Analysis, CCA) jest klasycznÄ… technikÄ… statystycznÄ… sÅ‚uÅ¼Ä…cÄ… do badania zwiÄ…zkÃ³w pomiÄ™dzy dwoma zestawami zmiennych wielowymiarowych. Jej podstawowym celem jest znalezienie takich kombinacji liniowych zmiennych z obu zestawÃ³w, ktÃ³re maksymalizujÄ… wzajemnÄ… korelacjÄ™ â€“ sÄ… to tzw. kanoniczne zmienne lub kanoniczne skÅ‚adniki. Technika ta zostaÅ‚a wprowadzona przez Harolda Hotellinga w roku 1936, a wiÄ™c w okresie intensywnego rozwoju metod statystycznych opartych na algebrze macierzy.\nW tym samym czasie powstawaÅ‚y takÅ¼e inne fundamenty analizy wielowymiarowej, takie jak analiza skÅ‚adowych gÅ‚Ã³wnych (PCA) czy dyskryminacja liniowa (LDA)1. Analiza kanoniczna stanowi zatem jeden z filarÃ³w klasycznej statystyki wielowymiarowej i do dziÅ› pozostaje istotnym narzÄ™dziem eksploracji i modelowania zÅ‚oÅ¼onych zaleÅ¼noÅ›ci.\nW odrÃ³Å¼nieniu od regresji wielorakiej, ktÃ³ra przewiduje zestaw zmiennych zaleÅ¼nych na podstawie zestawu predyktorÃ³w, analiza kanoniczna traktuje obie grupy zmiennych symetrycznie â€“ nie zakÅ‚ada istnienia wyraÅºnego kierunku przyczynowego. Dlatego stosuje siÄ™ jÄ… w sytuacjach, gdy celem jest ogÃ³lna analiza wspÃ³Å‚zaleÅ¼noÅ›ci pomiÄ™dzy dwoma zbiorami zmiennych, a nie przewidywanie jednego zestawu na podstawie drugiego.\nTypowe zastosowania analizy kanonicznej obejmujÄ…:\nNa potrzeby definicji modeli kanonicznego potrzebne bÄ™dÄ… nam pewne twierdzenia z zakresu algebry.\nOto matematyczna definicja modelu CCA oraz dowÃ³d istnienia rozwiÄ…zania, sformuÅ‚owana Å›ciÅ›le w duchu Twojego tekstu:",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#sformuÅ‚owanie-problemu-wÅ‚asnego",
    "href": "cca.html#sformuÅ‚owanie-problemu-wÅ‚asnego",
    "title": "Analiza kanoniczna",
    "section": "SformuÅ‚owanie problemu wÅ‚asnego",
    "text": "SformuÅ‚owanie problemu wÅ‚asnego\nPrzeksztaÅ‚Ä‡my zmienne \\[\nc=\\Sigma_{XX}^{1/2}a,\\quad d=\\Sigma_{YY}^{1/2}b.\n\\]\nWÃ³wczas \\[\n\\rho(a,b)=\\frac{c^\\top\\Sigma_{XX}^{-1/2}\\Sigma_{XY}\\Sigma_{YY}^{-1/2}d}{\\sqrt{c^\\top c}\\sqrt{d^\\top d}}.\n\\]\nZ lematu Cauchyâ€™egoâ€“Buniakowskiegoâ€“Schwarza mamy \\[\n\\left|c^\\top \\mathbf{M} d\\right| \\le\n\\bigl(c^\\top \\mathbf{M}\\mathbf{M}^\\top c\\bigr)^{1/2}\\bigl(d^\\top d\\bigr)^{1/2},\n\\quad \\text{gdzie }\\mathbf{M}=\\Sigma_{XX}^{-1/2}\\Sigma_{XY}\\Sigma_{YY}^{-1/2}.\n\\tag{5.1}\\]\nZatem \\[\n\\rho(a,b)^2 \\le\n\\frac{c^\\top\\mathbf{M}\\mathbf{M}^\\top c}{c^\\top c}.\n\\]\nPoniewaÅ¼ \\(\\mathbf{M}\\mathbf{M}^\\top=\\Sigma_{XX}^{-1/2}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma_{YX}\\Sigma_{XX}^{-1/2}\\) jest macierzÄ… symetrycznÄ… dodatnio okreÅ›lonÄ…, z lematu Rayleighaâ€“Ritza otrzymujemy \\[\n\\max_{c\\neq 0}\\frac{c^\\top\\mathbf{M}\\mathbf{M}^\\top c}{c^\\top c}=\\lambda_1,\n\\] gdzie \\(\\lambda_1\\) to najwiÄ™ksza wartoÅ›Ä‡ wÅ‚asna tej macierzy, osiÄ…gana dla \\(c=e_1\\) â€“ jej wektora wÅ‚asnego.\nJeÅ›li \\[\nd \\propto \\Sigma_{YY}^{-1/2}\\Sigma_{YX}\\Sigma_{XX}^{-1/2}e_1\n\\] to RÃ³wnanieÂ 5.1 staje siÄ™ rÃ³wnoÅ›ciÄ….\nWracajÄ…c do oryginalnych wspÃ³Å‚czynnikÃ³w \\[\na_1=\\Sigma_{XX}^{-1/2}e_1,\\quad\nb_1\\propto \\Sigma_{YY}^{-1/2}\\Sigma_{YX}\\Sigma_{XX}^{-1/2}e_1.\n\\]\nPierwsza korelacja kanoniczna wynosi wÃ³wczas \\[\n\\rho_1=\\sqrt{\\lambda_1}.\n\\]\nAnalogicznie dla kolejnych par, przy zaÅ‚oÅ¼eniu \\(c\\perp e_1,\\dots,e_{k-1}\\), mamy \\[\n\\rho_k=\\sqrt{\\lambda_k},\n\\] gdzie \\(\\lambda_k\\) to kolejne wartoÅ›ci wÅ‚asne macierzy \\(\\Sigma_{XX}^{-1/2}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma_{YX}\\Sigma_{XX}^{-1/2}\\), a odpowiadajÄ…ce im wektory wÅ‚asne \\(e_k\\) definiujÄ… kolejne wektory kanoniczne \\[\nU_k=e_k^\\top\\Sigma_{XX}^{-1/2}X,\\quad\nV_k=f_k^\\top\\Sigma_{YY}^{-1/2}Y,\\quad\nf_k\\propto \\Sigma_{YY}^{-1/2}\\Sigma_{YX}\\Sigma_{XX}^{-1/2}e_k.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#wÅ‚asnoÅ›ci-rozwiÄ…zaÅ„",
    "href": "cca.html#wÅ‚asnoÅ›ci-rozwiÄ…zaÅ„",
    "title": "Analiza kanoniczna",
    "section": "WÅ‚asnoÅ›ci rozwiÄ…zaÅ„",
    "text": "WÅ‚asnoÅ›ci rozwiÄ…zaÅ„\nDla kaÅ¼dej pary \\((U_k,V_k)\\) zachodzi \\[\n\\mathrm{Var}(U_k)=\\mathrm{Var}(V_k)=1,\\quad\n\\mathrm{Cov}(U_k,U_l)=\\mathrm{Cov}(V_k,V_l)=\\mathrm{Cov}(U_k,V_l)=0\\quad (k\\neq l).\n\\]\n\n\n\n\n\n\nDowÃ³d powyÅ¼szych rÃ³wnoÅ›ci\n\n\n\nDla danej pary wektorÃ³w kanonicznych mamy\n\\[\nU_k = a_k^\\top X = e_k^\\top \\Sigma_{XX}^{-1/2} X,\n    \\qquad\n    V_k = b_k^\\top Y = f_k^\\top \\Sigma_{YY}^{-1/2} Y,\n\\] gdzie:\n\n\n\\(e_k\\) jest ortonormalnym6 wektorem wÅ‚asnym macierzy \\(\\Sigma_{XX}^{-1/2} \\Sigma_{XY} \\Sigma_{YY}^{-1} \\Sigma_{YX} \\Sigma_{XX}^{-1/2}\\)\n\n\n\\(f_k \\propto \\Sigma_{YY}^{-1/2} \\Sigma_{YX} \\Sigma_{XX}^{-1/2} e_k\\),\n\n\\(\\rho_k = \\sqrt{\\lambda_k}\\), gdzie \\(\\lambda_k\\) to odpowiadajÄ…ca wartoÅ›Ä‡ wÅ‚asna.\n\nMacierze \\(\\Sigma_{XX}\\), \\(\\Sigma_{YY}\\) sÄ… dodatnio okreÅ›lone, wiÄ™c moÅ¼na wprowadziÄ‡ transformacje \\[\n\\tilde{X} = \\Sigma_{XX}^{-1/2}X, \\quad \\tilde{Y} = \\Sigma_{YY}^{-1/2}Y.\n\\] Zatem \\[\nU_k = e_k^\\top \\tilde{X},\\quad V_k = f_k^\\top \\tilde{Y}.\n\\]\nNajpierw udowodnimy, Å¼e \\(\\operatorname{Var}(U_k) = \\operatorname{Var}(V_k) = 1\\).\nZmienna \\(U_k = e_k^\\top \\tilde{X}\\), wiÄ™c \\[\n\\operatorname{Var}(U_k) = \\operatorname{Var}(e_k^\\top \\tilde{X}) = e_k^\\top \\operatorname{Var}(\\tilde{X}) e_k.\n\\] ZauwaÅ¼my, Å¼e \\[\n\\operatorname{Var}(\\tilde{X}) = \\Sigma_{XX}^{-1/2} \\Sigma_{XX} \\Sigma_{XX}^{-1/2} = I,\n\\] wiÄ™c \\[\n\\operatorname{Var}(U_k) = e_k^\\top I e_k = e_k^\\top e_k = 1.\n\\] Analogicznie \\[\n\\operatorname{Var}(V_k) = f_k^\\top \\operatorname{Var}(\\tilde{Y}) f_k = f_k^\\top f_k = 1,\n\\] poniewaÅ¼ \\(\\tilde{Y}\\) ma jednostkowÄ… macierz kowariancji, a \\(f_k\\) sÄ… znormalizowane.\nTeraz dowiedziemy, Å¼e \\(\\operatorname{Cov}(U_k, U_l) = 0\\) dla \\(k \\neq l\\)\n\\[\n\\operatorname{Cov}(U_k, U_l) = \\operatorname{Cov}(e_k^\\top \\tilde{X}, e_l^\\top \\tilde{X}) = e_k^\\top \\operatorname{Var}(\\tilde{X}) e_l = e_k^\\top e_l.\n\\] PoniewaÅ¼ \\(e_k\\), \\(e_l\\) sÄ… ortonormalnymi wektorami wÅ‚asnymi symetrycznej macierzy, to \\[\ne_k^\\top e_l = 0 \\quad \\text{dla } k \\neq l.\n\\] Zatem \\[\n\\operatorname{Cov}(U_k, U_l) = 0.\n\\] Podobnie \\[\n\\operatorname{Cov}(V_k, V_l) = f_k^\\top f_l = 0 \\quad \\text{dla } k \\neq l.\n\\]\nNa koniec dowiedÅºmy, Å¼e \\(\\operatorname{Cov}(U_k, V_l) = 0\\) dla \\(k \\neq l\\) \\[\n\\operatorname{Cov}(U_k, V_l) = \\operatorname{Cov}(e_k^\\top \\tilde{X}, f_l^\\top \\tilde{Y}) = e_k^\\top \\operatorname{Cov}(\\tilde{X}, \\tilde{Y}) f_l.\n\\] Z definicji \\[\n\\operatorname{Cov}(\\tilde{X}, \\tilde{Y}) = \\Sigma_{XX}^{-1/2} \\Sigma_{XY} \\Sigma_{YY}^{-1/2} =: M.\n\\] Zatem \\[\n\\operatorname{Cov}(U_k, V_l) = e_k^\\top M f_l.\n\\] Z poprzednich wyprowadzeÅ„ \\[\nf_l \\propto M^\\top e_l.\n\\] Zatem \\[\n\\operatorname{Cov}(U_k, V_l) \\propto e_k^\\top M M^\\top e_l.\n\\] Ale macierz \\(MM^\\top\\) jest symetryczna, a \\(e_k\\) sÄ… jej ortonormalnymi wektorami wÅ‚asnymi, wiÄ™c \\[\ne_k^\\top MM^\\top e_l = 0 \\quad \\text{dla } k \\neq l.\n\\] Zatem \\[\n\\operatorname{Cov}(U_k, V_l) = 0.\n\\]\n\n\n6Â ortonormalnoÅ›Ä‡ wynika z niezmienniczoÅ›ci korelacji wzglÄ™dem dÅ‚ugoÅ›ci wektorÃ³wPonadto korelacje kanoniczne sÄ… niezmiennicze wzglÄ™dem odwracalnych przeksztaÅ‚ceÅ„ liniowych \\(X\\) i \\(Y\\): \\[\nX^*=\\mathcal{U}^TX+u,\\quad Y^*=\\mathcal{V}^TY+v \\implies\n\\rho_i(X^*,Y^*)=\\rho_i(X,Y).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#wniosek",
    "href": "cca.html#wniosek",
    "title": "Analiza kanoniczna",
    "section": "Wniosek",
    "text": "Wniosek\nPoniewaÅ¼ macierze kowariancji \\(\\Sigma_{XX}\\) i \\(\\Sigma_{YY}\\) sÄ… dodatnio okreÅ›lone, ich odwrotnoÅ›ci istniejÄ…. Macierze: \\[\n\\Sigma_{XX}^{-1/2}\\Sigma_{XY}\\Sigma_{YY}^{-1}\\Sigma_{YX}\\Sigma_{XX}^{-1/2},\\quad\n\\Sigma_{YY}^{-1/2}\\Sigma_{YX}\\Sigma_{XX}^{-1}\\Sigma_{XY}\\Sigma_{YY}^{-1/2}\n\\] sÄ… symetryczne i dodatnio okreÅ›lone, wiÄ™c majÄ… rzeczywiste, dodatnie wartoÅ›ci wÅ‚asne i ortonormalne wektory wÅ‚asne. Z lematu Rayleighaâ€“Ritza otrzymujemy maksymalizacjÄ™ ilorazu Rayleigha oraz gwarancjÄ™ istnienia rozwiÄ…zania. Tym samym wykazano, Å¼e pary \\((a_k,b_k)\\) istniejÄ…, a odpowiadajÄ…ce im \\(\\rho_k=\\sqrt{\\lambda_k}\\) sÄ… kanonicznymi korelacjami.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#hipoteza-zerowa-i-alternatywna",
    "href": "cca.html#hipoteza-zerowa-i-alternatywna",
    "title": "Analiza kanoniczna",
    "section": "Hipoteza zerowa i alternatywna",
    "text": "Hipoteza zerowa i alternatywna\nDla zbiorÃ³w zmiennych \\(X \\in \\mathbb{R}^p\\), \\(Y \\in \\mathbb{R}^q\\), testujemy\n\n\n\\(H_0: \\rho_1 = \\rho_2 = \\cdots = \\rho_s = 0\\) â€“ brak istotnych korelacji kanonicznych (pierwiastkÃ³w),\n\n\\(H_1\\): istnieje co najmniej jedna istotna korelacja kanoniczna, tj. \\(\\exists i \\leq s \\ \\text{takie, Å¼e } \\rho_i \\ne 0\\).\n\ngdzie \\(s = \\min(p, q)\\), a \\(\\rho_i\\) to \\(i\\)-ta korelacja kanoniczna.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#statystyka-testowa-test-wilka",
    "href": "cca.html#statystyka-testowa-test-wilka",
    "title": "Analiza kanoniczna",
    "section": "Statystyka testowa â€“ test Wilka",
    "text": "Statystyka testowa â€“ test Wilka\nW celu przetestowania tej hipotezy, wykorzystuje siÄ™ statystykÄ™ Wilka, ktÃ³ra bazuje na iloczynie skÅ‚adnikÃ³w postaci (\\(1 - \\lambda_i\\)), gdzie \\(\\lambda_i\\) to wartoÅ›ci wÅ‚asne odpowiadajÄ…ce kwadratom korelacji kanonicznych \\[\n\\lambda_i = \\rho_i^2.\n\\] Statystyka Wilkas jest zdefiniowana jako \\[\n\\Lambda = \\prod_{i=1}^s (1 - \\lambda_i).\n\\]\nInterpretacja - im mniejsze wartoÅ›ci \\(\\Lambda\\), tym wiÄ™ksza zaleÅ¼noÅ›Ä‡ miÄ™dzy zbiorami \\(X\\) i \\(Y\\). DuÅ¼e wartoÅ›ci \\(\\lambda_i\\) (czyli silne korelacje kanoniczne) powodujÄ…, Å¼e \\(\\Lambda\\) dÄ…Å¼y do zera.\nW praktyce, dla prÃ³by \\(n\\)-elementowej, stosujemy wersjÄ™ testu bazujÄ…cÄ… na macierzach kowariancji estymowanych z prÃ³by \\(S_{XX}, S_{XY}, S_{YX}, S_{YY})\\) â€“ odpowiedniki \\(\\Sigma_{XX}, \\Sigma_{XY}, \\Sigma_{YX}, \\Sigma_{YY}\\).\nWÃ³wczas \\[\nT^2/n = \\left|I - S_{YY}^{-1} S_{YX} S_{XX}^{-1} S_{XY} \\right| = \\prod_{i=1}^s (1 - \\hat{\\lambda}_i),\n\\] gdzie \\(\\hat{\\lambda}_i\\) to prÃ³bkowe wartoÅ›ci wÅ‚asne (szacunki \\(\\lambda_i\\)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#rozkÅ‚ad-asymptotyczny-i-transformacja-do-rozkÅ‚adu-chi2",
    "href": "cca.html#rozkÅ‚ad-asymptotyczny-i-transformacja-do-rozkÅ‚adu-chi2",
    "title": "Analiza kanoniczna",
    "section": "RozkÅ‚ad asymptotyczny i transformacja do rozkÅ‚adu \\(\\chi^2\\)\n",
    "text": "RozkÅ‚ad asymptotyczny i transformacja do rozkÅ‚adu \\(\\chi^2\\)\n\nWielu autorÃ³w (np. Marriott i Gittins (1986)) sugeruje przeksztaÅ‚cenie statystyki Wilksa do postaci asymptotycznie zgodnej z rozkÅ‚adem \\(\\chi^2\\), np. za pomocÄ… transformacji\n\\[\n-\\left(n - \\frac{1}{2}(p + q + 1) \\right) \\cdot \\ln(\\Lambda) \\sim \\chi^2_{pq}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#procedura-testowania",
    "href": "cca.html#procedura-testowania",
    "title": "Analiza kanoniczna",
    "section": "Procedura testowania",
    "text": "Procedura testowania\n\nOszacuj wszystkie korelacje kanoniczne \\(\\hat{\\rho}_1, \\ldots, \\hat{\\rho}_p\\).\nOd \\(k = 0\\) do \\(p-1\\) oblicz \\(\\Lambda_k = \\prod_{i=k+1}^{p}(1 - \\hat{\\rho}_i^2)\\).\nOblicz transformacjÄ™ \\(\\chi^2_k=-\\left(n - \\frac{1}{2}(p + q + 1) \\right) \\cdot \\ln(\\Lambda_k)\\)\n\nPorÃ³wnaj z odpowiednim kwantylem rozkÅ‚adu \\(\\chi^2\\) z \\((q - k)(r - k)\\) stopniami swobody.\nJeÅ›li wartoÅ›Ä‡ statystyki przekracza ten kwantyl (\\(p&lt;\\alpha\\)), odrzuÄ‡ \\(H_0^{(k)}\\) i przejdÅº do \\(k+1\\). JeÅ›li nie, zatrzymaj siÄ™ â€“ kolejne korelacje uznajemy za nieistotne.\n\nOcena dopasowania modelu w analizie kanonicznej (CCA â€“ Canonical Correlation Analysis) obejmuje kilka istotnych wskaÅºnikÃ³w diagnostycznych, ktÃ³re pozwalajÄ… zrozumieÄ‡ siÅ‚Ä™ i strukturÄ™ relacji miÄ™dzy dwoma zbiorami zmiennych. PoniÅ¼ej omÃ³wione zostaÅ‚y trzy kluczowe miary: Å‚adunki czynnikowe, wariancja wyjaÅ›niona oraz redundancja.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#Å‚adunki-czynnikowe-ang.-canonical-loadings",
    "href": "cca.html#Å‚adunki-czynnikowe-ang.-canonical-loadings",
    "title": "Analiza kanoniczna",
    "section": "Åadunki czynnikowe (ang. canonical loadings)",
    "text": "Åadunki czynnikowe (ang. canonical loadings)\n\n\nDefinicja - korelacje pomiÄ™dzy zmiennymi kanonicznymi (czyli kombinacjami liniowymi wektorÃ³w \\(a_k'X\\) i \\(b_k'Y\\)) a oryginalnymi zmiennymi ze zbiorÃ³w \\(X\\) i \\(Y\\).\n\nInterpretacja:\n\nPokazujÄ…, ktÃ³re konkretne zmienne pierwotne w najwiÄ™kszym stopniu â€Å‚adujÄ… siÄ™â€ (czyli kontrybuujÄ…) na danÄ… zmiennÄ… kanonicznÄ….\nWysoka wartoÅ›Ä‡ (np. &gt; 0.7) wskazuje na silnÄ… zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennÄ… oryginalnÄ… a danÄ… zmiennÄ… kanonicznÄ….\nZnaki dodatnie/ujemne pozwalajÄ… wnioskowaÄ‡ o kierunku zwiÄ…zku.\n\n\n\nWzÃ³r:\n\nDla zbioru \\(X\\): \\[\n\\text{loadings}_X = \\mathrm{Corr}(X, U_k) = \\Sigma_{XX} a_k\n\\]\n\nDla zbioru \\(Y\\): \\[\n\\text{loadings}_Y = \\mathrm{Corr}(Y, V_k) = \\Sigma_{YY} b_k\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#wariancja-wyjaÅ›niona-ang.-variance-explained",
    "href": "cca.html#wariancja-wyjaÅ›niona-ang.-variance-explained",
    "title": "Analiza kanoniczna",
    "section": "Wariancja wyjaÅ›niona (ang. variance explained)",
    "text": "Wariancja wyjaÅ›niona (ang. variance explained)\n\n\nDefinicja - Å›rednia kwadratÃ³w Å‚adunkÃ³w czynnikowych dla kaÅ¼dej zmiennej kanonicznej i kaÅ¼dego zbioru danych.\n\nInterpretacja:\n\nInformuje, jakÄ… czÄ™Å›Ä‡ wariancji oryginalnych zmiennych w danym zbiorze (\\(X\\) lub \\(Y\\)) wyjaÅ›nia dana zmienna kanoniczna.\nMoÅ¼na traktowaÄ‡ ten wskaÅºnik jako odpowiednik wspÃ³Å‚czynnika determinacji \\(R^2\\) dla pojedynczej zmiennej kanonicznej.\nWysoka wartoÅ›Ä‡ oznacza, Å¼e dana zmienna kanoniczna dobrze reprezentuje zbiÃ³r, z ktÃ³rego zostaÅ‚a utworzona.\n\n\n\nWzÃ³r: \\[\n\\text{Explained variance} = \\frac{1}{p} \\sum_{j=1}^{p} \\mathrm{Corr}^2(X_j, U_k)\n\\] gdzie \\(p\\) to liczba zmiennych w zbiorze \\(X\\), a \\(U_k\\) to \\(k\\)-ta zmienna kanoniczna.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#redundancja-ang.-redundancy-index",
    "href": "cca.html#redundancja-ang.-redundancy-index",
    "title": "Analiza kanoniczna",
    "section": "Redundancja (ang. redundancy index)",
    "text": "Redundancja (ang. redundancy index)\n\n\nDefinicja - iloczyn kwadratu korelacji kanonicznej \\(\\rho_k^2\\) oraz wariancji wyjaÅ›nionej przez danÄ… zmiennÄ… kanonicznÄ… we wÅ‚asnym zbiorze.\n\nInterpretacja:\n\nInformuje, jaka czÄ™Å›Ä‡ przeciÄ™tnej wariancji jednej grupy zmiennych jest wyjaÅ›niana przez zmiennÄ… kanonicznÄ… utworzonÄ… na podstawie drugiego zbioru.\nMiara ta pokazuje, czy dany zbiÃ³r zmiennych wnosi unikalnÄ… informacjÄ™ o drugim zbiorze.\nWysoka redundancja oznacza, Å¼e istnieje istotny zwiÄ…zek miÄ™dzy strukturami dwÃ³ch zbiorÃ³w zmiennych.\n\n\n\nWzÃ³r: \\[\n\\text{Redundancy}_X = \\rho_k^2 \\cdot \\left( \\frac{1}{p} \\sum_{j=1}^{p} \\mathrm{Corr}^2(X_j, U_k) \\right)\n\\] Analogicznie definiujemy redundancjÄ™ wzglÄ™dem \\(Y\\).\n\n\n\n\n\n\n\n\nMiara\nCo opisuje\nInterpretacja praktyczna\n\n\n\nÅadunki czynnikowe\nSiÅ‚Ä™ powiÄ…zania zmiennej oryginalnej z kanonicznÄ…\nWysoka wartoÅ›Ä‡ â‡’ silna reprezentacja zmiennej\n\n\nWariancja wyjaÅ›niona\nÅšrednia siÅ‚a reprezentacji zbioru przez zm. kanonicznÄ…\nMiara dopasowania struktury do zbioru\n\n\nRedundancja\nIloÅ›Ä‡ informacji o jednym zbiorze zawarta w drugim\nMiara istotnoÅ›ci relacji miÄ™dzy zbiorami",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#normalnoÅ›Ä‡-wielowymiarowa",
    "href": "cca.html#normalnoÅ›Ä‡-wielowymiarowa",
    "title": "Analiza kanoniczna",
    "section": "NormalnoÅ›Ä‡ wielowymiarowa",
    "text": "NormalnoÅ›Ä‡ wielowymiarowa\nZakÅ‚ada siÄ™, Å¼e obydwa zbiory zmiennych losowych â€“ \\(X\\) i \\(Y\\) â€“ sÄ… wspÃ³lnie rozkÅ‚adem normalnym wielowymiarowym jak podano w RÃ³wnanieÂ 4.1. NormalnoÅ›Ä‡ umoÅ¼liwia stosowanie testÃ³w statystycznych (np. testu Wilksa) do oceny liczby istotnych korelacji kanonicznych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#brak-wartoÅ›ci-odstajÄ…cych-outliers",
    "href": "cca.html#brak-wartoÅ›ci-odstajÄ…cych-outliers",
    "title": "Analiza kanoniczna",
    "section": "Brak wartoÅ›ci odstajÄ…cych (outliers)",
    "text": "Brak wartoÅ›ci odstajÄ…cych (outliers)\nZarÃ³wno obserwacje odstajÄ…ce jednowymiarowe, jak i wielowymiarowe mogÄ… istotnie zaburzaÄ‡ wynik analizy kanonicznej. OdstajÄ…ce wartoÅ›ci mogÄ… wpÅ‚ywaÄ‡ na macierze kowariancji, zmieniajÄ…c kierunki i siÅ‚y relacji miÄ™dzy zbiorami zmiennych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#wystarczajÄ…ca-liczba-obserwacji",
    "href": "cca.html#wystarczajÄ…ca-liczba-obserwacji",
    "title": "Analiza kanoniczna",
    "section": "WystarczajÄ…ca liczba obserwacji",
    "text": "WystarczajÄ…ca liczba obserwacji\nLiczba obserwacji powinna znaczÄ…co przekraczaÄ‡ liczbÄ™ zmiennych w kaÅ¼dym zbiorze. Liczba obserwacji \\(n\\) w kaÅ¼dej grupie powinna byÄ‡ wiÄ™ksza niÅ¼ suma liczby zmiennych w \\(X\\) i \\(Y\\) \\[\nn &gt; p + q\n\\] Zapewnia odwracalnoÅ›Ä‡ macierzy kowariancji oraz stabilnoÅ›Ä‡ estymatorÃ³w.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#liniowoÅ›Ä‡-zaleÅ¼noÅ›ci",
    "href": "cca.html#liniowoÅ›Ä‡-zaleÅ¼noÅ›ci",
    "title": "Analiza kanoniczna",
    "section": "LiniowoÅ›Ä‡ zaleÅ¼noÅ›ci",
    "text": "LiniowoÅ›Ä‡ zaleÅ¼noÅ›ci\nZakÅ‚ada siÄ™, Å¼e zwiÄ…zki miÄ™dzy wszystkimi parami zmiennych sÄ… liniowe. PoniewaÅ¼ CCA opiera siÄ™ na maksymalizacji liniowych kombinacji, nieliniowe zaleÅ¼noÅ›ci mogÄ… pozostaÄ‡ niewykryte.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#brak-nadmiernej-wspÃ³Å‚liniowoÅ›ci-multikolinearnoÅ›ci",
    "href": "cca.html#brak-nadmiernej-wspÃ³Å‚liniowoÅ›ci-multikolinearnoÅ›ci",
    "title": "Analiza kanoniczna",
    "section": "Brak nadmiernej wspÃ³Å‚liniowoÅ›ci (multikolinearnoÅ›ci)",
    "text": "Brak nadmiernej wspÃ³Å‚liniowoÅ›ci (multikolinearnoÅ›ci)\nZmienne wewnÄ…trz kaÅ¼dego zbioru (w \\(X\\) lub w \\(Y\\)) nie powinny byÄ‡ nadmiernie skorelowane. Wysoka wspÃ³Å‚liniowoÅ›Ä‡ moÅ¼e prowadziÄ‡ do niestabilnych i trudnych do interpretacji wektorÃ³w kanonicznych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  },
  {
    "objectID": "cca.html#niezaleÅ¼noÅ›Ä‡-obserwacji",
    "href": "cca.html#niezaleÅ¼noÅ›Ä‡-obserwacji",
    "title": "Analiza kanoniczna",
    "section": "NiezaleÅ¼noÅ›Ä‡ obserwacji",
    "text": "NiezaleÅ¼noÅ›Ä‡ obserwacji\nKaÅ¼da obserwacja powinna pochodziÄ‡ od innej jednostki (brak powtÃ³rzeÅ„ pomiarÃ³w). NiezaleÅ¼noÅ›Ä‡ warunkuje poprawnoÅ›Ä‡ estymatorÃ³w kowariancji.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Analiza kanoniczna</span>"
    ]
  }
]