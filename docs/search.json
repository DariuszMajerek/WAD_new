[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wielowymiarowa analiza danych",
    "section": "",
    "text": "Wstęp\nWielowymiarowa analiza danych stanowi jeden z filarów współczesnej statystyki i eksploracji danych, oferując metody pozwalające zrozumieć strukturę i zależności w zbiorach danych, w których każda obserwacja jest opisana wieloma zmiennymi jednocześnie. W dobie powszechnego dostępu do danych oraz rosnącego zapotrzebowania na ich zaawansowaną analizę, umiejętność stosowania metod wielowymiarowych staje się nieodzowna zarówno w badaniach naukowych, jak i w analizie danych stosowanej w przemyśle, finansach, biologii, medycynie czy naukach społecznych.\nNiniejsza książka została opracowana z myślą o dwóch kierunkach kształcenia akademickiego: matematyce oraz inżynierii i analizie danych. Jej celem jest zapewnienie solidnych podstaw teoretycznych oraz praktycznych umiejętności niezbędnych do stosowania metod wielowymiarowych w rzeczywistych problemach badawczych i aplikacyjnych. Zakres tematyczny książki został dobrany tak, aby uwzględniać zarówno klasyczne metody statystyczne, jak i techniki wykorzystywane we wspsółczesnej analizie danych.\nW pierwszej części książki omówione zostaną testy wielowymiarowe, które stanowią rozszerzenie klasycznych metod statystycznych na przypadki, w których każda obserwacja opisana jest wieloma zmiennymi. Szczególna uwaga zostanie poświęcona testowi Hotellinga T², będącemu odpowiednikiem testu t dla wielu zmiennych, oraz analizie wariancji dla wielu zmiennych (MANOVA), pozwalającej na badanie różnic między grupami z uwzględnieniem współzależności zmiennych. Celem tej części będzie zrozumienie podstaw inferencji w przestrzeni wielowymiarowej i interpretacji wyników testów z uwzględnieniem macierzy kowariancji.\nNastępnie przedstawiona zostanie analiza kanoniczna, która służy do badania zależności pomiędzy dwoma zestawami zmiennych. Czytelnik pozna konstrukcję zmiennych kanonicznych, sposoby ich interpretacji oraz znaczenie wag i korelacji kanonicznych. Analiza ta ma kluczowe znaczenie wszędzie tam, gdzie celem jest znalezienie skorelowanych struktur w dwóch grupach cech, np. w badaniach biologicznych, społecznych lub psychometrycznych.\nKolejna część książki będzie poświęcona analizie czynnikowej (FA), która umożliwia modelowanie współzmienności zestawu zmiennych za pomocą mniejszej liczby zmiennych ukrytych, zwanych czynnikami. Przedstawione zostaną metody estymacji, kryteria wyboru liczby czynników oraz techniki rotacji, które służą lepszej interpretacji wyników. Analiza czynnikowa jest często stosowana w badaniach ankietowych i psychometrycznych, ale znajduje również zastosowanie w analizie danych ekonomicznych i marketingowych.\nW dalszej kolejności wprowadzony zostanie model ścieżkowy oraz jego uogólnienie w postaci modeli równań strukturalnych (SEM). Modele te pozwalają na modelowanie zarówno obserwowalnych, jak i ukrytych zmiennych oraz relacji przyczynowych pomiędzy nimi. Czytelnik pozna strukturę modelu ścieżkowego, pojęcie identyfikowalności, miary dopasowania oraz techniki estymacji parametrów. Modele SEM są obecnie szeroko stosowane w naukach społecznych, biologii, psychologii i ekonomii.\nNastępnie omówione zostaną metody redukcji wymiarowości, których celem jest uproszczenie reprezentacji danych bez utraty istotnej informacji. Kluczową techniką będzie analiza składowych głównych (PCA), która pozwala na znalezienie nowych osi zmienności w danych. Kolejno zaprezentowana zostanie analiza niezależnych składowych (ICA), która poszukuje składników statystycznie niezależnych, co jest szczególnie użyteczne w analizie sygnałów. Obie metody znajdą zastosowanie zarówno w przygotowaniu danych, jak i w ich eksploracji.\nKolejna część książki poświęcona będzie metodom skalowania wielowymiarowego (Multidimensional Scaling, MDS), które umożliwiają odwzorowanie relacji odległościowych pomiędzy obiektami w przestrzeni o mniejszym wymiarze. Wariant metric zakłada zachowanie rzeczywistych wartości odległości, natomiast non-metric koncentruje się na porządku dystansów. Metody te pozwalają uzyskać intuicyjne wizualizacje struktur danych, szczególnie przydatne w psychologii, socjologii czy analizie rynku.\nW uzupełnieniu do klasycznych technik przedstawione zostaną nieliniowe metody redukcji wymiarowości, takie jak t-distributed Stochastic Neighbor Embedding (t-SNE) oraz Uniform Manifold Approximation and Projection (UMAP). Obie techniki pozwalają na odwzorowanie skomplikowanych struktur danych w przestrzeniach dwu- lub trójwymiarowych, zachowując lokalne sąsiedztwa. Choć są to metody przede wszystkim eksploracyjne i wizualizacyjne, ich wartość w analizie dużych zbiorów danych jest trudna do przecenienia.\nNastępnie przedstawiona zostanie analiza skupień, której celem jest odkrywanie naturalnych grup w zbiorze danych. Omówione zostaną zarówno metody hierarchiczne, jak i niehierarchiczne, w tym popularna metoda k-średnich. Poruszona zostanie problematyka doboru liczby skupień oraz oceny stabilności i jakości otrzymanych rozwiązań. Analiza skupień znajduje zastosowanie w segmentacji rynku, biologii molekularnej, diagnostyce medycznej i wielu innych dziedzinach.\nKolejna część książki poświęcona będzie analizie korespondencji, stosowanej do eksploracji związków pomiędzy zmiennymi jakościowymi przedstawionymi w postaci tablicy kontyngencji. Przedstawiona zostanie zarówno analiza korespondencji prosta (dla dwóch zmiennych), jak i złożona (dla więcej niż dwóch). Omówione zostaną interpretacja map percepcyjnych, odwzorowanie profili oraz związki z metodami takimi jak PCA czy MDS.\nOstatni rozdział poświęcony będzie analizie log-liniowej, która umożliwia modelowanie częstości w tablicach wielodzielczych na podstawie interakcji pomiędzy zmiennymi kategorycznymi. Zostaną zaprezentowane modele pełne i uproszczone, zasady testowania złożoności modeli oraz interpretacji parametrów. Analiza log-liniowa jest szczególnie przydatna przy badaniu wielowymiarowych zależności między zmiennymi kategorycznymi w badaniach społecznych, medycznych oraz w analizie zachowań konsumenckich.\nWszystkie metody zostaną zilustrowane przykładami praktycznymi, realizowanymi w języku R. Pozwoli to Czytelnikowi nie tylko zrozumieć teoretyczne podstawy omawianych technik, ale także nabyć umiejętność ich stosowania w praktyce analitycznej.",
    "crumbs": [
      "Wstęp"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nKod\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. „Literate Programming”. Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "multi_tests.html",
    "href": "multi_tests.html",
    "title": "Testy wielowymiarowe",
    "section": "",
    "text": "Test Hotellinga dla znanej macierzy kowariancji\nW tradycyjnej analizie statystycznej często koncentrujemy się na porównywaniu grup ze względu na jedną zmienną – np. porównujemy średni wzrost kobiet i mężczyzn, wykorzystując test t-Studenta. Jednak w rzeczywistości badawczej rzadko interesuje nas tylko jedna cecha. Przykładowo, porównując grupy pacjentów, możemy jednocześnie rozważać poziom ciśnienia, cholesterolu i BMI. Albo, analizując dane socjologiczne, chcemy porównać grupy pod względem dochodów, wykształcenia i poziomu zadowolenia z życia.\nUżycie wielu testów jednowymiarowych wydaje się kuszące – testujemy każdą zmienną osobno. Jednak prowadzi to do trzech istotnych problemów:\n\\[\n\\mathbb{P}(\\text{co najmniej jeden błąd I rodzaju}) = 1 - (1 - \\alpha)^p = 1 - 0.95^{10} \\approx 0.40\n\\]\nPowyższe problemy uzasadniają potrzebę stosowania testów wielowymiarowych – uwzględniających strukturę współzmienności między cechami oraz pozwalających na testowanie hipotez dotyczących całych wektorów średnich.\nRozważmy próbkę \\(\\boldsymbol{y}_1, \\boldsymbol{y}_2, \\ldots, \\boldsymbol{y}_n \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), gdzie \\(\\boldsymbol{\\Sigma}\\) jest znana. Oznacza to, że mamy do czynienia z ciągiem niezależnych losowych wektorów \\(\\boldsymbol{y}_i\\), z których każdy ma ten sam wielowymiarowy rozkład normalny o wymiarze \\(p\\), średniej \\(\\boldsymbol{\\mu}\\) i macierzy kowariancji \\(\\boldsymbol{\\Sigma}\\). Każdy wektor \\(\\boldsymbol{y}_i\\) można interpretować jako punkt w przestrzeni \\(\\mathbb{R}^p\\), opisujący \\(p\\) cech (zmiennych) dla jednej obserwacji. Formalnie jest to wektor kolumnowy postaci \\(\\boldsymbol{y}_i = [y_{i1}, y_{i2}, \\ldots, y_{ip}]^\\top\\), gdzie indeks \\(i\\) numeruje jednostki (np. osoby, obiekty pomiaru), a indeksy \\(j = 1, \\ldots, p\\) odpowiadają poszczególnym zmiennym. Wektor ten traktowany jest jako zmienna losowa, ponieważ jego wartości są wynikiem losowego procesu generującego dane. Rozkład \\(\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) jest wielowymiarową wersją rozkładu normalnego. Opisuje on sytuację, w której każda kombinacja liniowa zmiennych losowych w \\(\\boldsymbol{y}_i\\) również ma rozkład normalny, a funkcja gęstości prawdopodobieństwa ma postać zależną od wartości wektora średnich oraz struktury kowariancji. Jest to fundamentalne założenie w klasycznej analizie statystycznej, pozwalające na stosowanie wielu narzędzi statystycznych.\nParametr \\(\\boldsymbol{\\mu} = [\\mu_1, \\mu_2, \\ldots, \\mu_p]^\\top\\) to wektor wartości oczekiwanych każdej z analizowanych zmiennych. Oznacza on przeciętny poziom zmiennej \\(y_{ij}\\) w populacji dla każdej cechy \\(j\\). Jest to parametr istotny z punktu widzenia testowania hipotez, ponieważ wiele testów statystycznych dotyczy właśnie równości lub różnic wektorów średnich między grupami.\nZ kolei macierz \\(\\boldsymbol{\\Sigma}\\) to dodatnio określona, symetryczna macierz kowariancji o wymiarach \\(p \\times p\\). Jej elementy \\(\\sigma_{jj}\\) opisują wariancje poszczególnych zmiennych, natomiast elementy poza główną przekątną \\(\\sigma_{jk}\\) (dla \\(j \\ne k\\)) opisują kowariancje, czyli współzmienność pomiędzy zmiennymi \\(y_{ij}\\) i \\(y_{ik}\\). W analizie wielowymiarowej uwzględnienie tych zależności między cechami jest kluczowe, ponieważ pozwala lepiej zrozumieć strukturę danych i dokonywać bardziej trafnych wniosków statystycznych.\nO próbie \\(\\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_n\\) zakładamy, że wszystkie obserwacje są niezależne oraz pochodzą z tego samego rozkładu. Oznacza to, że mamy do czynienia z próbą losową, niezależną o identycznych rozkładach (i.i.d.), co jest podstawowym założeniem wielu testów i metod estymacji. Całą próbkę można przedstawić jako macierz danych o wymiarach \\(n \\times p\\), w której wiersze odpowiadają jednostkom, a kolumny cechom.\nW przypadku, gdy macierz kowariancji \\(\\boldsymbol{\\Sigma}\\) jest znana, możemy zastosować uproszczone wersje testów statystycznych, takie jak klasyczny test Hotellinga \\(T^2\\) dla jednej próby. Jest to jednak sytuacja czysto teoretyczna, ponieważ w praktyce \\(\\boldsymbol{\\Sigma}\\) musi być zazwyczaj estymowana na podstawie danych. Pomimo tego, przypadek znanej macierzy jest użyteczny do budowania intuicji, zrozumienia ról poszczególnych parametrów i wyprowadzania własności statystyk testowych.\nChcemy przetestować hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_0 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu} \\neq \\boldsymbol{\\mu}_0\n\\]\nStatystyka testowa opiera się na uogólnionej odległości Mahalanobisa:\n\\[\nT^2 = n (\\bar{\\boldsymbol{y}} - \\boldsymbol{\\mu}_0)^T \\boldsymbol{\\Sigma}^{-1} (\\bar{\\boldsymbol{y}} - \\boldsymbol{\\mu}_0)\n\\]\nPod warunkiem spełnienia \\(H_0\\), statystyka \\(T^2 \\sim \\chi^2_p\\). Zatem możemy porównać wartość \\(T^2\\) z odpowiednim kwantylem rozkładu chi-kwadrat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-symulacja-w-r",
    "href": "multi_tests.html#przykład-symulacja-w-r",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.2 Przykład (symulacja w R)",
    "text": "1.2 Przykład (symulacja w R)\n\n\nKod\n# set.seed(44)\n# mu0 &lt;- c(170, 70)\n# Sigma &lt;- matrix(c(100, 40, 40, 100), nrow = 2)\n# n &lt;- 30\n# \n# # Generowanie danych\n# X &lt;- MASS::mvrnorm(n = n, mu = mu0, Sigma = Sigma)\n# \n# # Weryfikacja hipotezy H0: mu = mu0\n# x_bar &lt;- colMeans(X)\n# T2 &lt;- n * t(x_bar - mu0) %*% solve(Sigma) %*% (x_bar - mu0)\n# T2\n# pchisq(T2, df = 2, lower.tail = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-hotellinga-t2-dla-nieznanej-kowariancji",
    "href": "multi_tests.html#test-hotellinga-t2-dla-nieznanej-kowariancji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.2 Test Hotellinga \\(T^2\\) dla nieznanej kowariancji",
    "text": "1.2 Test Hotellinga \\(T^2\\) dla nieznanej kowariancji\nW przypadku, gdy próbka \\(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_n \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), a macierz kowariancji \\(\\boldsymbol{\\Sigma}\\) nie jest znana i musi być estymowana z danych, testujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_0\n\\]\nprzy pomocy statystyki Hotellinga:\n\\[\nT^2 = n (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)\n\\]\nW przeciwieństwie do przypadku znanej macierzy kowariancji, statystyka \\(T^2\\) nie ma rozkładu chi-kwadrat. W rzeczywistości jej rozkład pod warunkiem prawdziwości hipotezy zerowej określany jest jako rozkład Hotellinga, który stanowi przypadek szczególny rozkładu beta drugiego rodzaju (ang. beta type II distribution)1. Jest to rozkład znacznie mniej intuicyjny i trudniejszy w praktycznym zastosowaniu.\n1 Rozkład beta drugiego rodzaju (ang. Beta type II distribution), znany także jako rozkład beta-prime, jest ciągłym rozkładem prawdopodobieństwa definiowanym dla dodatnich wartości. Rozkład beta II o parametrach \\(a &gt; 0\\), \\(b &gt; 0\\) i skali \\(\\theta &gt; 0\\) ma funkcję gęstości postaci: \\[\nf(x) = \\frac{1}{\\theta} \\cdot \\frac{(x/\\theta)^{a - 1}}{(1 + x/\\theta)^{a + b}} \\cdot \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)}, \\quad x &gt; 0\n\\] gdzie \\(\\Gamma(\\cdot)\\) oznacza funkcję gamma Eulera. Wartość oczekiwana istnieje tylko dla \\(b &gt; 1\\) i wynosi: \\[\n\\mathbb{E}(X) = \\theta \\cdot \\frac{a}{b - 1}\n\\] a wariancja istnieje tylko dla \\(b &gt; 2\\) i wynosi: \\[\n\\operatorname{Var}(X) = \\theta^2 \\cdot \\frac{a(a + b - 1)}{(b - 2)(b - 1)^2}\n\\]Aby umożliwić testowanie hipotez z wykorzystaniem znanych tablic lub funkcji w programach statystycznych, Hotelling wykazał, że statystykę \\(T^2\\) można przekształcić do postaci mającej rozkład F-Fishera:\n\\[\nF = \\frac{(n - p)}{p(n - 1)} T^2 \\sim F_{p, n - p}\n\\]\nalbo równoważnie:\n\\[\nT^2 \\sim \\frac{p(n - 1)}{n - p} F_{p, n - p}\n\\]\nZ powyższej relacji wynika, że testowanie hipotezy \\(H_0\\) przy pomocy statystyki Hotellinga można sprowadzić do standardowego testu \\(F\\). Z tego względu mówi się, że statystyka Hotellinga ma rozkład Hotellinga T2, który w rzeczywistości jest funkcją rozkładu \\(F\\). Dla dużych liczności \\(n\\), rozkład statystyki \\(T^2\\) zbliża się do rozkładu \\(\\chi^2_p\\), czyli chi-kwadrat o \\(p\\) stopniach swobody, co często wykorzystywane jest jako przybliżenie asymptotyczne.\n\nPrzykład 1.2 (Test Hotellinga \\(T^2\\) dla nieznanej macierzy kowariancji)  \n\n\nKod\nset.seed(44)\nlibrary(mvtnorm)\nmu1 &lt;- c(-4, 4)\nSigma &lt;- matrix(c(16, -2, -2,9), byrow=TRUE, ncol=2)\nY1 &lt;- round(rmvnorm(15, mean=mu1, sigma=Sigma))\nmuH0 &lt;- c(-1, 2) # hipotetyczna średnia\nlibrary(ICSNP)\nHotellingsT2(Y1, mu=muH0)\n\n\n\n    Hotelling's one sample T2-test\n\ndata:  Y1\nT.2 = 2.7417, df1 = 2, df2 = 13, p-value = 0.1015\nalternative hypothesis: true location is not equal to c(-1,2)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-w-r-test-hotellinga",
    "href": "multi_tests.html#przykład-w-r-test-hotellinga",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.3 Przykład w R: test Hotellinga",
    "text": "1.3 Przykład w R: test Hotellinga\n\n\nKod\n# library(Hotelling)\n# hotelling.test(X, mu = mu0)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-hotellinga-dla-dwóch-grup",
    "href": "multi_tests.html#test-hotellinga-dla-dwóch-grup",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.3 Test Hotellinga dla dwóch grup",
    "text": "1.3 Test Hotellinga dla dwóch grup\nRozważmy dwa niezależne zbiory obserwacji:\n\n\\(\\boldsymbol{y}_{1,1}, \\boldsymbol{y}_{1,2}, \\ldots, \\boldsymbol{y}_{1,n_1} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\\),\n\\(\\boldsymbol{y}_{2,1}, \\boldsymbol{y}_{2,2}, \\ldots, \\boldsymbol{y}_{2,n_2} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_2, \\boldsymbol{\\Sigma}_2)\\)\n\ngdzie \\(\\boldsymbol{y}_{k,i} \\in \\mathbb{R}^p\\) są wektorami cech dla \\(k\\)-tej grupy (\\(k = 1,2\\)) i \\(i\\)-tej obserwacji, \\(\\boldsymbol{\\mu}_1\\) i \\(\\boldsymbol{\\mu}_2\\) to wektory średnich populacyjnych, a \\(\\boldsymbol{\\Sigma}_1\\), \\(\\boldsymbol{\\Sigma}_2\\) to macierze kowariancji.\nTestujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\n\\quad \\text{vs} \\quad\nH_1: \\boldsymbol{\\mu}_1 \\neq \\boldsymbol{\\mu}_2\n\\]\n\n1.3.1 Założenia\n\nPróby są niezależne;\nObserwacje w każdej grupie pochodzą z rozkładu wielowymiarowego normalnego;\nMacierze kowariancji są równe \\(\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}\\). Jest to kluczowe założenie umożliwiające zbudowanie wspólnego estymatora kowariancji i zastosowanie rozkładu \\(T^2\\) Hotellinga. Choć może być ono naruszone w praktyce, to dla dużych prób test zachowuje swoje właściwości asymptotyczne (Rencher 1998).\n\nWektory średnich z próby wyrażamy jako:\n\\[\n\\bar{\\boldsymbol{y}}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} \\boldsymbol{y}_{1,i}, \\quad\n\\bar{\\boldsymbol{y}}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} \\boldsymbol{y}_{2,i}\n\\]\nNieobciążonym estymatorem macierzy kowariancji (\\(\\boldsymbol{\\Sigma}\\)) jest tzw. połączony estymator kowariancji:\n\\[\n\\mathbf{S} =\n\\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\] gdzie \\[\n\\mathbf{S}_1 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top\n\\]\n\\[\n\\mathbf{S}_2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top\n\\]\nZatem:\n\\[\\mathbf{S} = \\frac{\\mathbf{W}_1 + \\mathbf{W}_2}{n_1 + n_2 - 2}\\] gdzie: \\[\n\\mathbf{W}_1 = \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top = (n_1 - 1)\\mathbf{S}_1\n\\]\n\\[\n\\mathbf{W}_2 = \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top = (n_2 - 1)\\mathbf{S}_2\n\\] Statystyka testowa Hotellinga wówczas ma postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)\n\\]\nA gdy \\(H_0\\) jest prawdziwa, to po przekształceniu:\n\\[\nF = \\frac{(n_1 + n_2 - p - 1)}{p(n_1 + n_2 - 2)} T^2 \\sim F_{p, n_1 + n_2 - p - 1}\n\\]\nAlternatywnie, można zapisać, że:\n\\[\nT^2 \\sim \\frac{p(n_1 + n_2 - 2)}{n_1 + n_2 - p - 1} F_{p, n_1 + n_2 - p - 1}\n\\]\nHipotezę zerową \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) odrzucamy na poziomie istotności \\(\\alpha\\), jeśli:\n\\[\nT^2 &gt; T^2_{\\alpha, p, n_1 + n_2 - 2}\n\\]\nlub równoważnie:\n\\[\nF &gt; F_{\\alpha, p, n_1 + n_2 - p - 1}\n\\]\nAby test był możliwy do przeprowadzenia, konieczne jest, aby \\(n_1 + n_2 - 2 &gt; p\\), czyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n\n\n\nAdnotacja\n\n\n\nW praktyce istotne jest, aby przed zastosowaniem testu \\(T^2\\) Hotellinga dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa. Test M Boxa (ang. Box’s M test) służy do statystycznej weryfikacji hipotezy równości macierzy kowariancji w wielu grupach.\nZałóżmy, że mamy \\(G\\) niezależnych prób z wielowymiarowego rozkładu normalnego:\n\\[\n\\boldsymbol{X}_{g} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_g, \\boldsymbol{\\Sigma}_g), \\quad g = 1, \\ldots, G\n\\]\nTestujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\ldots = \\boldsymbol{\\Sigma}_G = \\boldsymbol{\\Sigma}\n\\]\nprzeciwko alternatywie:\n\\[\nH_1: \\exists\\, g, h: \\boldsymbol{\\Sigma}_g \\ne \\boldsymbol{\\Sigma}_h\n\\]\nNiech\n\n\\(\\mathbf{S}_g\\) – macierz kowariancji w grupie \\(g\\),\n\\(n_g\\) – liczba obserwacji w grupie \\(g\\),\n\\(\\mathbf{S}_p\\) – połączony estymator macierzy kowariancji:\n\n\\[\n\\mathbf{S}_p = \\frac{1}{N - G} \\sum_{g=1}^G (n_g - 1)\\mathbf{S}_g\n\\]\ngdzie \\(N = \\sum_{g=1}^G n_g\\) – łączna liczba obserwacji. Wówczas, statystyka testowa Boxa ma postać:\n\\[\nM = (N - G) \\cdot \\ln|\\mathbf{S}_p| - \\sum_{g=1}^G (n_g - 1) \\cdot \\ln|\\mathbf{S}_g|\n\\]\nPoprawka na skończoną próbkę prowadzi do statystyki:\n\\[\nC = \\left(1 - c\\right) \\cdot M\n\\]\ngdzie:\n\\[\nc = \\frac{1}{3(p + 1)(G - 1)} \\left[ \\sum_{g=1}^G \\frac{1}{n_g - 1} - \\frac{1}{N - G} \\right]\n\\]\nStatystyka \\(C\\) jest asymptotycznie zbierzna do rozkładu \\(\\chi^2\\left(\\frac{p}{2}(p + 1)(G - 1)\\right)\\) liczbą stopni swobody.\nHipotezę \\(H_0\\) o równości macierzy kowariancji odrzuca się, jeśli:\n\\[\nC &gt; \\chi^2_{1 - \\alpha, df}\n\\]\nlub gdy \\(p\\) testu jest mniejsza od poziomu istotności \\(\\alpha\\).\nUwagi praktyczne\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.\n\n\n\n\nPrzykład 1.3 (Porównanie dwóch grup za pomocą testu \\(T^2\\) Hotellinga)  \n\n\nKod\nlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n\n[1] \"Statystyka T² = 17.340\"\n\n\nKod\nsprintf(\"Statystyka F = %.3f\", F_stat)\n\n\n[1] \"Statystyka F = 8.532\"\n\n\nKod\nsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n\n[1] \"Wartość krytyczna F = 3.145\"\n\n\nKod\nsprintf(\"p-value = %e\", p_val)\n\n\n[1] \"p-value = 5.330310e-04\"\n\n\nKod\n# Wizualizacja \ndf1 &lt;- as.data.frame(Y1) %&gt;%\n  mutate(grupa = \"Grupa 1\")\n\ndf2 &lt;- as.data.frame(Y2) %&gt;%\n  mutate(grupa = \"Grupa 2\")\n\ndf_all &lt;- bind_rows(df1, df2)\ncolnames(df_all)[1:2] &lt;- c(\"X1\", \"X2\")\n\n# Ramka danych ze średnimi\nmeans &lt;- data.frame(\n  X1 = c(y1_bar[1], y2_bar[1]),\n  X2 = c(y1_bar[2], y2_bar[2]),\n  grupa = c(\"Grupa 1\", \"Grupa 2\")\n)\n\n# Wykres\nggplot(df_all, aes(x = X1, y = X2, color = grupa, shape = grupa)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_point(data = means, aes(x = X1, y = X2),\n             shape = c(1, 2), size = 5, stroke = 1.2, show.legend = FALSE) +\n  scale_shape_manual(values = c(16, 17)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"Porównanie dwóch grup\",\n       x = \"X1\", y = \"X2\", color = \"Grupa\", shape = \"Grupa\")\n\n\n\n\n\n\n\n\n\n\n\nKod\n# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)\n\n\nW analizowanym przykładzie zdefiniowaliśmy macierze kowariancji identycznie ale w rzeczywistości należałoby testować hipotezę o równości macierzy kowariancji. Tylko dla celów ćwiczeniowych pokażę jak to zrobić.\n\n\nKod\n# Test Boxa na równość macierzy kowariancji\nlibrary(biotools)\nboxM(rbind(Y1, Y2), factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  rbind(Y1, Y2)\nChi-Sq (approx.) = 2.1261, df = 3, p-value = 0.5466\n\n\nKod\n# lub z wykorzystaniem pakietu rstatix\nlibrary(rstatix)\nbox_m(df_all[,-3], df_all[,3])\n\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                                            \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                             \n1      2.13   0.547         3 Box's M-test for Homogeneity of Covariance Matric…\n\n\n\n\n\n\n\n\n\nWskazówka\n\n\n\nW sytuacji, gdy założenie o równości macierzy kowariancji jest naruszone, można stosować alternatywne metody, takie jak:\n\nTesty permutacyjne (Hotelling::hotelling.test(X1, X2, perm = TRUE, B = 5000)).\nUogólniony test Hotellinga - test James (ang. James’s second-order test) lub czasami nazywany również testem Welch-type Hotelling test (Hotelling::hotelling.test(X1, X2, var.equal = FALSE)).\nW przypadku danych charakteryzujących się dużą liczbą zmiennych w stosunku do liczby obserwacji, można rozważyć użycie estymatora Jamesa-Steina do stabilizaji macierzy kowariancji (Hotelling::hotelling.test(X1, X2, shrinkage = TRUE)).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-porównanie-dwóch-grup-w-r",
    "href": "multi_tests.html#przykład-porównanie-dwóch-grup-w-r",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Przykład: porównanie dwóch grup w R",
    "text": "1.4 Przykład: porównanie dwóch grup w R\n\n\nKod\nlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n\n[1] \"Statystyka T² = 17.340\"\n\n\nKod\nsprintf(\"Statystyka F = %.3f\", F_stat)\n\n\n[1] \"Statystyka F = 8.532\"\n\n\nKod\nsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n\n[1] \"Wartość krytyczna F = 3.145\"\n\n\nKod\nsprintf(\"p-value = %e\", p_val)\n\n\n[1] \"p-value = 5.330310e-04\"\n\n\nKod\n# Wizualizacja \nplot(Y1, col = \"blue\", pch = 16, xlim = range(c(Y1[,1], Y2[,1])), ylim = range(c(Y1[,2], Y2[,2])),\n     xlab = \"X1\", ylab = \"X2\", main = \"Porównanie dwóch grup\")\npoints(Y2, col = \"red\", pch = 17)\nlegend(\"topright\", legend = c(\"Grupa 1\", \"Grupa 2\"), col = c(\"blue\", \"red\"), pch = c(16,17))\npoints(y1_bar[1], y1_bar[2], col = \"darkblue\", pch = 1, cex = 2)\npoints(y2_bar[1], y2_bar[2], col = \"darkred\", pch = 2, cex = 2)\n\n\n\n\n\n\n\n\n\n\n\nKod\n# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#wprowadzenie-do-manova",
    "href": "multi_tests.html#wprowadzenie-do-manova",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Wprowadzenie do MANOVA",
    "text": "1.4 Wprowadzenie do MANOVA\nW przypadku porównywania więcej niż dwóch grup nie możemy już stosować testu Hotellinga. Odpowiednikiem testu ANOVA w przestrzeni wielowymiarowej jest MANOVA – analiza wariancji dla wielu zmiennych. Testujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = \\ldots = \\boldsymbol{\\mu}_g\n\\]\ngdzie \\(g\\) to liczba grup. Szczegóły konstrukcji testów Wilksa, Lawleya-Hotellinga czy Roy’a zostaną przedstawione w dalszych wykładach.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#podsumowanie",
    "href": "multi_tests.html#podsumowanie",
    "title": "Testy wielowymiarowe",
    "section": "Podsumowanie",
    "text": "Podsumowanie\nTesty wielowymiarowe pozwalają na kompleksowe testowanie hipotez dotyczących wektorów średnich. Stanowią naturalne rozszerzenie klasycznych testów jednowymiarowych i eliminują błędy wynikające z wielokrotnego testowania oraz nieuwzględniania współzależności między cechami. W kolejnych częściach wykładu rozwiniemy tematykę MANOVA oraz testów dla bardziej złożonych struktur danych.\n\n\n\n\nRencher, Alvin C. 1998. Multivariate statistical inference and applications. T. 635. Wiley New York.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-dla-boldsymbolmu-boldsymbolmu_0-przy-znanej-macierzy-kowariancji",
    "href": "multi_tests.html#test-dla-boldsymbolmu-boldsymbolmu_0-przy-znanej-macierzy-kowariancji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "",
    "text": "Przykład 1.1 (Test Hotellinga \\(T^2\\) dla znanej macierzy kowariancji)  \n\n\nKod\nset.seed(44)\nmu0 &lt;- c(170, 70)\nSigma &lt;- matrix(c(100, 40, 40, 100), nrow = 2)\nn &lt;- 30\n\n# Generowanie danych\nX &lt;- MASS::mvrnorm(n = n, mu = mu0, Sigma = Sigma)\n\n# Weryfikacja hipotezy H0: mu = mu0\nx_bar &lt;- colMeans(X)\nT2 &lt;- n * t(x_bar - mu0) %*% solve(Sigma) %*% (x_bar - mu0)\nsprintf('T2 = %.3f', T2)\n\n\n[1] \"T2 = 0.670\"\n\n\nKod\nsprintf('p-value=%.3f', pchisq(T2, df = 2, lower.tail = FALSE))\n\n\n[1] \"p-value=0.715\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#estymatory-średnich",
    "href": "multi_tests.html#estymatory-średnich",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Estymatory średnich",
    "text": "1.4 Estymatory średnich\nWektory średnich z próby wyrażamy jako:\n[ {}1 = ^{n_1} {1,i}, {}2 = ^{n_2} ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#estymatory-kowariancji-i-ich-połączenie",
    "href": "multi_tests.html#estymatory-kowariancji-i-ich-połączenie",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.5 Estymatory kowariancji i ich połączenie",
    "text": "1.5 Estymatory kowariancji i ich połączenie\nNieobciążonym estymatorem macierzy kowariancji ( ) jest tzw. połączony estymator kowariancji:\n[ = ]\ngdzie:\n[ 1 = ^{n_1} (_{1,i} - {}1)( - {}_1)^ ]\n[ 2 = ^{n_2} (_{2,i} - {}2)( - {}_2)^ ]\nZatem:\n[ = ]\ngdzie:\n[ 1 = ^{n_1} (_{1,i} - {}1)( - {}_1)^= (n_1 - 1)_1 ]\n[ 2 = ^{n_2} (_{2,i} - {}2)( - {}_2)^= (n_2 - 1)_2 ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#statystyka-testowa",
    "href": "multi_tests.html#statystyka-testowa",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.6 Statystyka testowa",
    "text": "1.6 Statystyka testowa\nStatystyka testowa Hotellinga ma postać:\n[ T^2 = ({}_1 - {}_2) ({}_1 - {}_2) ]\nGdy ( H_0 ) jest prawdziwa, to po przekształceniu:\n[ F = T^2 F_{p, n_1 + n_2 - p - 1} ]\nAlternatywnie, można zapisać, że:\n[ T^2 F_{p, n_1 + n_2 - p - 1} ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#kryterium-decyzji",
    "href": "multi_tests.html#kryterium-decyzji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.7 Kryterium decyzji",
    "text": "1.7 Kryterium decyzji\nHipotezę zerową ( H_0: _1 = _2 ) odrzucamy na poziomie istotności ( ), jeśli:\n[ T^2 &gt; T^2_{, p, n_1 + n_2 - 2} ]\nlub równoważnie:\n[ F &gt; F_{, p, n_1 + n_2 - p - 1} ]\n\n\n1.7.1 Warunek zastosowania testu\nAby test był możliwy do przeprowadzenia, konieczne jest, aby:\n[ n_1 + n_2 - 2 &gt; p ]\nczyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n1.7.2 Uwaga praktyczna\nW praktyce istotne jest, aby przed zastosowaniem testu Hotellinga T² dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa lub poprzez ocenę wykresów rozrzutu. W przypadku jego naruszenia należy rozważyć zastosowanie testów niewymagających tego założenia lub podejść uogólnionych.\nRozważmy dwie próby \\(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_{n_1} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma})\\) oraz \\(\\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_{n_2} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_2, \\boldsymbol{\\Sigma})\\). Chcemy zwerfykikować hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\n\\]\nStatystyka testowa:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{x}} - \\bar{\\boldsymbol{y}})^T \\mathbf{S}_p^{-1} (\\bar{\\boldsymbol{x}} - \\bar{\\boldsymbol{y}})\n\\]\ngdzie \\(\\mathbf{S}_p\\) to tzw. macierz kowariancji połączonej (pooled covariance):\n\\[\n\\mathbf{S}_p = \\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#uwaga-praktyczna",
    "href": "multi_tests.html#uwaga-praktyczna",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Uwaga praktyczna",
    "text": "1.4 Uwaga praktyczna\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#założenia",
    "href": "multi_tests.html#założenia",
    "title": "Testy wielowymiarowe",
    "section": "Założenia",
    "text": "Założenia\n\nPróby są niezależne;\nObserwacje w każdej grupie pochodzą z rozkładu wielowymiarowego normalnego;\n\nMacierze kowariancji są równe \\(\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}\\). Jest to kluczowe założenie umożliwiające zbudowanie wspólnego estymatora kowariancji i zastosowanie rozkładu \\(T^2\\) Hotellinga. Choć może być ono naruszone w praktyce, to dla dużych prób test zachowuje swoje właściwości asymptotyczne (Rencher 1998).\n\nWektory średnich z próby wyrażamy jako:\n\\[\n\\bar{\\boldsymbol{y}}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} \\boldsymbol{y}_{1,i}, \\quad\n\\bar{\\boldsymbol{y}}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} \\boldsymbol{y}_{2,i}\n\\]\nNieobciążonym estymatorem macierzy kowariancji (\\(\\boldsymbol{\\Sigma}\\)) jest tzw. połączony estymator kowariancji:\n\\[\n\\mathbf{S} =\n\\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\] gdzie \\[\n\\mathbf{S}_1 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top\n\\]\n\\[\n\\mathbf{S}_2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top\n\\]\nZatem:\n\\[\n\\mathbf{S} = \\frac{\\mathbf{W}_1 + \\mathbf{W}_2}{n_1 + n_2 - 2}\n\\] gdzie: \\[\n\\mathbf{W}_1 = \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top = (n_1 - 1)\\mathbf{S}_1\n\\]\n\\[\n\\mathbf{W}_2 = \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top = (n_2 - 1)\\mathbf{S}_2\n\\] Statystyka testowa Hotellinga wówczas ma postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)\n\\]\nA gdy \\(H_0\\) jest prawdziwa, to po przekształceniu: \\[\nF = \\frac{(n_1 + n_2 - p - 1)}{p(n_1 + n_2 - 2)} T^2 \\sim F_{p, n_1 + n_2 - p - 1}\n\\]\nAlternatywnie, można zapisać, że: \\[\nT^2 \\sim \\frac{p(n_1 + n_2 - 2)}{n_1 + n_2 - p - 1} F_{p, n_1 + n_2 - p - 1}\n\\]\nHipotezę zerową \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) odrzucamy na poziomie istotności \\(\\alpha\\), jeśli: \\[\nT^2 &gt; T^2_{\\alpha, p, n_1 + n_2 - 2}\n\\] lub równoważnie: \\[\nF &gt; F_{\\alpha, p, n_1 + n_2 - p - 1}\n\\]\nAby test był możliwy do przeprowadzenia, konieczne jest, aby \\(n_1 + n_2 - 2 &gt; p\\), czyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n\n\n\nAdnotacja\n\n\n\nW praktyce istotne jest, aby przed zastosowaniem testu \\(T^2\\) Hotellinga dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa. Test M Boxa (ang. Box’s M test) służy do statystycznej weryfikacji hipotezy równości macierzy kowariancji w wielu grupach.\nZałóżmy, że mamy \\(G\\) niezależnych prób z wielowymiarowego rozkładu normalnego:\n\\[\n\\boldsymbol{y}_{g} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_g, \\boldsymbol{\\Sigma}_g), \\quad g = 1, \\ldots, G\n\\] Testujemy hipotezę: \\[\nH_0: \\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\ldots = \\boldsymbol{\\Sigma}_G = \\boldsymbol{\\Sigma}\n\\] przeciwko alternatywie: \\[\nH_1: \\exists\\, g, h: \\boldsymbol{\\Sigma}_g \\ne \\boldsymbol{\\Sigma}_h\n\\] Niech\n\n\n\\(\\mathbf{S}_g\\) – macierz kowariancji w grupie \\(g\\),\n\n\\(n_g\\) – liczba obserwacji w grupie \\(g\\),\n\n\\(\\mathbf{S}_p\\) – połączony estymator macierzy kowariancji:\n\n\\[\n\\mathbf{S}_p = \\frac{1}{N - G} \\sum_{g=1}^G (n_g - 1)\\mathbf{S}_g\n\\] gdzie \\(N = \\sum_{g=1}^G n_g\\) – łączna liczba obserwacji. Wówczas, statystyka testowa Boxa ma postać: \\[\nM = (N - G) \\cdot \\ln|\\mathbf{S}_p| - \\sum_{g=1}^G (n_g - 1) \\cdot \\ln|\\mathbf{S}_g|\n\\] Poprawka na skończoną próbkę prowadzi do statystyki: \\[\nC = \\left(1 - c\\right) \\cdot M\n\\] gdzie: \\[\nc = \\frac{1}{3(p + 1)(G - 1)} \\left[ \\sum_{g=1}^G \\frac{1}{n_g - 1} - \\frac{1}{N - G} \\right]\n\\] Statystyka \\(C\\) jest asymptotycznie zbierzna do rozkładu \\(\\chi^2\\left(\\frac{p}{2}(p + 1)(G - 1)\\right)\\) liczbą stopni swobody.\nHipotezę \\(H_0\\) o równości macierzy kowariancji odrzuca się, jeśli: \\[\nC &gt; \\chi^2_{1 - \\alpha, df}\n\\] lub gdy \\(p\\) testu jest mniejsza od poziomu istotności \\(\\alpha\\).\nUwagi praktyczne\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.\n\n\n\n\nPrzykład 4.1 (Porównanie dwóch grup za pomocą testu \\(T^2\\) Hotellinga)  \n\nKodlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n[1] \"Statystyka T² = 17.340\"\n\nKodsprintf(\"Statystyka F = %.3f\", F_stat)\n\n[1] \"Statystyka F = 8.532\"\n\nKodsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n[1] \"Wartość krytyczna F = 3.145\"\n\nKodsprintf(\"p-value = %e\", p_val)\n\n[1] \"p-value = 5.330310e-04\"\n\nKod# Wizualizacja \ndf1 &lt;- as.data.frame(Y1) %&gt;%\n  mutate(grupa = \"Grupa 1\")\n\ndf2 &lt;- as.data.frame(Y2) %&gt;%\n  mutate(grupa = \"Grupa 2\")\n\ndf_all &lt;- bind_rows(df1, df2)\ncolnames(df_all)[1:2] &lt;- c(\"X1\", \"X2\")\n\n# Ramka danych ze średnimi\nmeans &lt;- data.frame(\n  X1 = c(y1_bar[1], y2_bar[1]),\n  X2 = c(y1_bar[2], y2_bar[2]),\n  grupa = c(\"Grupa 1\", \"Grupa 2\")\n)\n\n# Wykres\nggplot(df_all, aes(x = X1, y = X2, color = grupa, shape = grupa)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_point(data = means, aes(x = X1, y = X2),\n             shape = c(1, 2), size = 5, stroke = 1.2, show.legend = FALSE) +\n  scale_shape_manual(values = c(16, 17)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"Porównanie dwóch grup\",\n       x = \"X1\", y = \"X2\", color = \"Grupa\", shape = \"Grupa\")\n\n\n\n\n\n\n\n\nKod# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)\n\n\nW analizowanym przykładzie zdefiniowaliśmy macierze kowariancji identycznie ale w rzeczywistości należałoby testować hipotezę o równości macierzy kowariancji. Tylko dla celów ćwiczeniowych pokażę jak to zrobić.\n\nKod# Test Boxa na równość macierzy kowariancji\nlibrary(biotools)\nboxM(rbind(Y1, Y2), factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  rbind(Y1, Y2)\nChi-Sq (approx.) = 2.1261, df = 3, p-value = 0.5466\n\nKod# lub z wykorzystaniem pakietu rstatix\nlibrary(rstatix)\nbox_m(df_all[,-3], df_all[,3])\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                                            \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                             \n1      2.13   0.547         3 Box's M-test for Homogeneity of Covariance Matric…\n\n\n\n\n\n\n\n\n\nWskazówka\n\n\n\nW sytuacji, gdy założenie o równości macierzy kowariancji jest naruszone, można stosować alternatywne metody, takie jak:\n\nTesty permutacyjne (Hotelling::hotelling.test(Y~Group, perm = TRUE, B = 5000)).\nUogólniony test Hotellinga - test Jamesa (ang. James’s second-order test) lub czasami nazywany również testem Welch-type Hotelling test (Hotelling::hotelling.test(Y~Group, var.equal = FALSE)).\nW przypadku danych charakteryzujących się dużą liczbą zmiennych w stosunku do liczby obserwacji, można rozważyć użycie estymatora Jamesa-Steina do stabilizaji macierzy kowariancji (Hotelling::hotelling.test(Y~Group, shrinkage = TRUE)).\n\n\n\n\n\n\n\n\n\nAdnotacja\n\n\n\nOdrzucenie hipotezy zerowej \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) w teście Hotellinga \\(T^2\\) oznacza, że mamy statystycznie istotny dowód na to, iż rozkłady średnich wektorów dwóch populacji wielowymiarowych różnią się, biorąc pod uwagę współzmienność między zmiennymi. W kontekście zastosowań praktycznych, oznacza to, że przynajmniej jedna zmienna (lub kombinacja zmiennych) odróżnia grupy, nawet jeśli nie da się tego wykazać za pomocą testów jednowymiarowych.\nW sytuacji, gdy mamy dane wielowymiarowe \\(\\boldsymbol{y}_{gi} \\in \\mathbb{R}^p\\) z dwóch niezależnych grup (\\(g = 1,2\\)), testujemy:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu}_1 \\neq \\boldsymbol{\\mu}_2.\n\\]\nOdrzucenie \\(H_0\\) sugeruje, że istnieje różnica pomiędzy średnimi wektorami, ale nie musi oznaczać, że którakolwiek ze średnich poszczególnych zmiennych \\(\\mu_{1j}, \\mu_{2j}\\) różni się istotnie — zwłaszcza jeśli uwzględnimy korelacje między zmiennymi.\nTesty jednowymiarowe ignorują te współzależności, dlatego mogą nie wykazać istotnych różnic, mimo że ogólny profil wielowymiarowy się różni. Innymi słowy, może nie istnieć żadna istotna różnica w poszczególnych zmiennych, ale pewna kombinacja liniowa tych zmiennych pozwala na rozróżnienie grup.\nRozważmy kombinację liniową:\n\\[\nz = \\boldsymbol{a}^\\top \\boldsymbol{y},\n\\]\ngdzie \\(\\boldsymbol{a} \\in \\mathbb{R}^p\\) to niezerowy wektor wag. Wówczas \\(z\\) jest jednowymiarową zmienną losową będącą projekcją obserwacji \\(\\boldsymbol{y}\\) na kierunek \\(\\boldsymbol{a}\\).\nJeśli hipoteza \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) jest fałszywa, to istnieje taki wektor \\(\\boldsymbol{a}\\), dla którego:\n\\[\nH_0: \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_1 = \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_2\n\\]\nzostanie odrzucona w teście jednowymiarowym. Dla takiej kombinacji liniowej możemy zdefiniować statystykę \\(t\\)-Studenta:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\bar{z}_1 - \\bar{z}_2}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) s_z^2}},\n\\]\ngdzie:\n\n\n\\(\\bar{z}_g = \\boldsymbol{a}^\\top \\bar{\\boldsymbol{y}}_g\\) – średnia z projekcji grupy \\(g\\),\n\n\\(s_z^2\\) – nieobciążony estymator wariancji \\(z\\), czyli:\n\n\\[\ns_z^2 = \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a},\n\\]\na \\(\\mathbf{S}\\) to wspólna macierz kowariancji.\nStąd pełna postać statystyki:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\boldsymbol{a}^\\top (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a}}}.\n\\]\nPonieważ statystyka \\(t(\\boldsymbol{a})\\) może być zarówno dodatnia, jak i ujemna, stosuje się często jej kwadrat jako miarę istotności:\n\\[\nT^2 = t^2(\\boldsymbol{a}).\n\\]\nStatystyka Hotellinga \\(T^2\\) przyjmuje postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nJest to forma uogólnionej odległości Mahalanobisa między średnimi wektorami. Można pokazać, że istnieje taki wektor \\(\\boldsymbol{a}\\), który maksymalizuje różnicę \\(t(\\boldsymbol{a})\\) — to tzw. funkcja dyskryminacyjna:\n\\[\n\\boldsymbol{a} = \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nDla tej wartości wektora \\(\\boldsymbol{a}\\), statystyka \\(T^2\\) przyjmuje największą wartość i jest najbardziej czuła na różnice między grupami.\nOdrzucenie \\(H_0\\) oznacza więc, że w przestrzeni \\(\\mathbb{R}^p\\) istnieje kierunek \\(\\boldsymbol{a}\\), dla którego grupy mają różne średnie projekcje. To otwiera drogę do:\n\nkonstrukcji funkcji dyskryminacyjnych (jak w analizie dyskryminacyjnej),\nidentyfikacji zmiennych lub ich kombinacji odpowiedzialnych za różnicę,\ndalszych analiz jednowymiarowych dla projekcji \\(z = \\boldsymbol{a}^\\top \\boldsymbol{y}\\).\n\n\nKodlibrary(gridExtra)  # dla strzałki jako warstwy\n\nset.seed(42)\n\n# Parametry\nn1 &lt;- n2 &lt;- 100\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1.5, 0.5)\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), ncol = 2)\n\n# Dane\nY1 &lt;- mvrnorm(n1, mu1, Sigma)\nY2 &lt;- mvrnorm(n2, mu2, Sigma)\n\n# Średnie\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymacja wspólnej kowariancji\nS_pooled &lt;- ((n1 - 1) * cov(Y1) + (n2 - 1) * cov(Y2)) / (n1 + n2 - 2)\n\n# Kierunek dyskryminacyjny a\ndiff &lt;- y1_bar - y2_bar\na &lt;- solve(S_pooled, diff)\na_norm &lt;- a / sqrt(sum(a^2))  # normalizacja\n\n# Punkt startowy strzałki (środek między średnimi)\norigin &lt;- (y1_bar + y2_bar) / 2\nscale &lt;- 3  # długość strzałki\narrow_end &lt;- origin + scale * a_norm\n\n# Ramka danych do wykresu\ndf &lt;- rbind(\n  data.frame(X1 = Y1[,1], X2 = Y1[,2], Grupa = \"Grupa 1\"),\n  data.frame(X1 = Y2[,1], X2 = Y2[,2], Grupa = \"Grupa 2\")\n)\n\n# Wektory średnich i strzałka\nmeans_df &lt;- data.frame(rbind(y1_bar, y2_bar))\ncolnames(means_df) &lt;- c(\"X1\", \"X2\")\nmeans_df$Grupa &lt;- c(\"Grupa 1\", \"Grupa 2\")  # te same etykiety co w danych punktów\n\narrow_df &lt;- data.frame(\n  x = origin[1],\n  y = origin[2],\n  xend = arrow_end[1],\n  yend = arrow_end[2]\n)\n\n# Wykres\nggplot(df, aes(x = X1, y = X2, color = Grupa)) +\n  geom_point(alpha = 0.5) +\n  geom_point(data = means_df, aes(x = X1, y = X2),\n             size = 4, shape = 16, show.legend = FALSE) +  # średnie tym samym kolorem; bez legendy\n  geom_segment(data = arrow_df, \n               aes(x = x, y = y, xend = xend, yend = yend),\n               arrow = arrow(length = unit(0.25, \"cm\")), color = \"black\", size = 1, show.legend = FALSE) +\n  labs(\n    title = latex2exp::TeX(r\"(Ilustracja kierunku dyskryminacyjnego $a = S^{-1} (\\bar{y}_1 - \\bar{y}_2)$)\"),\n    x = latex2exp::TeX(r\"($X_1$)\"),\n    y = latex2exp::TeX(r\"($X_2$)\")\n  ) +\n  coord_equal() +\n  theme_minimal() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#ujęcie-ogólne-i-ograniczenia-testów-jednowymiarowych",
    "href": "multi_tests.html#ujęcie-ogólne-i-ograniczenia-testów-jednowymiarowych",
    "title": "Testy wielowymiarowe",
    "section": "Ujęcie ogólne i ograniczenia testów jednowymiarowych",
    "text": "Ujęcie ogólne i ograniczenia testów jednowymiarowych\nW sytuacji, gdy mamy dane wielowymiarowe \\(\\boldsymbol{y}_{gi} \\in \\mathbb{R}^p\\) z dwóch niezależnych grup (\\(g = 1,2\\)), testujemy:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu}_1 \\neq \\boldsymbol{\\mu}_2.\n\\]\nOdrzucenie \\(H_0\\) sugeruje, że istnieje różnica pomiędzy średnimi wektorami, ale nie musi oznaczać, że którakolwiek ze średnich poszczególnych zmiennych \\(\\mu_{1j}, \\mu_{2j}\\) różni się istotnie — zwłaszcza jeśli uwzględnimy korelacje między zmiennymi.\nTesty jednowymiarowe ignorują te współzależności, dlatego mogą nie wykazać istotnych różnic, mimo że ogólny profil wielowymiarowy się różni. Innymi słowy, może nie istnieć żadna istotna różnica w poszczególnych zmiennych, ale pewna kombinacja liniowa tych zmiennych pozwala na rozróżnienie grup.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#wprowadzenie-kombinacji-liniowych-i-statystyki-ta",
    "href": "multi_tests.html#wprowadzenie-kombinacji-liniowych-i-statystyki-ta",
    "title": "Testy wielowymiarowe",
    "section": "Wprowadzenie kombinacji liniowych i statystyki \\(t(a)\\)\n",
    "text": "Wprowadzenie kombinacji liniowych i statystyki \\(t(a)\\)\n\nRozważmy kombinację liniową:\n\\[\nz = \\boldsymbol{a}^\\top \\boldsymbol{y},\n\\]\ngdzie \\(\\boldsymbol{a} \\in \\mathbb{R}^p\\) to niezerowy wektor wag. Wówczas \\(z\\) jest jednowymiarową zmienną losową będącą projekcją obserwacji \\(\\boldsymbol{y}\\) na kierunek \\(\\boldsymbol{a}\\).\nJeśli hipoteza \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) jest fałszywa, to istnieje taki wektor \\(\\boldsymbol{a}\\), dla którego:\n\\[\nH_0: \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_1 = \\boldsymbol{a}^\\top \\boldsymbol{\\mu}_2\n\\]\nzostanie odrzucona w teście jednowymiarowym. Dla takiej kombinacji liniowej możemy zdefiniować statystykę \\(t\\)-Studenta:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\bar{z}_1 - \\bar{z}_2}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) s_z^2}},\n\\]\ngdzie:\n\n\n\\(\\bar{z}_g = \\boldsymbol{a}^\\top \\bar{\\boldsymbol{y}}_g\\) – średnia z projekcji grupy \\(g\\),\n\n\\(s_z^2\\) – nieobciążony estymator wariancji \\(z\\), czyli:\n\n\\[\ns_z^2 = \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a},\n\\]\na \\(\\mathbf{S}\\) to wspólna macierz kowariancji.\nStąd pełna postać statystyki:\n\\[\nt(\\boldsymbol{a}) = \\frac{\\boldsymbol{a}^\\top (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)}{\\sqrt{\\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) \\boldsymbol{a}^\\top \\mathbf{S} \\boldsymbol{a}}}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#statystyka-t2-jako-funkcja-maksymalnej-różnicy",
    "href": "multi_tests.html#statystyka-t2-jako-funkcja-maksymalnej-różnicy",
    "title": "Testy wielowymiarowe",
    "section": "Statystyka \\(T^2\\) jako funkcja maksymalnej różnicy",
    "text": "Statystyka \\(T^2\\) jako funkcja maksymalnej różnicy\nPonieważ statystyka \\(t(\\boldsymbol{a})\\) może być zarówno dodatnia, jak i ujemna, stosuje się często jej kwadrat jako miarę istotności:\n\\[\nT^2 = t^2(\\boldsymbol{a}).\n\\]\nStatystyka Hotellinga \\(T^2\\) przyjmuje postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nJest to forma uogólnionej odległości Mahalanobisa między średnimi wektorami. Można pokazać, że istnieje taki wektor \\(\\boldsymbol{a}\\), który maksymalizuje różnicę \\(t(\\boldsymbol{a})\\) — to tzw. funkcja dyskryminacyjna:\n\\[\n\\boldsymbol{a} = \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2).\n\\]\nDla tej wartości wektora \\(\\boldsymbol{a}\\), statystyka \\(T^2\\) przyjmuje największą wartość i jest najbardziej czuła na różnice między grupami.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#znaczenie-praktyczne",
    "href": "multi_tests.html#znaczenie-praktyczne",
    "title": "Testy wielowymiarowe",
    "section": "Znaczenie praktyczne",
    "text": "Znaczenie praktyczne\nOdrzucenie \\(H_0\\) oznacza więc, że w przestrzeni \\(\\mathbb{R}^p\\) istnieje kierunek \\(\\boldsymbol{a}\\), dla którego grupy mają różne średnie projekcje. To otwiera drogę do:\n\nkonstrukcji funkcji dyskryminacyjnych (jak w analizie dyskryminacyjnej),\nidentyfikacji zmiennych lub ich kombinacji odpowiedzialnych za różnicę,\ndalszych analiz jednowymiarowych dla projekcji \\(z = \\boldsymbol{a}^\\top \\boldsymbol{y}\\).\n\n\nKodlibrary(gridExtra)  # dla strzałki jako warstwy\n\nset.seed(42)\n\n# Parametry\nn1 &lt;- n2 &lt;- 100\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1.5, 1)\nSigma &lt;- matrix(c(1, 0.85, 0.85, 1), ncol = 2)\n\n# Dane\nY1 &lt;- mvrnorm(n1, mu1, Sigma)\nY2 &lt;- mvrnorm(n2, mu2, Sigma)\n\n# Średnie\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymacja wspólnej kowariancji\nS_pooled &lt;- ((n1 - 1) * cov(Y1) + (n2 - 1) * cov(Y2)) / (n1 + n2 - 2)\n\n# Kierunek dyskryminacyjny a\ndiff &lt;- y1_bar - y2_bar\na &lt;- solve(S_pooled, diff)\na_norm &lt;- a / sqrt(sum(a^2))  # normalizacja\n\n# Punkt startowy strzałki (środek między średnimi)\norigin &lt;- (y1_bar + y2_bar) / 2\nscale &lt;- 3  # długość strzałki\narrow_end &lt;- origin + scale * a_norm\n\n# Ramka danych do wykresu\ndf &lt;- rbind(\n  data.frame(X1 = Y1[,1], X2 = Y1[,2], Grupa = \"Grupa 1\"),\n  data.frame(X1 = Y2[,1], X2 = Y2[,2], Grupa = \"Grupa 2\")\n)\n\n# Wektory średnich i strzałka\nmeans_df &lt;- data.frame(rbind(y1_bar, y2_bar))\ncolnames(means_df) &lt;- c(\"X1\", \"X2\")\nmeans_df$Grupa &lt;- c(\"Średnia 1\", \"Średnia 2\")\n\narrow_df &lt;- data.frame(\n  x = origin[1],\n  y = origin[2],\n  xend = arrow_end[1],\n  yend = arrow_end[2]\n)\n\n# Wykres\nggplot(df, aes(x = X1, y = X2, color = Grupa)) +\n  geom_point(alpha = 0.5) +\n  geom_point(data = means_df, aes(x = X1, y = X2, color = Grupa), size = 4, shape = 17) +\n  geom_segment(data = arrow_df, \n               aes(x = x, y = y, xend = xend, yend = yend),\n               arrow = arrow(length = unit(0.25, \"cm\")), color = \"darkgreen\", size = 1) +\n  labs(\n    title = TeX(\"Ilustracja kierunku dyskryminacyjnego $a = \\\\mathbf{S}^{-1} (\\\\bar{\\\\boldsymbol{y}}_1 - \\\\bar{\\\\boldsymbol{y}}_2)$\"),\n    x = TeX(\"$X_1$\"),\n    y = TeX(\"$X_2$\")\n  ) +\n  coord_equal() +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#założenia-i-testowane-hipotezy",
    "href": "multi_tests.html#założenia-i-testowane-hipotezy",
    "title": "Testy wielowymiarowe",
    "section": "Założenia i testowane hipotezy",
    "text": "Założenia i testowane hipotezy\nZakłada się, że obserwacje są niezależne i pochodzą z wielowymiarowego rozkładu normalnego w każdej grupie, tj.:\n\\[\n\\boldsymbol{y}_{ij} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}), \\quad i = 1, \\dots, g,\\ j = 1, \\dots, n_i,\n\\]\ngdzie:\n\n\n\\(\\boldsymbol{y}_{ij} \\in \\mathbb{R}^p\\) — wektor obserwacji w grupie \\(i\\),\n\n\\(\\boldsymbol{\\mu}_i\\) — wektor średnich dla grupy \\(i\\),\n\n\\(\\boldsymbol{\\Sigma}\\) — wspólna macierz kowariancji we wszystkich grupach (założenie homogeniczności).\n\nTestowana jest hipoteza zerowa:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = \\dots = \\boldsymbol{\\mu}_g\n\\]\nwobec alternatywy:\n\\[\nH_1: \\exists\\ i,j\\ \\text{takie, że}\\ \\boldsymbol{\\mu}_i \\ne \\boldsymbol{\\mu}_j.\n\\]\nModel MANOVA opiera się na kilku fundamentalnych założeniach dotyczących danych, których spełnienie warunkuje poprawność i wiarygodność uzyskanych wyników. Ich naruszenie może prowadzić do fałszywych wniosków, zbyt dużej liczby odrzuceń hipotezy zerowej lub do błędnych ocen efektów czynników. Poniżej przedstawiono szczegółowo każde z tych założeń.\n\nPierwszym kluczowym założeniem jest odpowiednia wielkość próby. Przyjmuje się, że liczba obserwacji w każdej grupie (komórce) powinna przekraczać liczbę zmiennych zależnych, które są jednocześnie analizowane. To praktyczne zalecenie pozwala uniknąć problemów z oszacowaniem macierzy kowariancji i zapewnia dostateczną moc statystyczną.\nKolejnym istotnym założeniem jest niezależność obserwacji. Oznacza to, że każda jednostka obserwacyjna (np. osoba) powinna przynależeć wyłącznie do jednej grupy. Obserwacje wewnątrz i pomiędzy grupami nie mogą być ze sobą powiązane. W szczególności, model MANOVA nie jest odpowiedni dla danych z pomiarami powtarzanymi u tych samych obiektów. Dobór próby powinien być dokonany w sposób losowy, bez systematycznych zależności.\nTrzecim wymogiem jest brak obserwacji odstających, zarówno w sensie jednowymiarowym (dla każdej zmiennej z osobna), jak i wielowymiarowym (dla kombinacji wszystkich zmiennych zależnych). Obserwacje odstające mogą silnie zniekształcać wartości średnich i macierzy kowariancji, przez co wyniki MANOVA stają się niestabilne.\nFundamentalnym założeniem MANOVA jest wielowymiarowa normalność rozkładu danych w każdej z grup. Oznacza to, że wektor zmiennych zależnych w każdej grupie powinien mieć rozkład wielowymiarowy normalny. W R można zastosować funkcję mshapiro_test() z pakietu rstatix, aby przeprowadzić test Shapiro–Wilka dla sprawdzenia normalności wielowymiarowej.\nKolejne założenie dotyczy braku współliniowości. Oczekuje się, że zmienne zależne będą ze sobą skorelowane w umiarkowany sposób, ale nie nadmiernie. Wartości współczynników korelacji przekraczające \\(r = 0,90\\) są uznawane za niepożądane i mogą powodować problemy numeryczne oraz błędną interpretację wyników. Jak podają Tabachnick i Fidell (2012), zmienne powinny wnosić unikalne informacje do modelu.\nWażnym wymogiem jest również liniowość zależności między zmiennymi zależnymi w każdej grupie. Oznacza to, że zależności pomiędzy każdą parą zmiennych muszą być dobrze opisane przez funkcję liniową — jest to konieczne, aby poprawnie oszacować strukturę kowariancji.\nDla poprawnego działania MANOVA zakłada się także jednorodność wariancji dla każdej zmiennej zależnej między grupami. Można to testować za pomocą testu Levene’a. Nieistotny wynik testu Levene’a sugeruje, że wariancje są porównywalne w grupach.\nOstatnie, ale bardzo istotne, jest założenie o jednorodności macierzy kowariancji (homogeniczności macierzy wariancji–kowariancji) pomiędzy grupami. Oznacza to, że struktura współzależności między zmiennymi powinna być podobna w każdej grupie. Weryfikację tego założenia umożliwia test Boxa (Box’s M test), który stanowi wielowymiarowy odpowiednik testu Levene’a. Ze względu na dużą czułość testu Boxa na odstępstwa od założeń, przyjmuje się konserwatywny poziom istotności \\(\\alpha = 0,001\\) dla weryfikacji jego wyniku.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#konstrukcja-modelu-i-statystyki-testowe",
    "href": "multi_tests.html#konstrukcja-modelu-i-statystyki-testowe",
    "title": "Testy wielowymiarowe",
    "section": "Konstrukcja modelu i statystyki testowe",
    "text": "Konstrukcja modelu i statystyki testowe\nPodobnie jak w jednowymiarowym przypadku, w MANOVA analizuje się rozkład wariancji całkowitej na wariancję międzygrupową i wewnątrzgrupową, ale w postaci macierzy kowariancji:\n\nMacierz wariancji międzygrupowej (ang. between-group SSCP):\n\n\\[\n\\mathbf{B} = \\sum_{i=1}^{g} n_i (\\bar{\\boldsymbol{y}}_i - \\bar{\\boldsymbol{y}})(\\bar{\\boldsymbol{y}}_i - \\bar{\\boldsymbol{y}})^\\top\n\\]\n\nMacierz wariancji wewnątrzgrupowej (ang. within-group SSCP):\n\n\\[\n\\mathbf{W} = \\sum_{i=1}^{g} \\sum_{j=1}^{n_i} (\\boldsymbol{y}_{ij} - \\bar{\\boldsymbol{y}}_i)(\\boldsymbol{y}_{ij} - \\bar{\\boldsymbol{y}}_i)^\\top\n\\]\nMacierz wariancji całkowitej to: \\(\\mathbf{T} = \\mathbf{B} + \\mathbf{W}\\).\nW celu przeprowadzenia testu MANOVA, wykorzystuje się statystyki oparte na stosunku macierzy:\n\\[\n\\mathbf{W}^{-1} \\mathbf{B}\n\\]\nNajczęściej spotykane statystyki testowe to:\n\nWilks’ Lambda:\n\n\\[\n\\Lambda = \\frac{\\det(\\mathbf{W})}{\\det(\\mathbf{B} + \\mathbf{W})}\n\\]\n\nStatystyka Pillai-Bartletta (Trace):\n\n\\[\nV = \\mathrm{tr}\\left[(\\mathbf{B} + \\mathbf{W})^{-1} \\mathbf{B}\\right]\n\\]\n\nStatystyka Hotellinga–Lawleya (Trace):\n\n\\[\nT = \\mathrm{tr}(\\mathbf{W}^{-1} \\mathbf{B})\n\\]\n\nNajwiększy pierwiastek Roy’a:\n\n\\[\n\\theta_{\\text{max}} = \\text{największa wartość własna}\\ (\\mathbf{W}^{-1} \\mathbf{B})\n\\]\nWybór konkretnej statystyki zależy od liczebności prób, wymiaru przestrzeni i liczby grup. W praktyce Wilks’ Lambda jest najczęściej stosowana.\n\nPrzykład 5.1 Na poziomie istotności \\(\\alpha=0.05\\) zweryfikuj hipotezę, że czynnik grupujący (Group) istotnie różnicuje zmienne Actions i Thoughts jednocześnie.\n\nKodlibrary(gtsummary)\nlibrary(rstatix)\nlibrary(easystats)\nlibrary(gt)\ndane &lt;- rio::import(\"data/OCD.dat\")\n\n\nStatystyki opisowe grup\n\nKoddane %&gt;% \n  tbl_summary(by = Group,\n              statistic = list(where(is.numeric) ~ \"{mean} ({sd})\"),\n              type = list(Actions ~ \"continuous\"),\n              digits = list(everything() ~ 2))\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nBT\nN = 101\n\n\nCBT\nN = 101\n\n\nNo Treatment Control\nN = 101\n\n\n\n\nActions\n3.70 (1.77)\n4.90 (1.20)\n5.00 (1.05)\n\n\nThoughts\n15.20 (2.10)\n13.40 (1.90)\n15.00 (2.36)\n\n\n\n\n1 Mean (SD)\n\n\n\n\nKodp &lt;- dane %&gt;% \n  select(-Group) %&gt;% \n  correlation()\n\np %&gt;% print_html()\n\n\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\nParameter1\nParameter2\nr\n95% CI\nt(28)\np\n\n\n\nActions\nThoughts\n0.06\n(-0.31, 0.41)\n0.31\n0.758\n\n\np-value adjustment method: Holm (1979); Observations: 30\n\n\n\n\n\nW kontekście zmiennej Actions widzimy najwyższy poziom w grupie No treatment, natomiast najniższy w grupie BT. Dla zmiennej Thoughts najwyższy poziom osiągnięto w grupie BT a najniższy w grupie CBT. Grupy różnią się również zmiennością obu cech. Związek pomiędzy zmiennymi Actions i Thoughts jest niemal niezauważalny. Korelacja pomiędzy tymi cechami jest nieistotnie różna od zera.\n\nKoddane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  ggplot(aes(x = Group, y = value, fill = name)) +\n  geom_boxplot() +\n  geom_jitter() +\n  labs(fill = \"Variable\", y = \"Response\") +\n  theme_minimal()\n\n\n\n\n\n\n\nPowyższe wykresy potwierdzają znaczne różnice pomiędzy grupami w kontekście analizowanych cech.\nZałożenia\n\nKoddane %&gt;% \n  group_split(Group) %&gt;% \n  map_df(~mshapiro_test(.x[,2:3])) %&gt;% \n  mutate(Group = dane %&gt;% \n           group_keys(Group) %&gt;% \n           pull(Group),\n         .before = statistic) %&gt;%\n  gt() %&gt;% \n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nstatistic\np.value\n\n\n\nBT\n0.891\n0.175\n\n\nCBT\n0.959\n0.777\n\n\nNo Treatment Control\n0.826\n0.030\n\n\n\n\n\n\nJedynie w grupie No treatment nie jest zachowana wielowymiarowa normalność rozkładu analizowanych cech. Można też przeprowadzić testy normalności poszczególnych zmiennych, ale należy pamiętać, że brak podstaw do odrzucenia hipotezy o normalności brzegowych zmiennych nie jest warunkiem dostatecznym, a jedynie koniecznym.\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  shapiro_test(Actions) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nvariable\nstatistic\np\n\n\n\nBT\nActions\n0.872\n0.106\n\n\nCBT\nActions\n0.952\n0.691\n\n\nNo Treatment Control\nActions\n0.859\n0.074\n\n\n\n\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  shapiro_test(Thoughts) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nvariable\nstatistic\np\n\n\n\nBT\nThoughts\n0.877\n0.120\n\n\nCBT\nThoughts\n0.914\n0.310\n\n\nNo Treatment Control\nThoughts\n0.826\n0.030\n\n\n\n\n\n\nPodobnie jak w przypadku wielowymiarowym brak normalności zarysował się w grupie No treatment i to tylko dla zmiennej Thoughts. Teraz przechodzimy do testowania jednorodności kowariancji.\n\nKodbox_m(dane[,2:3], dane$Group)  %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n8.893\n0.180\n6.000\nBox's M-test for Homogeneity of Covariance Matrices\n\n\n\n\n\nNa podstawie powyższego testu można stwierdzić, iż nie ma podstaw do odrzucenia hipotezy o jednorodności macierzy kowariancji.\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  identify_outliers(Actions) \n\n[1] Group      Actions    Thoughts   is.outlier is.extreme\n&lt;0 rows&gt; (or 0-length row.names)\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  identify_outliers(Thoughts) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nGroup\nActions\nThoughts\nis.outlier\nis.extreme\n\n\nNo Treatment Control\n4\n20\nTRUE\nFALSE\n\n\n\n\nKodwhich(dane$Actions == 4 & dane$Thoughts == 20)\n\n[1] 26\n\nKoddane %&gt;% \n  group_by(Group) %&gt;% \n  mahalanobis_distance() %&gt;% \n  filter(is.outlier==TRUE)\n\n# A tibble: 0 × 4\n# ℹ 4 variables: Actions &lt;int&gt;, Thoughts &lt;int&gt;, mahal.dist &lt;dbl&gt;,\n#   is.outlier &lt;lgl&gt;\n\n\nIstnieje jedna obserwacja odstająca w grupie No treatment (obserwacja nr 26). Test wielowymiarowy nie wykrył żadnego elementu odstającego.\nPomimo niespełnienia założenia o wielowymiarowej normalności cech w grupach, zastosujemy test MANOVA.\nManova\n\nKodmod &lt;- manova(cbind(Actions, Thoughts)~Group, data = dane)\nManova(mod) %&gt;% \n  parameters() %&gt;%\n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.32\n4\n54\n2.56\n0.049\n\n\nPillai test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Wilk\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.70\n4\n52\n2.55\n0.050\n\n\nWilks test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Roy\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.33\n2\n27\n4.52\n0.020\n\n\nRoy test statistic Anova Table (Type 2 tests)\n\n\n\n\nKodManova(mod, test = \"Hotelling\") %&gt;% \n  parameters() %&gt;% \n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.41\n4\n50\n2.55\n0.051\n\n\nHotelling-Lawley test statistic Anova Table (Type 2 tests)\n\n\n\n\nKod# model bez obserawcji odstającej\nmod2 &lt;- manova(cbind(Actions, Thoughts)~Group, data = dane[-26,])\nManova(mod2) %&gt;% \n  parameters() %&gt;%\n  print_html()\n\n\n\n\n\n\nModel Summary\n\n\nParameter\ndf\nStatistic\ndf (num.)\ndf (error)\nF\np\n\n\n\nGroup\n2\n0.36\n4\n52\n2.87\n0.032\n\n\nPillai test statistic Anova Table (Type 2 tests)\n\n\n\n\n\nAnalizują wszystkie rodzaje testów Manova, widzimy, że jedynie test Hotellinga-Laweya nie daje podstaw do odrzucenia hipotezy o równości wektorów średnich. Natomiast ponieważ co najmniej jeden z nich wskazał istotność różnic, to przyjmujemy, że są podstawy aby odrzucić hipotezę o równości wektorów średnich pomiędzy grupami. Test wykluczający obserwację odstającą również każe odrzucić hipotezę \\(H_0\\).\nPrzeprowadzimy zatem analizę brzegową.\n\nKoddane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  group_by(name) %&gt;% \n  anova_test(value~Group) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nname\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\nActions\nGroup\n2.000\n27.000\n2.771\n0.080\n\n0.170\n\n\nThoughts\nGroup\n2.000\n27.000\n2.154\n0.136\n\n0.138\n\n\n\n\n\n\nAnaliza brzegowa pokazuje ciekawy wynik, mianowicie, dla żadnej z analizowanych cech testy brzegowe nie wykazały istotnych różnic. To pokazuje jak ważne jest stosowanie testów wielowymiarowych w kontekście porównań grup.\nPost-hoc\nPonieważ testy brzegowe ANOVA nie wykazały różnic, to testów post-hoc nie powinno się wykonywać, ale dla celów ćwiczeniowych pokażę jak je wykonać.\n\nKodpwc &lt;- dane %&gt;% \n  pivot_longer(cols = -Group) %&gt;% \n  group_by(name) %&gt;% \n  games_howell_test(value~Group)\npwc %&gt;% \n  select(-.y.) %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = is.double, decimals = 3)\n\n\n\n\n\nname\ngroup1\ngroup2\nestimate\nconf.low\nconf.high\np.adj\np.adj.signif\n\n\n\nActions\nBT\nCBT\n1.200\n−0.544\n2.944\n0.209\nns\n\n\nActions\nBT\nNo Treatment Control\n1.300\n−0.394\n2.994\n0.148\nns\n\n\nActions\nCBT\nNo Treatment Control\n0.100\n−1.189\n1.389\n0.979\nns\n\n\nThoughts\nBT\nCBT\n−1.800\n−4.085\n0.485\n0.138\nns\n\n\nThoughts\nBT\nNo Treatment Control\n−0.200\n−2.749\n2.349\n0.978\nns\n\n\nThoughts\nCBT\nNo Treatment Control\n1.600\n−0.852\n4.052\n0.244\nns\n\n\n\n\n\n\nTesty post-hoc potwierdzają wyniki testów brzegowych ANOVA, ponieważ brakuje różnic pomiędzy poziomami zmiennych grupujących.\n\n\n\n\n\nRencher, Alvin C. 1998. Multivariate statistical inference and applications. T. 635. Wiley New York.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#weryfikacja-założeń",
    "href": "multi_tests.html#weryfikacja-założeń",
    "title": "Testy wielowymiarowe",
    "section": "Weryfikacja założeń",
    "text": "Weryfikacja założeń\nMANOVA zakłada:\n\n\nWielowymiarową normalność – można ocenić np. testem Roystona lub testem Shapiro dla każdej zmiennej i grupy.\n\nRówność macierzy kowariancji pomiędzy grupami – można testować testem Boxa-M (np. biotools::boxM()).\n\n\n\n\n\nRencher, Alvin C. 1998. Multivariate statistical inference and applications. T. 635. Wiley New York.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  }
]