[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wielowymiarowa analiza danych",
    "section": "",
    "text": "Wstęp\nWielowymiarowa analiza danych stanowi jeden z filarów współczesnej statystyki i eksploracji danych, oferując metody pozwalające zrozumieć strukturę i zależności w zbiorach danych, w których każda obserwacja jest opisana wieloma zmiennymi jednocześnie. W dobie powszechnego dostępu do danych oraz rosnącego zapotrzebowania na ich zaawansowaną analizę, umiejętność stosowania metod wielowymiarowych staje się nieodzowna zarówno w badaniach naukowych, jak i w analizie danych stosowanej w przemyśle, finansach, biologii, medycynie czy naukach społecznych.\nNiniejsza książka została opracowana z myślą o dwóch kierunkach kształcenia akademickiego: matematyce oraz inżynierii i analizie danych. Jej celem jest zapewnienie solidnych podstaw teoretycznych oraz praktycznych umiejętności niezbędnych do stosowania metod wielowymiarowych w rzeczywistych problemach badawczych i aplikacyjnych. Zakres tematyczny książki został dobrany tak, aby uwzględniać zarówno klasyczne metody statystyczne, jak i techniki wykorzystywane we współczesnej analizie danych.\nW pierwszej części książki omówione zostaną testy wielowymiarowe, które stanowią rozszerzenie klasycznych metod statystycznych na przypadki, w których każda obserwacja opisana jest wieloma zmiennymi. Szczególna uwaga zostanie poświęcona testowi Hotellinga T², będącemu odpowiednikiem testu t dla wielu zmiennych, oraz analizie wariancji dla wielu zmiennych (MANOVA), pozwalającej na badanie różnic między grupami z uwzględnieniem współzależności zmiennych. Celem tej części będzie zrozumienie podstaw inferencji w przestrzeni wielowymiarowej i interpretacji wyników testów z uwzględnieniem macierzy kowariancji.\nNastępnie przedstawiona zostanie analiza kanoniczna, która służy do badania zależności pomiędzy dwoma zestawami zmiennych. Czytelnik pozna konstrukcję zmiennych kanonicznych, sposoby ich interpretacji oraz znaczenie wag i korelacji kanonicznych. Analiza ta ma kluczowe znaczenie wszędzie tam, gdzie celem jest znalezienie skorelowanych struktur w dwóch grupach cech, np. w badaniach biologicznych, społecznych lub psychometrycznych.\nKolejna część książki będzie poświęcona analizie czynnikowej (FA), która umożliwia modelowanie współzmienności zestawu zmiennych za pomocą mniejszej liczby zmiennych ukrytych, zwanych czynnikami. Przedstawione zostaną metody estymacji, kryteria wyboru liczby czynników oraz techniki rotacji, które służą lepszej interpretacji wyników. Analiza czynnikowa jest często stosowana w badaniach ankietowych i psychometrycznych, ale znajduje również zastosowanie w analizie danych ekonomicznych i marketingowych.\nW dalszej kolejności wprowadzony zostanie model ścieżkowy oraz jego uogólnienie w postaci modeli równań strukturalnych (SEM). Modele te pozwalają na modelowanie zarówno obserwowalnych, jak i ukrytych zmiennych oraz relacji przyczynowych pomiędzy nimi. Czytelnik pozna strukturę modelu ścieżkowego, pojęcie identyfikowalności, miary dopasowania oraz techniki estymacji parametrów. Modele SEM są obecnie szeroko stosowane w naukach społecznych, biologii, psychologii i ekonomii.\nNastępnie omówione zostaną metody redukcji wymiarowości, których celem jest uproszczenie reprezentacji danych bez utraty istotnej informacji. Kluczową techniką będzie analiza składowych głównych (PCA), która pozwala na znalezienie nowych osi zmienności w danych. Kolejno zaprezentowana zostanie analiza niezależnych składowych (ICA), która poszukuje składników statystycznie niezależnych, co jest szczególnie użyteczne w analizie sygnałów. Obie metody znajdą zastosowanie zarówno w przygotowaniu danych, jak i w ich eksploracji.\nKolejna część książki poświęcona będzie metodom skalowania wielowymiarowego (Multidimensional Scaling, MDS), które umożliwiają odwzorowanie relacji odległościowych pomiędzy obiektami w przestrzeni o mniejszym wymiarze. Wariant metric zakłada zachowanie rzeczywistych wartości odległości, natomiast non-metric koncentruje się na porządku dystansów. Metody te pozwalają uzyskać intuicyjne wizualizacje struktur danych, szczególnie przydatne w psychologii, socjologii czy analizie rynku.\nW uzupełnieniu do klasycznych technik przedstawione zostaną nieliniowe metody redukcji wymiarowości, takie jak t-distributed Stochastic Neighbor Embedding (t-SNE) oraz Uniform Manifold Approximation and Projection (UMAP). Obie techniki pozwalają na odwzorowanie skomplikowanych struktur danych w przestrzeniach dwu- lub trójwymiarowych, zachowując lokalne sąsiedztwa. Choć są to metody przede wszystkim eksploracyjne i wizualizacyjne, ich wartość w analizie dużych zbiorów danych jest trudna do przecenienia.\nNastępnie przedstawiona zostanie analiza skupień, której celem jest odkrywanie naturalnych grup w zbiorze danych. Omówione zostaną zarówno metody hierarchiczne, jak i niehierarchiczne, w tym popularna metoda k-średnich. Poruszona zostanie problematyka doboru liczby skupień oraz oceny stabilności i jakości otrzymanych rozwiązań. Analiza skupień znajduje zastosowanie w segmentacji rynku, biologii molekularnej, diagnostyce medycznej i wielu innych dziedzinach.\nKolejna część książki poświęcona będzie analizie korespondencji, stosowanej do eksploracji związków pomiędzy zmiennymi jakościowymi przedstawionymi w postaci tablicy kontyngencji. Przedstawiona zostanie zarówno analiza korespondencji prosta (dla dwóch zmiennych), jak i złożona (dla więcej niż dwóch). Omówione zostaną interpretacja map percepcyjnych, odwzorowanie profili oraz związki z metodami takimi jak PCA czy MDS.\nOstatni rozdział poświęcony będzie analizie log-liniowej, która umożliwia modelowanie częstości w tablicach wielodzielczych na podstawie interakcji pomiędzy zmiennymi kategorycznymi. Zostaną zaprezentowane modele pełne i uproszczone, zasady testowania złożoności modeli oraz interpretacji parametrów. Analiza log-liniowa jest szczególnie przydatna przy badaniu wielowymiarowych zależności między zmiennymi kategorycznymi w badaniach społecznych, medycznych oraz w analizie zachowań konsumenckich.\nWszystkie metody zostaną zilustrowane przykładami praktycznymi, realizowanymi w języku R. Pozwoli to Czytelnikowi nie tylko zrozumieć teoretyczne podstawy omawianych technik, ale także nabyć umiejętność ich stosowania w praktyce analitycznej.",
    "crumbs": [
      "Wstęp"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nKod\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. „Literate Programming”. Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "multi_tests.html",
    "href": "multi_tests.html",
    "title": "\n1  Testy wielowymiarowe\n",
    "section": "",
    "text": "2 Test Hotellinga dla znanej macierzy kowariancji\nW tradycyjnej analizie statystycznej często koncentrujemy się na porównywaniu grup ze względu na jedną zmienną – np. porównujemy średni wzrost kobiet i mężczyzn, wykorzystując test t-Studenta. Jednak w rzeczywistości badawczej rzadko interesuje nas tylko jedna cecha. Przykładowo, porównując grupy pacjentów, możemy jednocześnie rozważać poziom ciśnienia, cholesterolu i BMI. Albo, analizując dane socjologiczne, chcemy porównać grupy pod względem dochodów, wykształcenia i poziomu zadowolenia z życia.\nUżycie wielu testów jednowymiarowych wydaje się kuszące – testujemy każdą zmienną osobno. Jednak prowadzi to do trzech istotnych problemów:\n\\[\\begin{equation}\n\\mathbb{P}(\\text{co najmniej jeden błąd I rodzaju}) = 1 - (1 - \\alpha)^p = 1 - 0.95^{10} \\approx 0.40\n\\end{equation}\\]\nPowyższe problemy uzasadniają potrzebę stosowania testów wielowymiarowych – uwzględniających strukturę współzmienności między cechami oraz pozwalających na testowanie hipotez dotyczących całych wektorów średnich.\nRozważmy próbkę \\(\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\ldots, \\boldsymbol{x}_n \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), gdzie \\(\\boldsymbol{\\Sigma}\\) jest znana. Oznacza to, że mamy do czynienia z ciągiem niezależnych losowych wektorów \\(\\boldsymbol{x}_i\\), z których każdy ma ten sam wielowymiarowy rozkład normalny o wymiarze \\(p\\), średniej \\(\\boldsymbol{\\mu}\\) i macierzy kowariancji \\(\\boldsymbol{\\Sigma}\\). Każdy wektor \\(\\boldsymbol{x}_i\\) można interpretować jako punkt w przestrzeni \\(\\mathbb{R}^p\\), opisujący \\(p\\) cech (zmiennych) dla jednej obserwacji. Formalnie jest to wektor kolumnowy postaci \\(\\boldsymbol{x}_i = [x_{i1}, x_{i2}, \\ldots, x_{ip}]^\\top\\), gdzie indeks \\(i\\) numeruje jednostki (np. osoby, obiekty pomiaru), a indeksy \\(j = 1, \\ldots, p\\) odpowiadają poszczególnym zmiennym. Wektor ten traktowany jest jako zmienna losowa, ponieważ jego wartości są wynikiem losowego procesu generującego dane. Rozkład \\(\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) jest wielowymiarową wersją rozkładu normalnego. Opisuje on sytuację, w której każda kombinacja liniowa zmiennych losowych w \\(\\boldsymbol{x}_i\\) również ma rozkład normalny, a funkcja gęstości prawdopodobieństwa ma postać zależną od wartości wektora średnich oraz struktury kowariancji. Jest to fundamentalne założenie w klasycznej analizie statystycznej, pozwalające na stosowanie wielu narzędzi statystycznych.\nParametr \\(\\boldsymbol{\\mu} = [\\mu_1, \\mu_2, \\ldots, \\mu_p]^\\top\\) to wektor wartości oczekiwanych każdej z analizowanych zmiennych. Oznacza on przeciętny poziom zmiennej \\(x_{ij}\\) w populacji dla każdej cechy \\(j\\). Jest to parametr istotny z punktu widzenia testowania hipotez, ponieważ wiele testów statystycznych dotyczy właśnie równości lub różnic wektorów średnich między grupami.\nZ kolei macierz \\(\\boldsymbol{\\Sigma}\\) to dodatnio określona, symetryczna macierz kowariancji o wymiarach \\(p \\times p\\). Jej elementy \\(\\sigma_{jj}\\) opisują wariancje poszczególnych zmiennych, natomiast elementy poza główną przekątną \\(\\sigma_{jk}\\) (dla \\(j \\ne k\\)) opisują kowariancje, czyli współzmienność pomiędzy zmiennymi \\(x_{ij}\\) i \\(x_{ik}\\). W analizie wielowymiarowej uwzględnienie tych zależności między cechami jest kluczowe, ponieważ pozwala lepiej zrozumieć strukturę danych i dokonywać bardziej trafnych wniosków statystycznych.\nO próbie \\(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_n\\) zakładamy, że wszystkie obserwacje są niezależne oraz pochodzą z tego samego rozkładu. Oznacza to, że mamy do czynienia z próbą losową, niezależną o identycznych rozkładach (i.i.d.), co jest podstawowym założeniem wielu testów i metod estymacji. Całą próbkę można przedstawić jako macierz danych o wymiarach \\(n \\times p\\), w której wiersze odpowiadają jednostkom, a kolumny cechom.\nW przypadku, gdy macierz kowariancji \\(\\boldsymbol{\\Sigma}\\) jest znana, możemy zastosować uproszczone wersje testów statystycznych, takie jak klasyczny test Hotellinga \\(T^2\\) dla jednej próby. Jest to jednak sytuacja czysto teoretyczna, ponieważ w praktyce \\(\\boldsymbol{\\Sigma}\\) musi być zazwyczaj estymowana na podstawie danych. Pomimo tego, przypadek znanej macierzy jest użyteczny do budowania intuicji, zrozumienia ról poszczególnych parametrów i wyprowadzania własności statystyk testowych.\nChcemy przetestować hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_0 \\quad \\text{vs} \\quad H_1: \\boldsymbol{\\mu} \\neq \\boldsymbol{\\mu}_0\n\\]\nStatystyka testowa opiera się na uogólnionej odległości Mahalanobisa:\n\\[\nT^2 = n (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)^T \\boldsymbol{\\Sigma}^{-1} (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)\n\\]\nPod warunkiem spełnienia \\(H_0\\), statystyka \\(T^2 \\sim \\chi^2_p\\). Zatem możemy porównać wartość \\(T^2\\) z odpowiednim kwantylem rozkładu chi-kwadrat.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-symulacja-w-r",
    "href": "multi_tests.html#przykład-symulacja-w-r",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.2 Przykład (symulacja w R)",
    "text": "1.2 Przykład (symulacja w R)\n\n\nKod\n# set.seed(44)\n# mu0 &lt;- c(170, 70)\n# Sigma &lt;- matrix(c(100, 40, 40, 100), nrow = 2)\n# n &lt;- 30\n# \n# # Generowanie danych\n# X &lt;- MASS::mvrnorm(n = n, mu = mu0, Sigma = Sigma)\n# \n# # Weryfikacja hipotezy H0: mu = mu0\n# x_bar &lt;- colMeans(X)\n# T2 &lt;- n * t(x_bar - mu0) %*% solve(Sigma) %*% (x_bar - mu0)\n# T2\n# pchisq(T2, df = 2, lower.tail = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-hotellinga-t2-dla-nieznanej-kowariancji",
    "href": "multi_tests.html#test-hotellinga-t2-dla-nieznanej-kowariancji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.2 Test Hotellinga \\(T^2\\) dla nieznanej kowariancji",
    "text": "1.2 Test Hotellinga \\(T^2\\) dla nieznanej kowariancji\nW przypadku, gdy próbka \\(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_n \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\), a macierz kowariancji \\(\\boldsymbol{\\Sigma}\\) nie jest znana i musi być estymowana z danych, testujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_0\n\\]\nprzy pomocy statystyki Hotellinga:\n\\[\nT^2 = n (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{x}} - \\boldsymbol{\\mu}_0)\n\\]\nW przeciwieństwie do przypadku znanej macierzy kowariancji, statystyka \\(T^2\\) nie ma rozkładu chi-kwadrat. W rzeczywistości jej rozkład pod warunkiem prawdziwości hipotezy zerowej określany jest jako rozkład Hotellinga, który stanowi przypadek szczególny rozkładu beta drugiego rodzaju (ang. beta type II distribution)1. Jest to rozkład znacznie mniej intuicyjny i trudniejszy w praktycznym zastosowaniu.\n1 Rozkład beta drugiego rodzaju (ang. Beta type II distribution), znany także jako rozkład beta-prime, jest ciągłym rozkładem prawdopodobieństwa definiowanym dla dodatnich wartości. Rozkład beta II o parametrach \\(a &gt; 0\\), \\(b &gt; 0\\) i skali \\(\\theta &gt; 0\\) ma funkcję gęstości postaci: \\[\nf(x) = \\frac{1}{\\theta} \\cdot \\frac{(x/\\theta)^{a - 1}}{(1 + x/\\theta)^{a + b}} \\cdot \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)}, \\quad x &gt; 0\n\\] gdzie \\(\\Gamma(\\cdot)\\) oznacza funkcję gamma Eulera. Wartość oczekiwana istnieje tylko dla \\(b &gt; 1\\) i wynosi: \\[\n\\mathbb{E}(X) = \\theta \\cdot \\frac{a}{b - 1}\n\\] a wariancja istnieje tylko dla \\(b &gt; 2\\) i wynosi: \\[\n\\operatorname{Var}(X) = \\theta^2 \\cdot \\frac{a(a + b - 1)}{(b - 2)(b - 1)^2}\n\\]Aby umożliwić testowanie hipotez z wykorzystaniem znanych tablic lub funkcji w programach statystycznych, Hotelling wykazał, że statystykę \\(T^2\\) można przekształcić do postaci mającej rozkład F-Fishera:\n\\[\nF = \\frac{(n - p)}{p(n - 1)} T^2 \\sim F_{p, n - p}\n\\]\nalbo równoważnie:\n\\[\nT^2 \\sim \\frac{p(n - 1)}{n - p} F_{p, n - p}\n\\]\nZ powyższej relacji wynika, że testowanie hipotezy \\(H_0\\) przy pomocy statystyki Hotellinga można sprowadzić do standardowego testu \\(F\\). Z tego względu mówi się, że statystyka Hotellinga ma rozkład Hotellinga T2, który w rzeczywistości jest funkcją rozkładu \\(F\\). Dla dużych liczności \\(n\\), rozkład statystyki \\(T^2\\) zbliża się do rozkładu \\(\\chi^2_p\\), czyli chi-kwadrat o \\(p\\) stopniach swobody, co często wykorzystywane jest jako przybliżenie asymptotyczne.\n\nPrzykład 1.2 (Test Hotellinga \\(T^2\\) dla nieznanej macierzy kowariancji)  \n\n\nKod\nset.seed(44)\nlibrary(mvtnorm)\nmu1 &lt;- c(-4, 4)\nSigma &lt;- matrix(c(16, -2, -2,9), byrow=TRUE, ncol=2)\nY1 &lt;- round(rmvnorm(15, mean=mu1, sigma=Sigma))\nmuH0 &lt;- c(-1, 2) # hipotetyczna średnia\nlibrary(ICSNP)\nHotellingsT2(Y1, mu=muH0)\n\n\n\n    Hotelling's one sample T2-test\n\ndata:  Y1\nT.2 = 2.7417, df1 = 2, df2 = 13, p-value = 0.1015\nalternative hypothesis: true location is not equal to c(-1,2)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-w-r-test-hotellinga",
    "href": "multi_tests.html#przykład-w-r-test-hotellinga",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.3 Przykład w R: test Hotellinga",
    "text": "1.3 Przykład w R: test Hotellinga\n\n\nKod\n# library(Hotelling)\n# hotelling.test(X, mu = mu0)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-hotellinga-dla-dwóch-grup",
    "href": "multi_tests.html#test-hotellinga-dla-dwóch-grup",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.3 Test Hotellinga dla dwóch grup",
    "text": "1.3 Test Hotellinga dla dwóch grup\nRozważmy dwa niezależne zbiory obserwacji:\n\n\\(\\boldsymbol{y}_{1,1}, \\boldsymbol{y}_{1,2}, \\ldots, \\boldsymbol{y}_{1,n_1} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\\),\n\\(\\boldsymbol{y}_{2,1}, \\boldsymbol{y}_{2,2}, \\ldots, \\boldsymbol{y}_{2,n_2} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_2, \\boldsymbol{\\Sigma}_2)\\)\n\ngdzie \\(\\boldsymbol{y}_{k,i} \\in \\mathbb{R}^p\\) są wektorami cech dla \\(k\\)-tej grupy (\\(k = 1,2\\)) i \\(i\\)-tej obserwacji, \\(\\boldsymbol{\\mu}_1\\) i \\(\\boldsymbol{\\mu}_2\\) to wektory średnich populacyjnych, a \\(\\boldsymbol{\\Sigma}_1\\), \\(\\boldsymbol{\\Sigma}_2\\) to macierze kowariancji.\nTestujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\n\\quad \\text{vs} \\quad\nH_1: \\boldsymbol{\\mu}_1 \\neq \\boldsymbol{\\mu}_2\n\\]\n\n1.3.1 Założenia\n\nPróby są niezależne;\nObserwacje w każdej grupie pochodzą z rozkładu wielowymiarowego normalnego;\nMacierze kowariancji są równe \\(\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}\\). Jest to kluczowe założenie umożliwiające zbudowanie wspólnego estymatora kowariancji i zastosowanie rozkładu \\(T^2\\) Hotellinga. Choć może być ono naruszone w praktyce, to dla dużych prób test zachowuje swoje właściwości asymptotyczne (Rencher 1998).\n\nWektory średnich z próby wyrażamy jako:\n\\[\n\\bar{\\boldsymbol{y}}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} \\boldsymbol{y}_{1,i}, \\quad\n\\bar{\\boldsymbol{y}}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} \\boldsymbol{y}_{2,i}\n\\]\nNieobciążonym estymatorem macierzy kowariancji (\\(\\boldsymbol{\\Sigma}\\)) jest tzw. połączony estymator kowariancji:\n\\[\n\\mathbf{S} =\n\\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\] gdzie \\[\n\\mathbf{S}_1 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top\n\\]\n\\[\n\\mathbf{S}_2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top\n\\]\nZatem:\n\\[\\mathbf{S} = \\frac{\\mathbf{W}_1 + \\mathbf{W}_2}{n_1 + n_2 - 2}\\] gdzie: \\[\n\\mathbf{W}_1 = \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top = (n_1 - 1)\\mathbf{S}_1\n\\]\n\\[\n\\mathbf{W}_2 = \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top = (n_2 - 1)\\mathbf{S}_2\n\\] Statystyka testowa Hotellinga wówczas ma postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)\n\\]\nA gdy \\(H_0\\) jest prawdziwa, to po przekształceniu:\n\\[\nF = \\frac{(n_1 + n_2 - p - 1)}{p(n_1 + n_2 - 2)} T^2 \\sim F_{p, n_1 + n_2 - p - 1}\n\\]\nAlternatywnie, można zapisać, że:\n\\[\nT^2 \\sim \\frac{p(n_1 + n_2 - 2)}{n_1 + n_2 - p - 1} F_{p, n_1 + n_2 - p - 1}\n\\]\nHipotezę zerową \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) odrzucamy na poziomie istotności \\(\\alpha\\), jeśli:\n\\[\nT^2 &gt; T^2_{\\alpha, p, n_1 + n_2 - 2}\n\\]\nlub równoważnie:\n\\[\nF &gt; F_{\\alpha, p, n_1 + n_2 - p - 1}\n\\]\nAby test był możliwy do przeprowadzenia, konieczne jest, aby \\(n_1 + n_2 - 2 &gt; p\\), czyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n\n\n\nAdnotacja\n\n\n\nW praktyce istotne jest, aby przed zastosowaniem testu \\(T^2\\) Hotellinga dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa. Test M Boxa (ang. Box’s M test) służy do statystycznej weryfikacji hipotezy równości macierzy kowariancji w wielu grupach.\nZałóżmy, że mamy \\(G\\) niezależnych prób z wielowymiarowego rozkładu normalnego:\n\\[\n\\boldsymbol{X}_{g} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_g, \\boldsymbol{\\Sigma}_g), \\quad g = 1, \\ldots, G\n\\]\nTestujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\ldots = \\boldsymbol{\\Sigma}_G = \\boldsymbol{\\Sigma}\n\\]\nprzeciwko alternatywie:\n\\[\nH_1: \\exists\\, g, h: \\boldsymbol{\\Sigma}_g \\ne \\boldsymbol{\\Sigma}_h\n\\]\nNiech\n\n\\(\\mathbf{S}_g\\) – macierz kowariancji w grupie \\(g\\),\n\\(n_g\\) – liczba obserwacji w grupie \\(g\\),\n\\(\\mathbf{S}_p\\) – połączony estymator macierzy kowariancji:\n\n\\[\n\\mathbf{S}_p = \\frac{1}{N - G} \\sum_{g=1}^G (n_g - 1)\\mathbf{S}_g\n\\]\ngdzie \\(N = \\sum_{g=1}^G n_g\\) – łączna liczba obserwacji. Wówczas, statystyka testowa Boxa ma postać:\n\\[\nM = (N - G) \\cdot \\ln|\\mathbf{S}_p| - \\sum_{g=1}^G (n_g - 1) \\cdot \\ln|\\mathbf{S}_g|\n\\]\nPoprawka na skończoną próbkę prowadzi do statystyki:\n\\[\nC = \\left(1 - c\\right) \\cdot M\n\\]\ngdzie:\n\\[\nc = \\frac{1}{3(p + 1)(G - 1)} \\left[ \\sum_{g=1}^G \\frac{1}{n_g - 1} - \\frac{1}{N - G} \\right]\n\\]\nStatystyka \\(C\\) jest asymptotycznie zbierzna do rozkładu \\(\\chi^2\\left(\\frac{p}{2}(p + 1)(G - 1)\\right)\\) liczbą stopni swobody.\nHipotezę \\(H_0\\) o równości macierzy kowariancji odrzuca się, jeśli:\n\\[\nC &gt; \\chi^2_{1 - \\alpha, df}\n\\]\nlub gdy \\(p\\) testu jest mniejsza od poziomu istotności \\(\\alpha\\).\nUwagi praktyczne\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.\n\n\n\n\nPrzykład 1.3 (Porównanie dwóch grup za pomocą testu \\(T^2\\) Hotellinga)  \n\n\nKod\nlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n\n[1] \"Statystyka T² = 17.340\"\n\n\nKod\nsprintf(\"Statystyka F = %.3f\", F_stat)\n\n\n[1] \"Statystyka F = 8.532\"\n\n\nKod\nsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n\n[1] \"Wartość krytyczna F = 3.145\"\n\n\nKod\nsprintf(\"p-value = %e\", p_val)\n\n\n[1] \"p-value = 5.330310e-04\"\n\n\nKod\n# Wizualizacja \ndf1 &lt;- as.data.frame(Y1) %&gt;%\n  mutate(grupa = \"Grupa 1\")\n\ndf2 &lt;- as.data.frame(Y2) %&gt;%\n  mutate(grupa = \"Grupa 2\")\n\ndf_all &lt;- bind_rows(df1, df2)\ncolnames(df_all)[1:2] &lt;- c(\"X1\", \"X2\")\n\n# Ramka danych ze średnimi\nmeans &lt;- data.frame(\n  X1 = c(y1_bar[1], y2_bar[1]),\n  X2 = c(y1_bar[2], y2_bar[2]),\n  grupa = c(\"Grupa 1\", \"Grupa 2\")\n)\n\n# Wykres\nggplot(df_all, aes(x = X1, y = X2, color = grupa, shape = grupa)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_point(data = means, aes(x = X1, y = X2),\n             shape = c(1, 2), size = 5, stroke = 1.2, show.legend = FALSE) +\n  scale_shape_manual(values = c(16, 17)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"Porównanie dwóch grup\",\n       x = \"X1\", y = \"X2\", color = \"Grupa\", shape = \"Grupa\")\n\n\n\n\n\n\n\n\n\n\n\nKod\n# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)\n\n\nW analizowanym przykładzie zdefiniowaliśmy macierze kowariancji identycznie ale w rzeczywistości należałoby testować hipotezę o równości macierzy kowariancji. Tylko dla celów ćwiczeniowych pokażę jak to zrobić.\n\n\nKod\n# Test Boxa na równość macierzy kowariancji\nlibrary(biotools)\nboxM(rbind(Y1, Y2), factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  rbind(Y1, Y2)\nChi-Sq (approx.) = 2.1261, df = 3, p-value = 0.5466\n\n\nKod\n# lub z wykorzystaniem pakietu rstatix\nlibrary(rstatix)\nbox_m(df_all[,-3], df_all[,3])\n\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                                            \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                             \n1      2.13   0.547         3 Box's M-test for Homogeneity of Covariance Matric…\n\n\n\n\n\n\n\n\n\nWskazówka\n\n\n\nW sytuacji, gdy założenie o równości macierzy kowariancji jest naruszone, można stosować alternatywne metody, takie jak:\n\nTesty permutacyjne (Hotelling::hotelling.test(X1, X2, perm = TRUE, B = 5000)).\nUogólniony test Hotellinga - test James (ang. James’s second-order test) lub czasami nazywany również testem Welch-type Hotelling test (Hotelling::hotelling.test(X1, X2, var.equal = FALSE)).\nW przypadku danych charakteryzujących się dużą liczbą zmiennych w stosunku do liczby obserwacji, można rozważyć użycie estymatora Jamesa-Steina do stabilizaji macierzy kowariancji (Hotelling::hotelling.test(X1, X2, shrinkage = TRUE)).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#przykład-porównanie-dwóch-grup-w-r",
    "href": "multi_tests.html#przykład-porównanie-dwóch-grup-w-r",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Przykład: porównanie dwóch grup w R",
    "text": "1.4 Przykład: porównanie dwóch grup w R\n\n\nKod\nlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n\n[1] \"Statystyka T² = 17.340\"\n\n\nKod\nsprintf(\"Statystyka F = %.3f\", F_stat)\n\n\n[1] \"Statystyka F = 8.532\"\n\n\nKod\nsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n\n[1] \"Wartość krytyczna F = 3.145\"\n\n\nKod\nsprintf(\"p-value = %e\", p_val)\n\n\n[1] \"p-value = 5.330310e-04\"\n\n\nKod\n# Wizualizacja \nplot(Y1, col = \"blue\", pch = 16, xlim = range(c(Y1[,1], Y2[,1])), ylim = range(c(Y1[,2], Y2[,2])),\n     xlab = \"X1\", ylab = \"X2\", main = \"Porównanie dwóch grup\")\npoints(Y2, col = \"red\", pch = 17)\nlegend(\"topright\", legend = c(\"Grupa 1\", \"Grupa 2\"), col = c(\"blue\", \"red\"), pch = c(16,17))\npoints(y1_bar[1], y1_bar[2], col = \"darkblue\", pch = 1, cex = 2)\npoints(y2_bar[1], y2_bar[2], col = \"darkred\", pch = 2, cex = 2)\n\n\n\n\n\n\n\n\n\n\n\nKod\n# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#wprowadzenie-do-manova",
    "href": "multi_tests.html#wprowadzenie-do-manova",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Wprowadzenie do MANOVA",
    "text": "1.4 Wprowadzenie do MANOVA\nW przypadku porównywania więcej niż dwóch grup nie możemy już stosować testu Hotellinga. Odpowiednikiem testu ANOVA w przestrzeni wielowymiarowej jest MANOVA – analiza wariancji dla wielu zmiennych. Testujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = \\ldots = \\boldsymbol{\\mu}_g\n\\]\ngdzie \\(g\\) to liczba grup. Szczegóły konstrukcji testów Wilksa, Lawleya-Hotellinga czy Roy’a zostaną przedstawione w dalszych wykładach.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#podsumowanie",
    "href": "multi_tests.html#podsumowanie",
    "title": "\n1  Testy wielowymiarowe\n",
    "section": "\n5.1 Podsumowanie",
    "text": "5.1 Podsumowanie\nTesty wielowymiarowe pozwalają na kompleksowe testowanie hipotez dotyczących wektorów średnich. Stanowią naturalne rozszerzenie klasycznych testów jednowymiarowych i eliminują błędy wynikające z wielokrotnego testowania oraz nieuwzględniania współzależności między cechami. W kolejnych częściach wykładu rozwiniemy tematykę MANOVA oraz testów dla bardziej złożonych struktur danych.\n\n\n\n\nRencher, Alvin C. 1998. Multivariate statistical inference and applications. T. 635. Wiley New York.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#test-dla-boldsymbolmu-boldsymbolmu_0-przy-znanej-macierzy-kowariancji",
    "href": "multi_tests.html#test-dla-boldsymbolmu-boldsymbolmu_0-przy-znanej-macierzy-kowariancji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "",
    "text": "Przykład 1.1 (Test Hotellinga \\(T^2\\) dla znanej macierzy kowariancji)  \n\n\nKod\nset.seed(44)\nmu0 &lt;- c(170, 70)\nSigma &lt;- matrix(c(100, 40, 40, 100), nrow = 2)\nn &lt;- 30\n\n# Generowanie danych\nX &lt;- MASS::mvrnorm(n = n, mu = mu0, Sigma = Sigma)\n\n# Weryfikacja hipotezy H0: mu = mu0\nx_bar &lt;- colMeans(X)\nT2 &lt;- n * t(x_bar - mu0) %*% solve(Sigma) %*% (x_bar - mu0)\nsprintf('T2 = %.3f', T2)\n\n\n[1] \"T2 = 0.670\"\n\n\nKod\nsprintf('p-value=%.3f', pchisq(T2, df = 2, lower.tail = FALSE))\n\n\n[1] \"p-value=0.715\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#estymatory-średnich",
    "href": "multi_tests.html#estymatory-średnich",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Estymatory średnich",
    "text": "1.4 Estymatory średnich\nWektory średnich z próby wyrażamy jako:\n[ {}1 = ^{n_1} {1,i}, {}2 = ^{n_2} ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#estymatory-kowariancji-i-ich-połączenie",
    "href": "multi_tests.html#estymatory-kowariancji-i-ich-połączenie",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.5 Estymatory kowariancji i ich połączenie",
    "text": "1.5 Estymatory kowariancji i ich połączenie\nNieobciążonym estymatorem macierzy kowariancji ( ) jest tzw. połączony estymator kowariancji:\n[ = ]\ngdzie:\n[ 1 = ^{n_1} (_{1,i} - {}1)( - {}_1)^ ]\n[ 2 = ^{n_2} (_{2,i} - {}2)( - {}_2)^ ]\nZatem:\n[ = ]\ngdzie:\n[ 1 = ^{n_1} (_{1,i} - {}1)( - {}_1)^= (n_1 - 1)_1 ]\n[ 2 = ^{n_2} (_{2,i} - {}2)( - {}_2)^= (n_2 - 1)_2 ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#statystyka-testowa",
    "href": "multi_tests.html#statystyka-testowa",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.6 Statystyka testowa",
    "text": "1.6 Statystyka testowa\nStatystyka testowa Hotellinga ma postać:\n[ T^2 = ({}_1 - {}_2) ({}_1 - {}_2) ]\nGdy ( H_0 ) jest prawdziwa, to po przekształceniu:\n[ F = T^2 F_{p, n_1 + n_2 - p - 1} ]\nAlternatywnie, można zapisać, że:\n[ T^2 F_{p, n_1 + n_2 - p - 1} ]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#kryterium-decyzji",
    "href": "multi_tests.html#kryterium-decyzji",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.7 Kryterium decyzji",
    "text": "1.7 Kryterium decyzji\nHipotezę zerową ( H_0: _1 = _2 ) odrzucamy na poziomie istotności ( ), jeśli:\n[ T^2 &gt; T^2_{, p, n_1 + n_2 - 2} ]\nlub równoważnie:\n[ F &gt; F_{, p, n_1 + n_2 - p - 1} ]\n\n\n1.7.1 Warunek zastosowania testu\nAby test był możliwy do przeprowadzenia, konieczne jest, aby:\n[ n_1 + n_2 - 2 &gt; p ]\nczyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n1.7.2 Uwaga praktyczna\nW praktyce istotne jest, aby przed zastosowaniem testu Hotellinga T² dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa lub poprzez ocenę wykresów rozrzutu. W przypadku jego naruszenia należy rozważyć zastosowanie testów niewymagających tego założenia lub podejść uogólnionych.\nRozważmy dwie próby \\(\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_{n_1} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma})\\) oraz \\(\\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_{n_2} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_2, \\boldsymbol{\\Sigma})\\). Chcemy zwerfykikować hipotezę:\n\\[\nH_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\n\\]\nStatystyka testowa:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{x}} - \\bar{\\boldsymbol{y}})^T \\mathbf{S}_p^{-1} (\\bar{\\boldsymbol{x}} - \\bar{\\boldsymbol{y}})\n\\]\ngdzie \\(\\mathbf{S}_p\\) to tzw. macierz kowariancji połączonej (pooled covariance):\n\\[\n\\mathbf{S}_p = \\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#uwaga-praktyczna",
    "href": "multi_tests.html#uwaga-praktyczna",
    "title": "1  Testy wielowymiarowe – wprowadzenie",
    "section": "1.4 Uwaga praktyczna",
    "text": "1.4 Uwaga praktyczna\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe – wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_tests.html#założenia",
    "href": "multi_tests.html#założenia",
    "title": "\n1  Testy wielowymiarowe\n",
    "section": "\n4.1 Założenia",
    "text": "4.1 Założenia\n\nPróby są niezależne;\nObserwacje w każdej grupie pochodzą z rozkładu wielowymiarowego normalnego;\n\nMacierze kowariancji są równe \\(\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}\\). Jest to kluczowe założenie umożliwiające zbudowanie wspólnego estymatora kowariancji i zastosowanie rozkładu \\(T^2\\) Hotellinga. Choć może być ono naruszone w praktyce, to dla dużych prób test zachowuje swoje właściwości asymptotyczne (Rencher 1998).\n\nWektory średnich z próby wyrażamy jako:\n\\[\n\\bar{\\boldsymbol{y}}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} \\boldsymbol{y}_{1,i}, \\quad\n\\bar{\\boldsymbol{y}}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} \\boldsymbol{y}_{2,i}\n\\]\nNieobciążonym estymatorem macierzy kowariancji (\\(\\boldsymbol{\\Sigma}\\)) jest tzw. połączony estymator kowariancji:\n\\[\n\\mathbf{S} =\n\\frac{(n_1 - 1) \\mathbf{S}_1 + (n_2 - 1) \\mathbf{S}_2}{n_1 + n_2 - 2}\n\\] gdzie \\[\n\\mathbf{S}_1 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top\n\\]\n\\[\n\\mathbf{S}_2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top\n\\]\nZatem:\n\\[\\mathbf{S} = \\frac{\\mathbf{W}_1 + \\mathbf{W}_2}{n_1 + n_2 - 2}\\] gdzie: \\[\n\\mathbf{W}_1 = \\sum_{i=1}^{n_1} (\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)(\\boldsymbol{y}_{1,i} - \\bar{\\boldsymbol{y}}_1)^\\top = (n_1 - 1)\\mathbf{S}_1\n\\]\n\\[\n\\mathbf{W}_2 = \\sum_{i=1}^{n_2} (\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)(\\boldsymbol{y}_{2,i} - \\bar{\\boldsymbol{y}}_2)^\\top = (n_2 - 1)\\mathbf{S}_2\n\\] Statystyka testowa Hotellinga wówczas ma postać:\n\\[\nT^2 = \\frac{n_1 n_2}{n_1 + n_2} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)^\\top \\mathbf{S}^{-1} (\\bar{\\boldsymbol{y}}_1 - \\bar{\\boldsymbol{y}}_2)\n\\]\nA gdy \\(H_0\\) jest prawdziwa, to po przekształceniu:\n\\[\nF = \\frac{(n_1 + n_2 - p - 1)}{p(n_1 + n_2 - 2)} T^2 \\sim F_{p, n_1 + n_2 - p - 1}\n\\]\nAlternatywnie, można zapisać, że:\n\\[\nT^2 \\sim \\frac{p(n_1 + n_2 - 2)}{n_1 + n_2 - p - 1} F_{p, n_1 + n_2 - p - 1}\n\\]\nHipotezę zerową \\(H_0: \\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2\\) odrzucamy na poziomie istotności \\(\\alpha\\), jeśli:\n\\[\nT^2 &gt; T^2_{\\alpha, p, n_1 + n_2 - 2}\n\\]\nlub równoważnie:\n\\[\nF &gt; F_{\\alpha, p, n_1 + n_2 - p - 1}\n\\]\nAby test był możliwy do przeprowadzenia, konieczne jest, aby \\(n_1 + n_2 - 2 &gt; p\\), czyli liczba stopni swobody w estymacji wspólnej kowariancji była większa niż wymiar przestrzeni cech.\n\n\n\n\n\n\nAdnotacja\n\n\n\nW praktyce istotne jest, aby przed zastosowaniem testu \\(T^2\\) Hotellinga dla dwóch prób zweryfikować założenie o równości macierzy kowariancji — np. za pomocą testu Boxa. Test M Boxa (ang. Box’s M test) służy do statystycznej weryfikacji hipotezy równości macierzy kowariancji w wielu grupach.\nZałóżmy, że mamy \\(G\\) niezależnych prób z wielowymiarowego rozkładu normalnego:\n\\[\n\\boldsymbol{X}_{g} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_g, \\boldsymbol{\\Sigma}_g), \\quad g = 1, \\ldots, G\n\\]\nTestujemy hipotezę:\n\\[\nH_0: \\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\ldots = \\boldsymbol{\\Sigma}_G = \\boldsymbol{\\Sigma}\n\\]\nprzeciwko alternatywie:\n\\[\nH_1: \\exists\\, g, h: \\boldsymbol{\\Sigma}_g \\ne \\boldsymbol{\\Sigma}_h\n\\]\nNiech\n\n\n\\(\\mathbf{S}_g\\) – macierz kowariancji w grupie \\(g\\),\n\n\\(n_g\\) – liczba obserwacji w grupie \\(g\\),\n\n\\(\\mathbf{S}_p\\) – połączony estymator macierzy kowariancji:\n\n\\[\n\\mathbf{S}_p = \\frac{1}{N - G} \\sum_{g=1}^G (n_g - 1)\\mathbf{S}_g\n\\]\ngdzie \\(N = \\sum_{g=1}^G n_g\\) – łączna liczba obserwacji. Wówczas, statystyka testowa Boxa ma postać:\n\\[\nM = (N - G) \\cdot \\ln|\\mathbf{S}_p| - \\sum_{g=1}^G (n_g - 1) \\cdot \\ln|\\mathbf{S}_g|\n\\]\nPoprawka na skończoną próbkę prowadzi do statystyki:\n\\[\nC = \\left(1 - c\\right) \\cdot M\n\\]\ngdzie:\n\\[\nc = \\frac{1}{3(p + 1)(G - 1)} \\left[ \\sum_{g=1}^G \\frac{1}{n_g - 1} - \\frac{1}{N - G} \\right]\n\\]\nStatystyka \\(C\\) jest asymptotycznie zbierzna do rozkładu \\(\\chi^2\\left(\\frac{p}{2}(p + 1)(G - 1)\\right)\\) liczbą stopni swobody.\nHipotezę \\(H_0\\) o równości macierzy kowariancji odrzuca się, jeśli:\n\\[\nC &gt; \\chi^2_{1 - \\alpha, df}\n\\]\nlub gdy \\(p\\) testu jest mniejsza od poziomu istotności \\(\\alpha\\).\nUwagi praktyczne\n\nTest M Boxa jest wrażliwy na odchylenia od normalności – jeśli dane nie są zbliżone do normalnych, test może dawać mylące wyniki.\nW dużych próbach nawet drobne różnice między macierzami kowariancji mogą prowadzić do odrzucenia \\(H_0\\), choć nie mają istotnego wpływu praktycznego.\nW małych próbach test może być niestabilny – zaleca się ostrożność przy interpretacji.\n\n\n\n\nPrzykład 4.1 (Porównanie dwóch grup za pomocą testu \\(T^2\\) Hotellinga)  \n\nKodlibrary(MASS)\n# Parametry symulacji\nset.seed(44)\np &lt;- 2          # liczba zmiennych\nn1 &lt;- 30        # liczba obserwacji w grupie 1\nn2 &lt;- 35        # liczba obserwacji w grupie 2\n\n# Parametry rozkładu\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(1, 1)\nSigma &lt;- matrix(c(1, 0.5,\n                  0.5, 1), nrow = 2)\n\n# Generowanie danych\nY1 &lt;- mvrnorm(n1, mu = mu1, Sigma = Sigma)\nY2 &lt;- mvrnorm(n2, mu = mu2, Sigma = Sigma)\n\n# Średnie z próby\ny1_bar &lt;- colMeans(Y1)\ny2_bar &lt;- colMeans(Y2)\n\n# Estymatory kowariancji\nS1 &lt;- cov(Y1)\nS2 &lt;- cov(Y2)\n\n# Wspólna kowariancja (połączona)\nSp &lt;- ((n1 - 1)*S1 + (n2 - 1)*S2) / (n1 + n2 - 2)\n\n# Statystyka testowa Hotellinga T^2\ndiff_mean &lt;- y1_bar - y2_bar\nT2 &lt;- (n1 * n2) / (n1 + n2) * t(diff_mean) %*% solve(Sp) %*% diff_mean\nT2 &lt;- as.numeric(T2)\n\n# Przekształcenie do F\ndf1 &lt;- p\ndf2 &lt;- n1 + n2 - p - 1\nF_stat &lt;- (df2 / (df1 * (n1 + n2 - 2))) * T2\n\n# Wartość krytyczna\nalpha &lt;- 0.05\nF_crit &lt;- qf(1 - alpha, df1, df2)\n\n# p-wartość\np_val &lt;- 1 - pf(F_stat, df1, df2)\n\n# Wynik testu\nsprintf(\"Statystyka T² = %.3f\", T2)\n\n[1] \"Statystyka T² = 17.340\"\n\nKodsprintf(\"Statystyka F = %.3f\", F_stat)\n\n[1] \"Statystyka F = 8.532\"\n\nKodsprintf(\"Wartość krytyczna F = %.3f\", F_crit)\n\n[1] \"Wartość krytyczna F = 3.145\"\n\nKodsprintf(\"p-value = %e\", p_val)\n\n[1] \"p-value = 5.330310e-04\"\n\nKod# Wizualizacja \ndf1 &lt;- as.data.frame(Y1) %&gt;%\n  mutate(grupa = \"Grupa 1\")\n\ndf2 &lt;- as.data.frame(Y2) %&gt;%\n  mutate(grupa = \"Grupa 2\")\n\ndf_all &lt;- bind_rows(df1, df2)\ncolnames(df_all)[1:2] &lt;- c(\"X1\", \"X2\")\n\n# Ramka danych ze średnimi\nmeans &lt;- data.frame(\n  X1 = c(y1_bar[1], y2_bar[1]),\n  X2 = c(y1_bar[2], y2_bar[2]),\n  grupa = c(\"Grupa 1\", \"Grupa 2\")\n)\n\n# Wykres\nggplot(df_all, aes(x = X1, y = X2, color = grupa, shape = grupa)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_point(data = means, aes(x = X1, y = X2),\n             shape = c(1, 2), size = 5, stroke = 1.2, show.legend = FALSE) +\n  scale_shape_manual(values = c(16, 17)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"Porównanie dwóch grup\",\n       x = \"X1\", y = \"X2\", color = \"Grupa\", shape = \"Grupa\")\n\n\n\n\n\n\n\n\nKod# Alternatywnie, użycie gotowej funkcji z pakietu ICSNP\nlibrary(ICSNP)\nHotellingsT2(rbind(Y1, Y2)~factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Hotelling's two sample T2-test\n\ndata:  rbind(Y1, Y2) by factor(c(rep(1, n1), rep(2, n2)))\nT.2 = 8.5321, df1 = 2, df2 = 62, p-value = 0.000533\nalternative hypothesis: true location difference is not equal to c(0,0)\n\n\nW analizowanym przykładzie zdefiniowaliśmy macierze kowariancji identycznie ale w rzeczywistości należałoby testować hipotezę o równości macierzy kowariancji. Tylko dla celów ćwiczeniowych pokażę jak to zrobić.\n\nKod# Test Boxa na równość macierzy kowariancji\nlibrary(biotools)\nboxM(rbind(Y1, Y2), factor(c(rep(1, n1), rep(2, n2))))\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  rbind(Y1, Y2)\nChi-Sq (approx.) = 2.1261, df = 3, p-value = 0.5466\n\nKod# lub z wykorzystaniem pakietu rstatix\nlibrary(rstatix)\nbox_m(df_all[,-3], df_all[,3])\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                                            \n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                                             \n1      2.13   0.547         3 Box's M-test for Homogeneity of Covariance Matric…\n\n\n\n\n\n\n\n\n\nWskazówka\n\n\n\nW sytuacji, gdy założenie o równości macierzy kowariancji jest naruszone, można stosować alternatywne metody, takie jak:\n\nTesty permutacyjne (Hotelling::hotelling.test(Y~Group, perm = TRUE, B = 5000)).\nUogólniony test Hotellinga - test James (ang. James’s second-order test) lub czasami nazywany również testem Welch-type Hotelling test (Hotelling::hotelling.test(Y~Group, var.equal = FALSE)).\nW przypadku danych charakteryzujących się dużą liczbą zmiennych w stosunku do liczby obserwacji, można rozważyć użycie estymatora Jamesa-Steina do stabilizaji macierzy kowariancji (Hotelling::hotelling.test(Y~Group, shrinkage = TRUE)).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Testy wielowymiarowe</span>"
    ]
  }
]