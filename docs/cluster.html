<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Analiza skupień – Wielowymiarowa analiza danych</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./pca.html" rel="prev">
<link href="./images/cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-bc185b5c5bdbcb35c2eb49d8a876ef70.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-2d449610c6da6b3fd31ed0a9984c1b47.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-f7ccbded210020a5533f6fd86e3f20c2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-2d449610c6da6b3fd31ed0a9984c1b47.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Brak wyników",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "więcej dopasowań w tym dokumencie",
    "search-more-matches-text": "więcej dopasowań w tym dokumencie",
    "search-clear-button-title": "Wyczyść",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "Zatwierdź",
    "search-label": "Szukaj"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./cluster.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Analiza skupień</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Szukaj" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Wielowymiarowa analiza danych</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/DariuszMajerek/WAD_new" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Przełącz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Przełącz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wstęp</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multi_tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Testy wielowymiarowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Analiza kanoniczna</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fa.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analiza czynnikowa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modele strukturalne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Metody redukcji wymiarowości</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cluster.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Analiza skupień</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatura</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Spis treści</h2>
   
  <ul>
<li><a href="#rys-historyczny" id="toc-rys-historyczny" class="nav-link active" data-scroll-target="#rys-historyczny">Rys historyczny</a></li>
  <li><a href="#podzia%C5%82-metod-analizy-skupie%C5%84" id="toc-podział-metod-analizy-skupień" class="nav-link" data-scroll-target="#podzia%C5%82-metod-analizy-skupie%C5%84">Podział metod analizy skupień</a></li>
  <li>
<a href="#metody-hierarchiczne" id="toc-metody-hierarchiczne" class="nav-link" data-scroll-target="#metody-hierarchiczne">Metody hierarchiczne</a>
  <ul class="collapse">
<li><a href="#metody-aglomeracyjne" id="toc-metody-aglomeracyjne" class="nav-link" data-scroll-target="#metody-aglomeracyjne">Metody aglomeracyjne</a></li>
  <li><a href="#metody-deglomeracyjne" id="toc-metody-deglomeracyjne" class="nav-link" data-scroll-target="#metody-deglomeracyjne">Metody deglomeracyjne</a></li>
  </ul>
</li>
  <li>
<a href="#metody-niehierarchiczne" id="toc-metody-niehierarchiczne" class="nav-link" data-scroll-target="#metody-niehierarchiczne">Metody niehierarchiczne</a>
  <ul class="collapse">
<li><a href="#podzia%C5%82-twardy" id="toc-podział-twardy" class="nav-link" data-scroll-target="#podzia%C5%82-twardy">Podział twardy</a></li>
  <li><a href="#podzia%C5%82-rozmyty" id="toc-podział-rozmyty" class="nav-link" data-scroll-target="#podzia%C5%82-rozmyty">Podział rozmyty</a></li>
  <li><a href="#metoda-k-%C5%9Brednich-k-means" id="toc-metoda-k-średnich-k-means" class="nav-link" data-scroll-target="#metoda-k-%C5%9Brednich-k-means">Metoda k-średnich (<em>k-means</em>)</a></li>
  <li><a href="#metoda-k-medoid%C3%B3w-k-medoids" id="toc-metoda-k-medoidów-k-medoids" class="nav-link" data-scroll-target="#metoda-k-medoid%C3%B3w-k-medoids">Metoda k-medoidów (<em>k-medoids</em>)</a></li>
  <li><a href="#clara-i-clarans" id="toc-clara-i-clarans" class="nav-link" data-scroll-target="#clara-i-clarans">CLARA i CLARANS</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/DariuszMajerek/WAD_new/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span class="chapter-title">Analiza skupień</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="rys-historyczny" class="level2"><h2 class="anchored" data-anchor-id="rys-historyczny">Rys historyczny</h2>
<p>Analiza skupień, znana również jako <em>cluster analysis</em>, ma swoje korzenie w połowie XX wieku, choć jej podstawy koncepcyjne pojawiły się znacznie wcześniej w statystyce i biologii systematycznej. Jej rozwój przebiegał równolegle w kilku dziedzinach, w tym w psychologii, biologii, socjologii i informatyce, a z czasem stała się jednym z fundamentalnych narzędzi eksploracyjnej analizy danych. Pierwsze idee grupowania obiektów o podobnych cechach można odnaleźć już w XVIII i XIX wieku w klasyfikacji biologicznej. Carl Linneusz wprowadził system binominalny oparty na cechach morfologicznych organizmów, co stanowiło wczesny przykład klasyfikacji hierarchicznej. Współczesne podejście matematyczne do analizy skupień zaczęło się jednak kształtować dopiero w XX wieku wraz z rozwojem metod statystycznych i koncepcji odległości w przestrzeni wielowymiarowej. Za właściwy początek analizy skupień w sensie statystycznym uznaje się lata 30. i 40. XX wieku. W 1939 roku Tryon wprowadził pojęcie analizy grupowej (<em>cluster analysis</em>) w psychologii, stosując ją do klasyfikacji zmiennych i jednostek na podstawie macierzy podobieństw. W latach 50. i 60. intensywny rozwój metod klasyfikacji hierarchicznej był związany z rozwojem biologii numerycznej (<em>numerical taxonomy</em>), głównie dzięki pracom Sokal’a i Sneath’a, którzy w latach 60. zaproponowali formalne podstawy taksonomii numerycznej opartej na macierzach podobieństw między organizmami. Lata 60. i 70. XX wieku przyniosły znaczący rozwój metod niehierarchicznych, w tym przede wszystkim metody <em>k-means</em>, zaproponowanej przez MacQueena w 1967 roku. Algorytm ten stał się jednym z najczęściej stosowanych narzędzi w analizie skupień dzięki swojej prostocie, interpretowalności i efektywności obliczeniowej. W tym samym okresie rozwijano również metody oparte na gęstości (np. późniejszy DBSCAN), metody probabilistyczne (modele mieszanek Gaussa) oraz techniki optymalizacyjne pozwalające na automatyczne wyznaczanie liczby skupień. W latach 80. i 90. wraz z rozwojem informatyki oraz eksploracji danych (data mining), analiza skupień zaczęła być szeroko stosowana w zastosowaniach praktycznych – od segmentacji rynku, przez rozpoznawanie obrazów, po bioinformatykę. Pojawiły się również metody adaptacyjne i oparte na uczeniu nienadzorowanym, w tym sieci neuronowe typu <em>self-organizing maps</em> (SOM) opracowane przez Kohonena. W XXI wieku analiza skupień stała się kluczowym elementem nauki o danych (<em>data science</em>). Współczesne metody integrują klasyczne podejścia statystyczne z algorytmami uczenia maszynowego. Opracowano wiele nowych technik, takich jak metody oparte na gęstości (DBSCAN, OPTICS), metody spektralne wykorzystujące wartości własne macierzy podobieństwa, czy algorytmy głębokiego grupowania (<em>deep clustering</em>) bazujące na sieciach neuronowych. Równocześnie rozwinięto teoretyczne podstawy walidacji skupień, takie jak współczynniki <em>silhouette</em>, indeks Calinskiego-Harabasza czy Davies-Bouldin, umożliwiające obiektywną ocenę jakości grupowania.</p>
</section><section id="podział-metod-analizy-skupień" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="podział-metod-analizy-skupień">Podział metod analizy skupień</h2>
<p>Metody analizy skupień można klasyfikować według różnych kryteriów, takich jak sposób tworzenia skupień, założenia o strukturze danych, rodzaj miary podobieństwa czy sposób reprezentacji wyników. Najczęściej przyjmuje się podział taksonomiczny oparty na sposobie grupowania obiektów, który pozwala wyróżnić cztery główne klasy metod: hierarchiczne, niehierarchiczne, oparte na gęstości i oparte na modelach probabilistycznych.</p>
<p>Pierwszą i jedną z najstarszych kategorii są metody hierarchiczne. Ich istotą jest budowa dendrogramu odzwierciedlającego stopniowe łączenie (lub rozdzielanie) obiektów w skupienia. Wyróżnia się dwa podejścia: aglomeracyjne, które rozpoczynają od traktowania każdego obiektu jako odrębnego skupienia i następnie łączą je zgodnie z określoną miarą odległości (np. metoda pojedynczego, pełnego lub średniego wiązania), oraz dzielące, które zaczynają od jednego skupienia zawierającego wszystkie obiekty i w kolejnych krokach dokonują jego podziału. Metody hierarchiczne mają tę zaletę, że nie wymagają wcześniejszego określenia liczby skupień, lecz ich wadą jest wysoka złożoność obliczeniowa i wrażliwość na szumy.</p>
<p>Drugą grupę stanowią metody niehierarchiczne, wśród których najbardziej znane są algorytmy typu <em>k-means</em> oraz <em>k-medoids</em>. Ich celem jest bezpośrednie przypisanie każdego obiektu do jednego z ustalonej liczby skupień na podstawie minimalizacji sumy kwadratów odległości wewnątrzgrupowych. Metoda <em>k-means</em> jest szybka i skuteczna przy danych o wyraźnie kulistych skupieniach, natomiast <em>k-medoids</em> (np. algorytm PAM) jest bardziej odporna na wartości odstające. Do tej kategorii należą również algorytmy optymalizacyjne, takie jak <em>k-means++</em> czy <em>mini-batch k-means</em>, dostosowane do dużych zbiorów danych.</p>
<p>Trzecią kategorię tworzą metody oparte na gęstości, w których skupienia definiuje się jako obszary przestrzeni danych o wysokim zagęszczeniu punktów oddzielone obszarami o niskiej gęstości. Klasycznym przykładem jest algorytm DBSCAN, który wykrywa skupienia dowolnego kształtu i pozwala automatycznie identyfikować punkty szumu. Udoskonaloną wersją tej metody jest OPTICS, umożliwiająca hierarchiczne przedstawienie struktur gęstościowych. Metody tego typu są szczególnie użyteczne przy analizie danych przestrzennych oraz w sytuacjach, gdy skupienia nie mają regularnego kształtu.</p>
<p>Czwartą grupą są metody oparte na modelach probabilistycznych. Zakładają one, że dane pochodzą z mieszaniny rozkładów (najczęściej wielowymiarowych normalnych), a zadaniem algorytmu jest estymacja parametrów tych rozkładów oraz przypisanie obiektów do skupień na podstawie maksymalnego prawdopodobieństwa. Do tej kategorii należą modele mieszanek Gaussa (GMM) estymowane metodą EM (<em>Expectation–Maximization</em>), które umożliwiają probabilistyczne przypisanie obiektów do wielu skupień z różnym stopniem przynależności.</p>
<p>Poza głównymi czterema klasami wyróżnia się również metody hybrydowe i współczesne podejścia uczenia nienadzorowanego. Przykładem są metody spektralne, które wykorzystują analizę wartości własnych macierzy podobieństwa, oraz metody głębokiego grupowania (<em>deep clustering</em>), integrujące sieci neuronowe autoenkoderowe z klasycznymi procedurami klastrowania<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Ten rodzaj klastrowania nie będzie przedmiotem tego rozdziału ponieważ wykracza poza klasyczne podejście statystyczne i wymaga wiedzy na temat sieci neuronowych, która pojawia się na późniejszych semestrach.</p></div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/clust1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Podział metod grupowania"><img src="images/clust1.png" class="img-fluid figure-img" alt="Podział metod grupowania"></a></p>
<figcaption>Podział metod grupowania</figcaption></figure>
</div>
</section><section id="metody-hierarchiczne" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="metody-hierarchiczne">Metody hierarchiczne</h2>
<p>Metody hierarchiczne w analizie skupień opierają się na iteracyjnym łączeniu lub dzieleniu obiektów w sposób odzwierciedlający ich podobieństwo, prowadząc do utworzenia struktury drzewiastej (dendrogramu). Struktura ta ukazuje hierarchiczne relacje między obiektami – od indywidualnych elementów aż po jedną nadrzędną grupę lub odwrotnie. Wyróżnia się dwa główne podejścia: metody aglomeracyjne oraz deglomeracyjne (dzielące).</p>
<section id="metody-aglomeracyjne" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="metody-aglomeracyjne">Metody aglomeracyjne</h3>
<p>W podejściu aglomeracyjnym proces rozpoczyna się od traktowania każdego obiektu jako odrębnego skupienia jednoelementowego. Następnie w kolejnych krokach łączy się dwa najbardziej podobne skupienia, aż do momentu uzyskania jednego skupienia zawierającego wszystkie obiekty. Proces ten można formalnie zapisać następująco</p>
<ol type="1">
<li>Niech zbiór danych składa się z <span class="math inline">\(n\)</span> obiektów <span class="math display">\[
X = \{x_1, x_2, \ldots, x_n\},
\]</span> gdzie każdy obiekt <span class="math inline">\(x_i \in \mathbb{R}^p.\)</span>
</li>
<li>Początkowo każdy obiekt stanowi odrębne skupienie <span class="math display">\[
C_i^{(0)} = \{x_i\} \quad \text{dla}\quad i = 1, \ldots, n.
\]</span>
</li>
<li>Definiuje się macierz odległości <span class="math inline">\(D = [d(x_i, x_j)]\)</span>, gdzie funkcja <span class="math inline">\(d(\cdot, \cdot)\)</span> określa miarę odległości (np. euklidesową, Mahalanobisa, Manhattan).</li>
<li>Na każdym kroku <span class="math inline">\(t\)</span> wyszukuje się dwa skupienia <span class="math inline">\(C_p^{(t)}\)</span> i <span class="math inline">\(C_q^{(t)}\)</span>, które są najbliższe względem przyjętej miary odległości między skupieniami <span class="math inline">\(D(C_p, C_q)\)</span>. Następnie łączy się je w jedno nowe skupienie <span class="math display">\[
C_{pq}^{(t+1)} = C_p^{(t)} \cup C_q^{(t)}.
\]</span>
</li>
<li>Odległości między nowo utworzonym skupieniem a pozostałymi aktualizuje się zgodnie z przyjętą regułą wiązania (<em>linkage criterion</em>). Niech <span class="math inline">\(D(C_i,C_j)\)</span> oznacza odległość klaster–klaster, <span class="math inline">\(d(x,y)\)</span> bazową odległość punkt–punkt, <span class="math inline">\(|C_i|=n_i\)</span> liczność klastra <span class="math inline">\(C_i\)</span>, <span class="math inline">\(\bar x_i\)</span> centroid <span class="math inline">\(C_i\)</span>. Reguła aglomeracji w postaci rekurencji Lance’a–Williamsa przyjmuje wówczas postać <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\alpha_i D(C_i,C_k)+\alpha_j D(C_j,C_k)+\beta D(C_i,C_j)+\gamma\,\big|D(C_i,C_k)-D(C_j,C_k)\big|,
\]</span> z współczynnikami (<span class="math inline">\(\alpha_i,\alpha_j,\beta,\gamma\)</span>) zależnymi od wybranego sposobu łączenia. Dla metod centroidowych i Warda inicjalizujemy macierz odległości kwadratami odległości euklidesowych i interpretujemy wyniki jako wartości kwadratowe. Możemy wówczas wyróżnić następujące metody aglomeracji:
<ul>
<li>Metoda pojedynczego wiązania (<em>single linkage</em>) <span class="math display">\[
D(C_i,C_j)=\min_{x\in C_i,\,y\in C_j} d(x,y).
\]</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\min\!\big(D(C_i,C_k),\,D(C_j,C_k)\big),
\]</span> co odpowiada <span class="math inline">\(\alpha_i=\alpha_j=\tfrac12,\ \beta=0,\ \gamma=-\tfrac12\)</span> przy inicjalizacji <span class="math inline">\(D(\{x\},\{y\})=d(x,y)\)</span>.</li>
<li>Metoda pełnego wiązania (<em>complete linkage</em>) <span class="math display">\[
D(C_i,C_j)=\max_{x\in C_i,\,y\in C_j} d(x,y).
\]</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\max\!\big(D(C_i,C_k),\,D(C_j,C_k)\big),
\]</span> czyli <span class="math inline">\(\alpha_i=\alpha_j=\tfrac12,\ \beta=0,\ \gamma=+\tfrac12\)</span>, z inicjalizacją <span class="math inline">\(d(x,y)\)</span>.</li>
<li>Metoda średniego wiązania (<em>average linkage</em>, UPGMA - <em>Unweighted Pair Group Method using Arithmetic Averages</em>) <span class="math display">\[
D(C_i,C_j)=\frac{1}{n_i n_j}\sum_{x\in C_i}\sum_{y\in C_j} d(x,y).
\]</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\frac{n_i\,D(C_i,C_k)+n_j\,D(C_j,C_k)}{n_i+n_j},
\]</span> co daje <span class="math inline">\(\alpha_i=\tfrac{n_i}{n_i+n_j},\ \alpha_j=\tfrac{n_j}{n_i+n_j},\ \beta=\gamma=0\)</span>.</li>
<li>Metoda ważonego średniego wiązania (<em>weighted average linkage</em>, WPGMA - <em>Weighted Pair Group Method using Arithmetic Averages</em>, McQuitty) - zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\tfrac12\big(D(C_i,C_k)+D(C_j,C_k)\big),
\]</span> tj. <span class="math inline">\(\alpha_i=\alpha_j=\tfrac12,\ \beta=\gamma=0\)</span>, przy inicjalizacji <span class="math inline">\(d(x,y)\)</span>.</li>
<li>Metoda centroidów (<em>centroid linkage</em>, UPGMC - <em>Unweighted Pair Group Method using Centroids</em>)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> - definicja przez centroidy (wymaga kwadratów odległości euklidesowych) <span class="math display">\[
D(C_i,C_j)=\|\bar x_i-\bar x_j\|^2,\qquad \bar x_i=\frac{1}{n_i}\sum_{x\in C_i}x.
\]</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\frac{n_i}{n_i+n_j}D(C_i,C_k)+\frac{n_j}{n_i+n_j}D(C_j,C_k)-\frac{n_i n_j}{(n_i+n_j)^2}D(C_i,C_j),
\]</span> co odpowiada <span class="math inline">\(\alpha_i=\tfrac{n_i}{n_i+n_j},\ \alpha_j=\tfrac{n_j}{n_i+n_j},\ \beta=-\tfrac{n_i n_j}{(n_i+n_j)^2},\ \gamma=0\)</span>, inicjalizujemy <span class="math inline">\(D(\{x\},\{y\})=\|x-y\|^2\)</span>.</li>
<li>Metoda mediany (<em>median linkage</em>, WPGMC - <em>Weighted Pair Group Method using Centroids</em>) - centra klastrów aktualizujemy przez punkt środkowy median <span class="math inline">\(m_{i\cup j}=\tfrac12(m_i+m_j).\)</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\tfrac12\big(D(C_i,C_k)+D(C_j,C_k)\big)-\tfrac14\,D(C_i,C_j),
\]</span> czyli <span class="math inline">\(\alpha_i=\alpha_j=\tfrac12,\ \beta=-\tfrac14,\ \gamma=0\)</span>, z inicjalizacją <span class="math inline">\(D(\{x\},\{y\})=\|x-y\|^2\)</span>.</li>
<li>Metoda Warda (<em>Ward’s linkage</em>) <span class="math display">\[
D(C_i,C_j)=\frac{2\,n_i n_j}{n_i+n_j}\,\|\bar x_i-\bar x_j\|^2,
\]</span> Zbiory łączymy regułą <span class="math display">\[
D\big((C_i\!\cup\!C_j),C_k\big)=\frac{n_i+n_k}{n_i+n_j+n_k}D(C_i,C_k)+\frac{n_j+n_k}{n_i+n_j+n_k}D(C_j,C_k)-\frac{n_k}{n_i+n_j+n_k}D(C_i,C_j),
\]</span> przy inicjalizacji <span class="math inline">\(D(\{x\},\{y\})=\|x-y\|^2\)</span>.</li>
</ul>
</li>
<li>Proces powtarza się do momentu, gdy wszystkie obiekty znajdą się w jednym skupieniu, tworząc hierarchiczny układ połączeń.</li>
</ol>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;W metodach centroidowych, medianowej i Warda podkreśla się konieczność pracy na kwadratach odległości euklidesowych.</p></div></div><p>Zaletą metod aglomeracyjnych jest to, że nie wymagają a priori określenia liczby skupień. Wadą jest natomiast ich nieodwracalność – raz połączone skupienia nie mogą zostać rozdzielone, a wynik końcowy jest wrażliwy na wybór miary odległości i kryterium wiązania.</p>
<div id="exm-1" class="theorem example">
<p><span class="theorem-title"><strong>Przykład 6.1</strong></span> &nbsp;</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/rpkgs/factoextra">factoextra</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rpkgs.datanovia.com/ggpubr/">ggpubr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 1. Przygotowanie danych: standaryzacja czterech cech numerycznych</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Macierz odległości euklidesowych</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">X</span>, method <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Budowa dendrogramów dla różnych metod łączenia</span></span>
<span><span class="va">hc_single</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">d</span>, method <span class="op">=</span> <span class="st">"single"</span><span class="op">)</span></span>
<span><span class="va">hc_complete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">d</span>, method <span class="op">=</span> <span class="st">"complete"</span><span class="op">)</span></span>
<span><span class="va">hc_average</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">d</span>, method <span class="op">=</span> <span class="st">"average"</span><span class="op">)</span>     <span class="co"># UPGMA</span></span>
<span><span class="va">hc_ward</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">d</span>, method <span class="op">=</span> <span class="st">"ward.D2"</span><span class="op">)</span>     <span class="co"># Ward (zalecany wariant .D2)</span></span>
<span></span>
<span><span class="co"># 4. Wizualizacja dendrogramów z linią cięcia na K=3</span></span>
<span><span class="va">p_d_single</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">hc_single</span>,   k <span class="op">=</span> <span class="fl">3</span>, cex <span class="op">=</span> <span class="fl">0.6</span>, main <span class="op">=</span> <span class="st">"single linkage (K=3)"</span><span class="op">)</span></span>
<span><span class="va">p_d_complete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">hc_complete</span>, k <span class="op">=</span> <span class="fl">3</span>, cex <span class="op">=</span> <span class="fl">0.6</span>, main <span class="op">=</span> <span class="st">"complete linkage (K=3)"</span><span class="op">)</span></span>
<span><span class="va">p_d_average</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">hc_average</span>,  k <span class="op">=</span> <span class="fl">3</span>, cex <span class="op">=</span> <span class="fl">0.6</span>, main <span class="op">=</span> <span class="st">"average linkage (K=3)"</span><span class="op">)</span></span>
<span><span class="va">p_d_ward</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">hc_ward</span>,     k <span class="op">=</span> <span class="fl">3</span>, cex <span class="op">=</span> <span class="fl">0.6</span>, main <span class="op">=</span> <span class="st">"Ward.D2 (K=3)"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html">ggarrange</a></span><span class="op">(</span><span class="va">p_d_single</span>, <span class="va">p_d_complete</span>, <span class="va">p_d_average</span>, <span class="va">p_d_ward</span>, ncol <span class="op">=</span> <span class="fl">2</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><a href="cluster_files/figure-html/unnamed-chunk-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="cluster_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 5. Uzyskanie etykiet klastrów dla K=3 i rzutowanie grup w przestrzeń PCA</span></span>
<span><span class="va">cl_single</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hc_single</span>,   k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">cl_complete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hc_complete</span>, k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">cl_average</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hc_average</span>,  k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">cl_ward</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hc_ward</span>,     k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_c_single</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">X</span>, cluster <span class="op">=</span> <span class="va">cl_single</span><span class="op">)</span>,</span>
<span>                             geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span> <span class="st">"norm"</span>,</span>
<span>                             main <span class="op">=</span> <span class="st">"single linkage"</span><span class="op">)</span></span>
<span><span class="va">p_c_complete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">X</span>, cluster <span class="op">=</span> <span class="va">cl_complete</span><span class="op">)</span>,</span>
<span>                             geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span> <span class="st">"norm"</span>,</span>
<span>                             main <span class="op">=</span> <span class="st">"complete linkage"</span><span class="op">)</span></span>
<span><span class="va">p_c_average</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">X</span>, cluster <span class="op">=</span> <span class="va">cl_average</span><span class="op">)</span>,</span>
<span>                             geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span> <span class="st">"norm"</span>,</span>
<span>                             main <span class="op">=</span> <span class="st">"average linkage"</span><span class="op">)</span></span>
<span><span class="va">p_c_ward</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">X</span>, cluster <span class="op">=</span> <span class="va">cl_ward</span><span class="op">)</span>,</span>
<span>                             geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span> <span class="st">"norm"</span>,</span>
<span>                             main <span class="op">=</span> <span class="st">"Ward.D2"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html">ggarrange</a></span><span class="op">(</span><span class="va">p_c_single</span>, <span class="va">p_c_complete</span>, <span class="va">p_c_average</span>, <span class="va">p_c_ward</span>, ncol <span class="op">=</span> <span class="fl">2</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><a href="cluster_files/figure-html/unnamed-chunk-1-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="cluster_files/figure-html/unnamed-chunk-1-2.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</div>
</section><section id="metody-deglomeracyjne" class="level3"><h3 class="anchored" data-anchor-id="metody-deglomeracyjne">Metody deglomeracyjne</h3>
<p>Metody deglomeracyjne (dzielące) stanowią odwrotność podejścia aglomeracyjnego. Zaczyna się od jednego skupienia zawierającego wszystkie obiekty, które następnie są iteracyjnie dzielone na mniejsze podzbiory, aż do osiągnięcia oczekiwanej liczby skupień lub spełnienia kryterium zatrzymania.</p>
<p>Formalnie proces można przedstawić w postaci</p>
<ol type="1">
<li>Początkowo przyjmuje się jedno skupienie <span class="math display">\[C^{(0)} = X.\]</span>
</li>
<li>W każdym kroku wybiera się skupienie <span class="math inline">\(C_i^{(t)}\)</span>, które zostanie podzielone. Wybór ten może wynikać z maksymalnej wariancji wewnątrzgrupowej, liczby elementów lub innych kryteriów jakości skupień.</li>
<li>Dokonuje się podziału wybranego skupienia na dwa mniejsze, minimalizując błąd wewnątrzgrupowegy lub maksymalizując różnice międzygrupowe. Najczęściej stosuje się algorytm analogiczny do <em>bisecting k-means</em> <span class="math display">\[
C_i^{(t)} \rightarrow \{C_{i1}^{(t+1)}, C_{i2}^{(t+1)}\},
\]</span> przy czym podział realizuje się poprzez iteracyjne zastosowanie k-means z <span class="math inline">\(k = 2\)</span>.</li>
<li>Proces dzielenia jest powtarzany do momentu uzyskania żądanej liczby skupień lub gdy dalszy podział nie prowadzi do istotnej poprawy jakości.</li>
</ol>
<p>Metody deglomeracyjne są mniej popularne z powodu wyższego kosztu obliczeniowego i konieczności przyjęcia dodatkowych kryteriów decyzyjnych dotyczących wyboru skupienia do podziału. Jednak w dużych zbiorach danych mogą być efektywniejsze niż aglomeracyjne, szczególnie gdy implementuje się je z wykorzystaniem metod heurystycznych.</p>
</section></section><section id="metody-niehierarchiczne" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="metody-niehierarchiczne">Metody niehierarchiczne</h2>
<p>Metody niehierarchiczne w analizie skupień koncentrują się na bezpośrednim przypisaniu obiektów do określonej liczby skupień bez tworzenia struktury hierarchicznej. Najbardziej znane i szeroko stosowane są algorytmy typu <em>k-means</em> oraz <em>k-medoids</em>. Podstawą matematyczną metod niehierarchicznych jest minimalizacja pewnej funkcji celu, najczęściej sumy kwadratów odchyleń punktów od środków grup, zwanych centroidami. W przeciwieństwie do podejścia hierarchicznego, proces ten ma charakter iteracyjny i wymaga wcześniejszego określenia liczby klastrów. W efekcie powstaje partycja przestrzeni danych, w której każdy obiekt zostaje przypisany do jednego lub kilku klastrów w zależności od przyjętej koncepcji przynależności (podział płaski<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>). W tym kontekście wyróżnia się dwa główne typy podziałów: podział twardy i podział rozmyty.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;podział płaski oznacza, że każdy obiekt należy do dokładnie jednej grupy i nie istnieje hierarchia między grupami</p></div></div><section id="podział-twardy" class="level3"><h3 class="anchored" data-anchor-id="podział-twardy">Podział twardy</h3>
<p>Podział twardy opiera się na jednoznacznym przypisaniu każdego obiektu do dokładnie jednego klastra. W ujęciu matematycznym przyjmuje się, że dla zbioru obserwacji <span class="math inline">\(X = \{x_1, x_2, \ldots, x_n\}\)</span> oraz ustalonej liczby klastrów <span class="math inline">\(K\)</span>, istnieje macierz przynależności <span class="math inline">\(U = [u_{ik}]\)</span>, w której każdy element przyjmuje wartość 0 lub 1. Wartość <span class="math inline">\(u_{ik} = 1\)</span> oznacza, że obiekt <span class="math inline">\(x_i\)</span> należy do klastra <span class="math inline">\(k\)</span>, natomiast <span class="math inline">\(u_{ik} = 0\)</span> – że do niego nie należy.</p>
<p>Pierwszym warunkiem podziału twardego jest to, że każdy obiekt musi należeć dokładnie do jednej grupy. Oznacza to, że dla każdego obiektu suma przynależności po wszystkich klastrach równa się jeden <span class="math display">\[
\sum_{k=1}^{K} u_{ik} = 1, \quad \forall i \in \{1, 2, \ldots, n\}.
\]</span> Z kolei każdy klaster powinien zawierać przynajmniej jeden element, co można zapisać jako <span class="math display">\[
1 \leq \sum_{i=1}^{n} u_{ik}, \quad \forall k \in \{1, 2, \ldots, K\}.
\]</span> Wynika z tego, że nie dopuszcza się powstawania pustych grup. Kolejnym warunkiem jest binarność przypisań, czyli <span class="math display">\[
u_{ik} \in \{0, 1\}, \quad \forall i, k.
\]</span> Przynależność obiektu do klastra jest zatem całkowita i nie dopuszcza stanów pośrednich. Wreszcie, formalnym celem podziału twardego jest minimalizacja funkcji błędu, która określa sumę kwadratów odchyleń poszczególnych obiektów od centroidów klastrów, do których zostały przypisane <span class="math display">\[
J = \sum_{k=1}^{K} \sum_{i=1}^{n} u_{ik} \, \|x_i - \mu_k\|^2,
\]</span> gdzie <span class="math inline">\(\mu_k\)</span> oznacza środek klastra <span class="math inline">\(k\)</span>, a <span class="math inline">\(\|\cdot\|\)</span> jest najczęściej normą euklidesową. Każdy obiekt powinien zostać przypisany do tego klastra, którego centroid jest najbliższy, czyli <span class="math display">\[
u_{ik} =
\begin{cases}
1, &amp; \text{jeśli } k = \arg \min_{j} \|x_i - \mu_j\|, \\
0, &amp; \text{w przeciwnym razie.}
\end{cases}
\]</span></p>
</section><section id="podział-rozmyty" class="level3"><h3 class="anchored" data-anchor-id="podział-rozmyty">Podział rozmyty</h3>
<p>Podział rozmyty (ang. <em>fuzzy clustering</em>) stanowi uogólnienie klasycznego, twardego podejścia do grupowania, w którym dopuszcza się możliwość częściowej przynależności obiektu do więcej niż jednego klastra. Zamiast przypisywać każdy element jednoznacznie do jednej grupy, wprowadza się pojęcie stopnia przynależności, który przyjmuje wartości z przedziału <span class="math inline">\([0,1]\)</span>. W ten sposób odzwierciedla się niepewność lub płynność granic między grupami, co czyni tę metodę bardziej elastyczną i lepiej dostosowaną do danych o niejednoznacznej strukturze.</p>
<p>Matematycznie, dla zbioru obserwacji <span class="math inline">\(X = \{x_1, x_2, \ldots, x_n\}\)</span> oraz ustalonej liczby klastrów <span class="math inline">\(K\)</span>, definiuje się macierz przynależności <span class="math inline">\(U = [u_{ik}]\)</span>, gdzie każdy element <span class="math inline">\(u_{ik}\)</span> oznacza stopień, w jakim obiekt <span class="math inline">\(x_i\)</span> należy do klastra <span class="math inline">\(k\)</span>. W odróżnieniu od podziału twardego, tutaj <span class="math inline">\(u_{ik} \in [0,1]\)</span>, a nie tylko <span class="math inline">\(\{0,1\}\)</span>. Zachowany zostaje jednak warunek, że suma stopni przynależności danego obiektu do wszystkich klastrów musi być równa jeden <span class="math display">\[
\sum_{k=1}^{K} u_{ik} = 1, \quad \forall i \in \{1, 2, \ldots, n\}.
\]</span> Warunek ten oznacza, że przynależności mają charakter względny – im silniejszy związek obiektu z jednym klastrem, tym słabszy z innymi.</p>
<p>Podział rozmyty opiera się na minimalizacji rozmytej funkcji celu, znanej z algorytmu <em>Fuzzy c-means</em> <span class="math display">\[
J_m = \sum_{k=1}^{K} \sum_{i=1}^{n} (u_{ik})^m \, \|x_i - \mu_k\|^2,
\]</span> gdzie <span class="math inline">\(\mu_k\)</span> oznacza centroid klastra <span class="math inline">\(k\)</span>, a parametr <span class="math inline">\(m &gt; 1\)</span> kontroluje poziom rozmycia. Im większa wartość <span class="math inline">\(m\)</span>, tym bardziej rozmyty staje się podział, ponieważ różnice pomiędzy wartościami przynależności poszczególnych obiektów do klastrów ulegają spłaszczeniu. W praktyce najczęściej przyjmuje się <span class="math inline">\(m = 2\)</span>. Optymalizacja funkcji celu prowadzi do następujących warunków aktualizacji. Stopnie przynależności obliczane są według wzoru <span class="math display">\[
u_{ik} = \frac{1}{\sum_{j=1}^{K} \left( \frac{\|x_i - \mu_k\|}{\|x_i - \mu_j\|} \right)^{\frac{2}{m-1}}},
\]</span> natomiast nowe położenie centroidów wyznacza się jako ważoną średnią punktów, gdzie wagi stanowią stopnie przynależności podniesione do potęgi <span class="math inline">\(m\)</span> <span class="math display">\[
\mu_k = \frac{\sum_{i=1}^{n} (u_{ik})^m x_i}{\sum_{i=1}^{n} (u_{ik})^m}.
\]</span> Proces ten przebiega iteracyjnie – w każdej iteracji obliczane są nowe wartości <span class="math inline">\(u_{ik}\)</span> i <span class="math inline">\(\mu_k\)</span>, aż do osiągnięcia zbieżności funkcji celu <span class="math inline">\(J_m\)</span>.</p>
</section><section id="metoda-k-średnich-k-means" class="level3"><h3 class="anchored" data-anchor-id="metoda-k-średnich-k-means">Metoda k-średnich (<em>k-means</em>)</h3>
<p>Algorytm <em>k-means</em> wynika z problemu minimalizacji sumy kwadratów odchyleń punktów od reprezentantów grup w metryce euklidesowej. Niech dany będzie zbiór obserwacji <span class="math inline">\(X=\{x_1,\dots,x_n\}\subset\mathbb{R}^p\)</span> oraz liczba klastrów <span class="math inline">\(K\)</span>. Celem jest znalezienie partycji danych i wektorów <span class="math inline">\(\mu_1,\dots,\mu_K\in\mathbb{R}^p\)</span> minimalizujących funkcję celu <span class="math display">\[
J(U,\mu)=\sum_{k=1}^K\sum_{i=1}^n u_{ik}\,\|x_i-\mu_k\|^2,
\]</span> gdzie <span class="math inline">\(U=[u_{ik}]\)</span> jest macierzą przypisań spełniającą warunki podziału twardego <span class="math inline">\(u_{ik}\in\{0,1\}\)</span>, <span class="math inline">\(\sum_{k=1}^K u_{ik}=1\)</span> dla każdego <span class="math inline">\(i\)</span>, a <span class="math inline">\(\sum_{i=1}^n u_{ik}\ge 1\)</span> dla każdego <span class="math inline">\(k\)</span>.</p>
<p>Wyprowadzenie algorytmu polega na zastosowaniu naprzemiennej minimalizacji względem <span class="math inline">\(U\)</span> i <span class="math inline">\(\mu\)</span>, ponieważ jednoczesna minimalizacja jest problemem kombinatorycznym trudnym obliczeniowo. Rozważmy najpierw minimalizację względem centroidów przy ustalonych przypisaniach. Dla danego <span class="math inline">\(k\)</span> rozważmy funkcję <span class="math display">\[
J_k(\mu_k)=\sum_{i=1}^n u_{ik}\,\|x_i-\mu_k\|^2.
\]</span> Jest to funkcja kwadratowa ściśle wypukła w <span class="math inline">\(\mu_k\)</span>. Obliczamy gradient <span class="math display">\[
\nabla_{\mu_k}J_k(\mu_k)=2\sum_{i=1}^n u_{ik}\,(\mu_k-x_i)=2\left(\Big(\sum_{i}u_{ik}\Big)\mu_k-\sum_{i}u_{ik}x_i\right).
\]</span> Warunek <span class="math inline">\(\nabla_{\mu_k}J_k(\mu_k)=0\)</span> daje <span class="math display">\[
\mu_k^\star=\frac{\sum_{i=1}^n u_{ik}x_i}{\sum_{i=1}^n u_{ik}},
\]</span> czyli optymalny centroid jest średnią arytmetyczną punktów przypisanych do klastra. Wypukłość zapewnia, że jest to minimum globalne względem <span class="math inline">\(\mu_k\)</span>. Zatem przy ustalonych <span class="math inline">\(U\)</span> krok aktualizacji centroidów ma postać średniej ważonej ze wskaźnikami <span class="math inline">\(u_{ik}\)</span>.</p>
<p>Następnie dokonujemy minimalizacji względem przypisań przy ustalonych centroidach. Dla każdego obiektu <span class="math inline">\(x_i\)</span> problem redukuje się do <span class="math display">\[
\min_{u_{i1},\dots,u_{iK}} \sum_{k=1}^K u_{ik}\,\|x_i-\mu_k\|^2\quad \text{przy}\quad u_{ik}\in\{0,1\},\ \sum_k u_{ik}=1.
\]</span> Ponieważ wyrażenie jest liniowe w <span class="math inline">\(u_{ik}\)</span>, optimum osiąga się, wybierając <span class="math inline">\(u_{ik}=1\)</span> dla indeksu <span class="math inline">\(k\)</span> minimalizującego odległość euklidesową <span class="math display">\[
u_{ik}=\mathbf{1}_\left\{k=\operatorname{argmin}_{j\in\{1,\dots,K\}}\|x_i-\mu_j\|^2\right\}.
\]</span> Wynika stąd reguła „przypisz do najbliższego centroidu”, co geometrycznie odpowiada podziałowi przestrzeni na komórki Woronoja wyznaczone przez <span class="math inline">\(\{\mu_k\}\)</span>.</p>
<p><a href="images/kmeans_animation.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="images/kmeans_animation.gif" class="img-fluid"></a></p>
<p>Złożenie obu kroków prowadzi do procedury znanej jako <em>Lloyd’s algorithm</em>:</p>
<ol type="1">
<li>Startujemy od wstępnych centroidów <span class="math inline">\(\mu^{(0)}\)</span>.</li>
<li>Naprzemiennie wykonujemy przypisanie do najbliższego centroidu.</li>
<li>Przeprowadzamy aktualizację centroidów jako średnich.</li>
<li>Wykonujemy kroki 2-3 aż do osiągnięcia zbieżności (punkty nie zmieniają swoich skupień).</li>
</ol>
<p>Każdy z kroków 2-3 nie zwiększa funkcji celu, bo przy ustalonych centroidach wybór najbliższego centroidu minimalizuje składnik <span class="math inline">\(\|x_i-\mu_k\|^2\)</span> dla każdego <span class="math inline">\(i\)</span>, więc <span class="math inline">\(J\)</span> maleje lub pozostaje stała, a przy ustalonych przypisaniach do klastrów wybór średniej minimalizuje sumę kwadratów, więc <span class="math inline">\(J\)</span> również maleje lub pozostaje stała. Ponieważ istnieje skończona liczba możliwych partycji i <span class="math inline">\(J\ge 0\)</span>, monotonicznie niemalejąca sekwencja wartości funkcji celu musi zatrzymać się w skończonej liczbie kroków na punkcie stacjonarnym, czyli minimum lokalnym problemu z ograniczeniami twardych przypisań.</p>
<p>Warto zauważyć, że równoważnie można interpretować cel jako minimalizację wariancji wewnątrzklastrowej. W klasycznej dekompozycji SST <span class="math display">\[
\underbrace{\sum_{i=1}^n \|x_i-\bar{x}\|^2}_{\text{SST}}=\underbrace{\sum_{k=1}^K\sum_{i=1}^n u_{ik}\|x_i-\mu_k\|^2}_{\text{WSS}}+\underbrace{\sum_{k=1}^K n_k\|\mu_k-\bar{x}\|^2}_{\text{BSS}},
\]</span> gdzie <span class="math inline">\(\bar{x}\)</span> jest średnią globalną, a <span class="math inline">\(n_k=\sum_i u_{ik}\)</span>. Minimalizacja WSS (ang. <em>within-cluster sum of squares</em>) przy zadanym <span class="math inline">\(K\)</span> jest równoważna maksymalizacji BSS, czyli maksymalizacji separacji centroidów względem średniej globalnej, co formalnie uzasadnia intuicję „maksymalizować jednorodność wewnątrz klastrów i różnice między klastrami”.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<em>k-means++</em>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Zastosowanie inicjalizacji <em>k-means++</em> polega na losowaniu początków z uprzywilejowaniem punktów odległych od już wybranych centroidów, co w sensie teoretycznym daje gwarancje aproksymacyjne rzędu <span class="math inline">\(O(\log K)\)</span> względem optimum oczekiwanego, a w praktyce istotnie poprawia jakość minimum lokalnego.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warunki stacjonarności otrzymanego rozwiązania
</div>
</div>
<div class="callout-body-container callout-body">
<p>Para <span class="math inline">\((U^\star,\mu^\star)\)</span> jest punktem stałym algorytmu wtedy i tylko wtedy, gdy spełnia jednocześnie dwa warunki: po pierwsze <span class="math inline">\(\mu_k^\star\)</span> są średnimi swoich klastrów, po drugie przypisania <span class="math inline">\(U^\star\)</span> są zgodne z najbliższymi centroidami <span class="math inline">\(\mu^\star.\)</span> Takie rozwiązanie spełnia warunki optymalności pierwszego rzędu względem naprzemiennych bloków zmiennych i stanowi minimum lokalne funkcji <span class="math inline">\(J\)</span> na zbiorze dopuszczalnych rozwiązań wyznaczonych z ograniczeniami twardych przypisań.</p>
</div>
</div>
</section><section id="metoda-k-medoidów-k-medoids" class="level3"><h3 class="anchored" data-anchor-id="metoda-k-medoidów-k-medoids">Metoda k-medoidów (<em>k-medoids</em>)</h3>
<p>Metoda k-medoid (ang. <em>k-medoids</em>) stanowi bliski odpowiednik klasycznej metody <em>k-means</em>, lecz wprowadza zasadniczą zmianę w sposobie definiowania reprezentanta klastra. Zamiast centroidu obliczanego jako średnia arytmetyczna wszystkich punktów w danym klastrze, metoda k-medoid wykorzystuje medoid, czyli rzeczywisty punkt ze zbioru danych, który minimalizuje sumę odległości do pozostałych elementów tego samego klastra. Dzięki temu metoda ta jest bardziej odporna na obserwacje odstające oraz umożliwia zastosowanie dowolnej miary odległości, nie tylko euklidesowej.</p>
<p>Niech dany będzie zbiór obserwacji <span class="math inline">\(X = \{x_1, x_2, \ldots, x_n\} \subset \mathbb{R}^p\)</span> oraz liczba klastrów <span class="math inline">\(K\)</span>. Celem jest podział zbioru <span class="math inline">\(X\)</span> na <span class="math inline">\(K\)</span> grup w taki sposób, aby suma odległości pomiędzy punktami a reprezentantami ich klastrów była minimalna. Funkcję celu można zapisać jako <span class="math display">\[
J(M, U) = \sum_{k=1}^{K} \sum_{i=1}^{n} u_{ik} \, d(x_i, m_k),
\]</span> gdzie <span class="math inline">\(M = \{m_1, m_2, \ldots, m_K\} \subset X\)</span> to zbiór medoidów, <span class="math inline">\(U = [u_{ik}]\)</span> to macierz przypisań punktów do klastrów, a <span class="math inline">\(d(x_i, m_k)\)</span> oznacza wybraną miarę odległości. Dla każdego obiektu zachodzi warunek <span class="math inline">\(u_{ik} \in \{0,1\}\)</span> oraz <span class="math inline">\(\sum_{k=1}^{K} u_{ik} = 1\)</span>, co oznacza, że każdy punkt należy dokładnie do jednego klastra. Medoid klastra definiuje się jako punkt <span class="math inline">\(m_k \in X\)</span>, który minimalizuje sumę odległości do wszystkich pozostałych punktów tego klastra <span class="math display">\[
m_k = \operatorname{argmin}_{x_j \in X_k} \sum_{x_i \in X_k} d(x_i, x_j),
\]</span> gdzie <span class="math inline">\(X_k = \{x_i : u_{ik} = 1\}\)</span>.</p>
<p>W praktyce metoda realizowana jest iteracyjnie, analogicznie do <em>k-means</em>, ale z innym sposobem aktualizacji reprezentantów. Najbardziej znanym algorytmem implementującym tę ideę jest PAM (<em>Partitioning Around Medoids</em>). Procedura ta obejmuje następujące kroki. Po pierwsze, inicjalizuje się losowo <span class="math inline">\(K\)</span> punktów jako początkowe medoidy. Następnie każdy obiekt przypisywany jest do najbliższego medoidu, zgodnie z regułą <span class="math display">\[
u_{ik} = \mathbf{1}_\left\{\,k = \operatorname{argmin}_{j} d(x_i, m_j)\right\}.
\]</span> W ten sposób powstaje podział przestrzeni na obszary przypominające komórki Woronoja. W kolejnym kroku, dla każdego klastra wybiera się nowy medoid, czyli punkt, który minimalizuje sumę odległości do pozostałych punktów w tym klastrze. Algorytm powtarza naprzemienne kroki przypisania i aktualizacji aż do momentu, gdy zestaw medoidów przestaje się zmieniać lub wartość funkcji celu stabilizuje się.</p>
<p>Metoda k-medoid jest blisko spokrewniona z metodą k-means, która minimalizuje sumę kwadratów odległości euklidesowych <span class="math display">\[
J_{\text{k-means}} = \sum_{k=1}^{K}\sum_{i=1}^{n} u_{ik}\,\|x_i - \mu_k\|^2,
\]</span> gdzie <span class="math inline">\(\mu_k\)</span> oznacza centroid klastra. W k-medoid zamiast średniej stosuje się rzeczywisty punkt danych, a w funkcji celu pojawia się bezpośrednia odległość, nie jej kwadrat. W konsekwencji metoda k-means jest szybsza, lecz wrażliwa na wartości odstające i ograniczona do przestrzeni euklidesowych, natomiast k-medoid jest bardziej odporna i umożliwia pracę z dowolnymi macierzami odległości, także nieliczbowymi.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ostrzeżenie
</div>
</div>
<div class="callout-body-container callout-body">
<p>Warto odróżnić metodę k-medoid od metody k-median. W k-medoid reprezentantem klastra jest rzeczywisty punkt ze zbioru danych, natomiast w k-median mediana klastra może znajdować się w dowolnym miejscu przestrzeni. Funkcja celu w k-median minimalizuje sumę odległości w sensie L1 (Manhattan) <span class="math display">\[
J_{\text{k-median}} = \sum_{k=1}^{K}\sum_{i=1}^{n} u_{ik} \, \|x_i - m_k\|_1.
\]</span> Zatem k-median stanowi ciągły odpowiednik metody k-medoid, podobnie jak k-means jest wersją ciągłą dla odległości euklidesowych w kwadracie.</p>
</div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 28%">
<col style="width: 29%">
<col style="width: 23%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Cechy</th>
<th style="text-align: left;">k-means</th>
<th style="text-align: left;">k-median</th>
<th style="text-align: left;">k-medoid</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Reprezentant</td>
<td style="text-align: left;">średnia arytmetyczna (punkt w ℝᵖ)</td>
<td style="text-align: left;">mediana geometryczna (punkt w ℝᵖ)</td>
<td style="text-align: left;">rzeczywisty punkt danych</td>
</tr>
<tr class="even">
<td style="text-align: left;">Miara odległości</td>
<td style="text-align: left;">kwadrat euklidesowej</td>
<td style="text-align: left;">Manhattan (L1)</td>
<td style="text-align: left;">dowolna miara</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Odporność na odstające</td>
<td style="text-align: left;">niska</td>
<td style="text-align: left;">średnia</td>
<td style="text-align: left;">wysoka</td>
</tr>
<tr class="even">
<td style="text-align: left;">Typ zmiennych</td>
<td style="text-align: left;">ciągłe</td>
<td style="text-align: left;">ciągłe</td>
<td style="text-align: left;">dowolne (także kategoryczne)</td>
</tr>
</tbody>
</table></section><section id="clara-i-clarans" class="level3"><h3 class="anchored" data-anchor-id="clara-i-clarans">CLARA i CLARANS</h3>
<p>Algorytmy CLARA i CLARANS stanowią rozwinięcia metody k-medoid, opracowane w celu rozwiązania problemu wysokiej złożoności obliczeniowej klasycznego algorytmu PAM. Oba podejścia zachowują tę samą ideę — minimalizację sumy odległości punktów do reprezentantów (medoidów) — lecz różnią się strategią poszukiwania najlepszego zbioru medoidów w dużych zbiorach danych.</p>
<section id="algorytm-clara-clustering-large-applications" class="level4"><h4 class="anchored" data-anchor-id="algorytm-clara-clustering-large-applications">Algorytm CLARA (<em>Clustering LARge Applications</em>)</h4>
<p>Algorytm CLARA został zaproponowany przez Kaufmana i Rousseeuwa (1990) jako metoda przybliżona dla k-medoids, umożliwiająca efektywne działanie przy dużej liczbie obserwacji. Kluczową ideą CLARA jest ograniczenie pełnych obliczeń do próbek danych, zamiast całego zbioru.</p>
<p>Procedura przebiega w kilku etapach:</p>
<ol type="1">
<li>Losowanie próbki - z całego zbioru danych <span class="math inline">\(X\)</span> losuje się podzbiór <span class="math inline">\(S \subset X\)</span> o umiarkowanej liczności (np. 5–10% wszystkich obserwacji).</li>
<li>Zastosowanie algorytmu PAM - na wylosowanej próbce <span class="math inline">\(S\)</span> przeprowadza się pełną procedurę PAM w celu wyznaczenia <span class="math inline">\(K\)</span> medoidów <span class="math inline">\(M_S = \{m_1, \ldots, m_K\}\)</span>.</li>
<li>Ocena jakości podziału - uzyskane medoidy testuje się na całym zbiorze danych, obliczając wartość funkcji kosztu <span class="math display">\[
J(M_S) = \sum_{i=1}^{n} \min_{m_k \in M_S} d(x_i, m_k),
\]</span> czyli sumę odległości każdego punktu do najbliższego medoidu.</li>
<li>Powtórzenia i wybór najlepszego rozwiązania - proces losowania próbki i przeprowadzania PAM powtarza się kilka razy (np. 5–10), a końcowy wynik wybiera się na podstawie minimalnej wartości funkcji celu <span class="math inline">\(J(M_S)\)</span>.</li>
</ol>
<p>Zaletą CLARA jest znaczne obniżenie kosztów obliczeniowych w porównaniu z PAM, którego złożoność wynosi <span class="math inline">\(O(k(n-k)^2)\)</span>. W CLARA złożoność zależy od rozmiaru próbki, a nie całego zbioru, co umożliwia stosowanie metody na dużych danych. Wadą jest jednak możliwość utraty jakości rozwiązania, jeśli próbka nie jest reprezentatywna — w szczególności, jeśli pomija mniejsze skupienia obecne w zbiorze danych.</p>
</section><section id="algorytm-clarans-clustering-large-applications-based-on-randomized-search" class="level4"><h4 class="anchored" data-anchor-id="algorytm-clarans-clustering-large-applications-based-on-randomized-search">Algorytm CLARANS (<em>Clustering Large Applications based on RANdomized Search</em>)</h4>
<p>Algorytm CLARANS, opracowany przez Ng i Hana (1994), stanowi dalsze rozwinięcie CLARA i PAM, oparte na losowym przeszukiwaniu przestrzeni możliwych zbiorów medoidów. Jego działanie inspirowane jest technikami heurystycznymi, takimi jak <em>local search</em> lub <em>simulated annealing</em>. CLARANS traktuje przestrzeń wszystkich możliwych zestawów medoidów jako graf, w którym każdy wierzchołek odpowiada pewnemu zestawowi <span class="math inline">\(K\)</span> medoidów, a krawędzie łączą wierzchołki różniące się jednym medoidem. Poszukiwanie najlepszego rozwiązania odbywa się przez losowe przechodzenie po tym grafie, przy czym zmiany medoidów dokonuje się tylko wtedy, gdy poprawiają funkcję celu.</p>
<p>Schemat działania można opisać następująco:</p>
<ol type="1">
<li>Inicjalizacja - losowo wybrać zestaw <span class="math inline">\(K\)</span> medoidów <span class="math inline">\(M\)</span>.</li>
<li>Losowa eksploracja sąsiedztwa - spośród wszystkich możliwych „zamian” jednego medoidu <span class="math inline">\(m \in M\)</span> na punkt niebędący medoidem <span class="math inline">\(x \in X \setminus M\)</span>, losowo wybrać kilka par kandydatów (tzw. <em>neighbors</em>).</li>
<li>Ocena sąsiadów - dla każdego kandydata obliczyć zmianę funkcji celu <span class="math display">\[
\Delta J = J(M’) - J(M),
\]</span> gdzie <span class="math inline">\(M’\)</span> to nowy zestaw medoidów po zamianie.</li>
<li>Krok optymalizacyjny - jeśli znajdzie się sąsiad z mniejszą wartością funkcji kosztu, przyjąć go jako nowy zestaw medoidów <span class="math inline">\(M \leftarrow M’\)</span>.</li>
<li>Kontynuacja - powtarzać losowe przeszukiwanie do osiągnięcia lokalnego minimum (brak poprawiających się sąsiadów) lub do wyczerpania limitu iteracji.</li>
<li>Powtórzenia - dla zwiększenia szansy znalezienia rozwiązania globalnego, procedurę powtarza się kilka razy z różnymi początkowymi zestawami medoidów.</li>
</ol>
<p>CLARANS jest więc algorytmem probabilistycznym, który w każdym kroku dokonuje losowej eksploracji przestrzeni możliwych rozwiązań. W przeciwieństwie do CLARA nie ogranicza się do jednej próbki danych, lecz do ograniczonej liczby losowo sprawdzanych sąsiadów, co pozwala zachować kompromis między dokładnością a szybkością.</p>
<div id="exm-2" class="theorem example">
<p><span class="theorem-title"><strong>Przykład 6.2</strong></span> &nbsp;</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/cluster/">cluster</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">44</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 1. k-means</span></span>
<span><span class="va">kmeans_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">X</span>, centers <span class="op">=</span> <span class="fl">3</span>, nstart <span class="op">=</span> <span class="fl">25</span><span class="op">)</span></span>
<span><span class="va">p_kmeans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="va">kmeans_res</span>, data <span class="op">=</span> <span class="va">X</span>, geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span><span class="st">"norm"</span>, main <span class="op">=</span> <span class="st">"k-means"</span><span class="op">)</span></span>
<span><span class="co"># 2. k-medoids (PAM)</span></span>
<span><span class="va">pam_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/cluster/man/pam.html">pam</a></span><span class="op">(</span><span class="va">X</span>, k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">p_pam</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="va">pam_res</span>, geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span><span class="st">"norm"</span>, main <span class="op">=</span> <span class="st">"PAM (k-medoids)"</span><span class="op">)</span></span>
<span><span class="co"># 3. CLARA</span></span>
<span><span class="va">clara_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/cluster/man/clara.html">clara</a></span><span class="op">(</span><span class="va">X</span>, k <span class="op">=</span> <span class="fl">3</span>, samples <span class="op">=</span> <span class="fl">5</span>, pamLike<span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">p_clara</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="va">clara_res</span>, geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span></span>
<span>                               <span class="st">"norm"</span>, main <span class="op">=</span> <span class="st">"CLARA"</span><span class="op">)</span></span>
<span><span class="co"># 4. CLARANS</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">fastkmedoids</span><span class="op">)</span></span>
<span><span class="va">clarans_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/fastkmedoids/man/fastclarans.html">fastclarans</a></span><span class="op">(</span><span class="va">d</span>, k <span class="op">=</span> <span class="fl">3</span>, n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">p_clarans</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">X</span>, cluster <span class="op">=</span> <span class="va">clara_res</span><span class="op">$</span><span class="va">clustering</span><span class="op">)</span>, geom <span class="op">=</span> <span class="st">"point"</span>, ellipse.type <span class="op">=</span></span>
<span>                                 <span class="st">"norm"</span>, main <span class="op">=</span> <span class="st">"CLARANS"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html">ggarrange</a></span><span class="op">(</span><span class="va">p_kmeans</span>, <span class="va">p_pam</span>, <span class="va">p_clara</span>, <span class="va">p_clarans</span>, ncol <span class="op">=</span> <span class="fl">2</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><a href="cluster_files/figure-html/unnamed-chunk-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="cluster_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</div>


</section></section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Skopiowano!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Skopiowano!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./pca.html" class="pagination-link" aria-label="Metody redukcji wymiarowości">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Metody redukcji wymiarowości</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Literatura">
        <span class="nav-page-text">Literatura</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Wielowymiarowa analiza danych</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/DariuszMajerek/WAD_new/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Dariusz Majerek ©2025</p>
</div>
  </div>
</footer><script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>


</body></html>